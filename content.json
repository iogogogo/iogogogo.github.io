{"meta":{"title":"阿牛的博客","subtitle":"阿牛的博客","description":null,"author":"阿牛","url":"http://iogogogo.github.io","root":"/"},"pages":[{"title":"分类","date":"2020-01-01T03:40:32.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"categories/index.html","permalink":"http://iogogogo.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-01-01T03:41:12.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"about/index.html","permalink":"http://iogogogo.github.io/about/index.html","excerpt":"","text":""},{"title":"留言板","date":"2020-01-01T03:41:46.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"contact/index.html","permalink":"http://iogogogo.github.io/contact/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-01-01T03:41:35.000Z","updated":"2024-07-01T12:30:37.382Z","comments":true,"path":"friends/index.html","permalink":"http://iogogogo.github.io/friends/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-01-01T03:42:26.000Z","updated":"2024-07-01T12:30:37.458Z","comments":true,"path":"tags/index.html","permalink":"http://iogogogo.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Git配置多个SSH-Key","slug":"ssh-key-multiple","date":"2023-03-12T07:49:31.000Z","updated":"2024-07-01T12:39:43.061Z","comments":true,"path":"2023/03/12/ssh-key-multiple/","link":"","permalink":"http://iogogogo.github.io/2023/03/12/ssh-key-multiple/","excerpt":"","text":"背景当有多个git账号时，比如： 一个gitee，用于公司内部的工作开发； 一个github，用于自己进行一些开发活动； 解决方法生成一个公司用的SSH-Key ssh-keygen -t rsa -C 'xxxxx@company.com' -f ~/.ssh/gitee_id_rsa 生成一个github用的SSH-Key ssh-keygen -t rsa -C 'xxxxx@qq.com' -f ~/.ssh/github_id_rsa 在 ~/.ssh 目录下新建一个config文件，添加如下内容（其中Host和HostName填写git服务器的域名，IdentityFile指定私钥的路径） # gitee Host gitee.com HostName gitee.com PreferredAuthentications publickey IdentityFile ~/.ssh/gitee_id_rsa # github Host github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/github_id_rsa 用ssh命令分别测试 ssh -T git@gitee.com ssh -T git@github.com 这里以gitee为例，成功的话会返回以下内容 ➜ ~ ssh -T git@gitee.com Hi xxxx! You've successfully authenticated, but GITEE.COM does not provide shell access. FAQ执行测试命令时，出现错误：Bad owner or permissions on /home/xx/.ssh/config 解决方案：chmod 600 ~/.ssh/config","categories":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/tags/Git/"}]},{"title":"mkdocs安装与配置","slug":"blog-mkdocs-install-configure","date":"2023-03-12T04:30:02.000Z","updated":"2024-07-01T12:30:37.355Z","comments":true,"path":"2023/03/12/blog-mkdocs-install-configure/","link":"","permalink":"http://iogogogo.github.io/2023/03/12/blog-mkdocs-install-configure/","excerpt":"","text":"上篇文档介绍了hexo的建站与基础配置，hexo适合做博客日志平台，不适合做帮助系统。所以最后又看了mkdocs，最后经过评审选择了mkdocs作为帮助系统的写作平台。 什么是MkDocsMkDocs 是一个基于Python构建的内容管理平台，它拥有丰富的主题，内容自定义性也强大，非常适合做一个帮助系统的建站工具，其中mkdocs的官网也是基于mkdocs去实现的。 使用MkDocs建站使用mkdocs建站，一共有以下几个步骤 安装Python环境 安装mkdocs相关依赖 配置mkdocs基本信息 编译运行 安装Python环境mkdocs支持Python2.6+的版本，为了方便管理依赖，我们可以直接使用Anaconda进行安装。 具体安装不在赘述，基本就是下一步交互式安装 Windows：下载exe文件，双击下一步安装 macOS：下载pkg文件，双击下一步安装 Linux：执行安装脚本 sh Anaconda3-xxxx.xx-Linux-x86_64.sh 为了加速anaconda的下载，整理了以下几个anaconda的镜像网站，方便下载安装 清华大学开源软件镜像站：https://mirrors.bfsu.edu.cn/anaconda/archive/ 北京外国语大学开源软件镜像站：https://mirrors.bfsu.edu.cn/anaconda/archive/ 安装好Python后可以查看一下Python的版本与对应法发行方 # python 版本是3.9.13 ➜ ~ python -V Python 3.9.13 ➜ ~ # 对应的发行商是Anaconda ➜ ~ python Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ] :: Anaconda, Inc. on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> 安装mkdocs相关包# 这里为了加速下载，使用了豆瓣的pip源 pip install --trusted-host pypi.douban.com -i http://pypi.douban.com/simple/ mkdocs 安装好之后可以验证一下是否安装成功，查看一下mkdocs的版本 ➜ ~ mkdocs -V mkdocs, version 1.4.2 from /opt/app/anaconda3/lib/python3.9/site-packages/mkdocs (Python 3.9) 使用mkdocs搭建第一个内容网站 建站命令 mkdocs new mkdocs-blog && cd mkdocs-blog 对应的日志输出 ➜ ~ mkdocs new mkdocs-blog && cd mkdocs-blog INFO - Creating project directory: mkdocs-blog INFO - Writing config file: mkdocs-blog/mkdocs.yml INFO - Writing initial docs: mkdocs-blog/docs/index.md ➜ mkdocs-blog ll total 8 drwxr-xr-x 3 tao.zeng staff 96B 3 12 18:16 docs -rw-r--r-- 1 tao.zeng staff 19B 3 12 18:16 mkdocs.yml 运行mkdocs网站 mkdocs serve 在浏览器中打开，只要看到这个首页，就证明我们的mkdocs已经正常运行。 mkdocs主题配置mkdocs有比较丰富的主题，我个人比较倾向于Material for MkDocs (squidfunk.github.io)，下面介绍一下这个主题的相关配置。 material-mkdocs是一个基于Google material design设计的一款主题，风格比较清新。 使用material-mkdocs主题也很简单，需要使用pip进行安装，这里也使用了豆瓣源 pip install --trusted-host pypi.douban.com -i http://pypi.douban.com/simple/ mkdocs-material 安装完成之后在 mkdocs.yml 中配置主题 theme: # 配置主题 name: material # 配置语言为中文，搜索框search就会变成搜索 language: zh 重启mkdocs服务，即可看到主题已经发生变化 更多关于material-mkdocs的配置与他支持的markdown语法，请查看我的另外一个基于mkdocs的帮助文档：Material for MkDocs - Markdown语法详解(基于mkdocs-material) (iogogogo.github.io) 发布到GitHub-PagesGitHub pages是一个github的静态资源托管服务，只需要把我们写好的程序进行打包上传到github，github就会帮我们进行代理访问，https://{username}.github.io/{repoName} 使用mkdocs发布到github pages只需要几步简单的配置即可完成，在 mkdocs.yml添加以下内容 # Project information site_name: Markdown语法详解(基于mkdocs-material) # 最终访问的地址，这个很重要，mkdocs会自动创建一个gh-pages的分支进行代码托管，repoNmae也关系到我们访问的contextPath site_url: https://iogogogo.github.io/markdown-with-mkdocs-material site_author: 曾涛 site_description: mkdocs-material支持的markdown语法，包括传统语法和扩展语法介绍。 # Repository repo_name: iogogogo/markdown-with-mkdocs-material # 源码git地址 repo_url: https://github.com/iogogogo/markdown-with-mkdocs-material 发布到github，等待几分钟就可以打开页面进行查看 这里以markdown-with-mkdocs-material示例，访问：https://iogogogo.github.io/markdown-with-mkdocs-material/ mkdocs gh-deploy --clean 发布到服务器mkdocs也提供静态资源包，可以将静态资源包通过服务器进行代理访问，比如通过Nginx进行代理 执行打包命令，会生成一个site文件夹，这个文件夹就是前端静态资源 mkdocs build --clean 使用Nginx进行静态资源代理，Nginx参考配置 server { # 客户端访问端口 listen 8000; # 客户端访问域名 server_name 127.0.0.1; # 静态资源根目录 root /Users/xxx/share/opensource/mkdocs-blog/site; gzip_types text/plain application/javascript text/css image/svg+xml; gzip_proxied no-cache no-store private expired auth; gzip_static on; #brotli_static on; gunzip on; location = / { index index.html; } } 总结mkdocs整体来说比hexo更加简单，也更加适合做帮助类网站的建站工具。 不过也有个明显的缺点就是目录不支持自动创建，需要手动进行维护，但是对于个人来说，这个不算是太严重的问题，因为写的文档需要放在某个目录下，自己应该是清楚的，只是做了一个配置而已。 在下一篇文章我将按照自己的理解，来讲讲如果是团队写作，使用mkdocs应该怎么进行协作，以及需要注意的点，敬请期待。","categories":[{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/categories/博客选型/"}],"tags":[{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/tags/博客选型/"}]},{"title":"hexo安装与配置","slug":"blog-hexo-install-configure","date":"2023-03-11T10:30:19.000Z","updated":"2024-07-01T12:30:37.346Z","comments":true,"path":"2023/03/11/blog-hexo-install-configure/","link":"","permalink":"http://iogogogo.github.io/2023/03/11/blog-hexo-install-configure/","excerpt":"","text":"最近产品在做帮助手册的编写，在技术选型上有几个大概的方向，倾向于开源或者自建搭建一套类似的写作平台，经过一周左右的调研，找了几个开源产品和于前端开发沟通，最终选择使用开源的工具进行建站写作，Nginx代理帮助静态资源展示。 其中核心的诉求有几个 写作简单，容易上手 可以支持协作，因为我们写作的人比较多 不要有数据库，因为有数据库就牵扯到后端服务比较麻烦 最终找的开源建站工具主要有：Hexo、GitBook、MkDocs、WordPress。 每一个工具都很优秀，下面做了一个简单对比（基于个人理解） 工具 特点 优点 缺点 hexo 基于nodejs，渲染Markdown文件展示 写作简单，编译和响应速度快 无明显短板，可能就是node版本坑比较多 gitbook 基于nodejs，渲染Markdown文件展示 写作简单 目录需要自己维护、node版本坑比较多、官网不维护停更 mkdocs 基于Python，渲染Markdown文件展示 写作简单，编译和响应速度快 目录需要自己维护 WordPress - - 需要数据库 下面先介绍一下hexo 什么是hexo官网地址：https://hexo.io/zh-cn/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 适用场景 hexo很优秀，作为个人写作博客应该算是比较方便的一个工具，目前我的博客就是基于hexo搭建的 但是hexo不太适合帮助类文档网站的构建 菜单结构单一，可定制性不强 协作不方便，虽然可以依赖git，但不是所有人都会使用git工具 图片处理不友好，最后找到了解决办法，所以这个不算是缺点了。 使用hexo建站hexo安装hexo依赖于nodejs，所以在按照hexo之前需要安装nodejs，从Node.js (nodejs.org)官网下载对应的安装包，安装即可。 Mac：下载pkg文件，双击下一步安装 Windows：下载exe文件，双击下一步安装 Linux：下载tar.zx安装包文件，解压安装配置环境变量 # 设置环境变量 echo 'export NODEJS_HOME=/opt/app/node-v18.14.0-linux-x64' >> /etc/profile echo 'export PATH=$NODEJS_HOME/bin:$PATH' >> /etc/profile source /etc/profile && node -v && npm -v 安装好node之后，安装hexo只需要执行以下命令即可 文档 | Hexo sudo npm install -g hexo-cli 安装完成之后，查看hexo版本，验证是否安装成功 ➜ ~ hexo version hexo-cli: 4.3.0 os: darwin 21.6.0 12.5 node: 13.14.0 v8: 7.9.317.25-node.32 uv: 1.37.0 zlib: 1.2.11 brotli: 1.0.7 ares: 1.16.0 modules: 79 nghttp2: 1.40.0 napi: 6 llhttp: 2.0.4 openssl: 1.1.1g cldr: 36.1 icu: 66.1 tz: 2019c unicode: 13.0 ➜ ~ 如果npm安装缓慢，可以设置一下淘宝的镜像源 # 设置淘宝镜像源 npm config set registry https://registry.npm.taobao.org # 还原配置 npm config set registry https://registry.npmjs.org 校验npm镜像源是否配置成功 # 配置之前 ➜ ~ npm config get registry https://registry.npmjs.org/ # 配置之后 ➜ ~ npm config set registry https://registry.npm.taobao.org ➜ ~ npm config get registry https://registry.npm.taobao.org/ ➜ ~ hexo建站 执行 hexo init blog，它会从github上拉取一个模板项目，有可能网络问题导致下载失败，可以试试直接下载模板压缩包文件自己解压也是可以的。 模板压缩包：https://github.com/hexojs/hexo-starter/archive/refs/heads/master.zip 进入blog目录，安装npm依赖，执行npm install 安装依赖文件 # 进入blog目录并安装npm依赖 cd blog && rm -rf node_modules && npm install --force 运行hexo s，就可以打开 http://localhost:8082/ 看到我们的第一个博客项目了 # -p 8082 指定端口为8082运行 hexo s -p 8082 hexo配置安装好hexo后下一步就是进行基础配置和写作了，下面介绍一些比较常用的插件和配置 常用插件 图片资源路径转换：npm install hexo-asset-img --save 可实现 Typora 等 Markdown 编辑器预览 与 Hexo 发布预览 均能正常显示图片 yiyungent/hexo-asset-img: 🍰 Hexo local image plugin. | Hexo 本地图片插件: 转换 图片相对路径 为 asset_img (github.com) 全局搜索：npm install hexo-generator-json-content --save 用于生成静态站点数据，提供搜索功能的数据源。 alexbruno/hexo-generator-json-content: Hexo (https://hexo.io/) plugin to generate a JSON file for generic use or consumption with the contents of posts and pages. (github.com) 更多介绍：Hexo博客常用插件及用法 | Cofess - Web Developer &amp; Designer 常用配置hexo-asset-img 插件搭配typora实现编辑于发布图片实时展示。 参考文档 Hexo + Typora + 开发Hexo插件 解决图片路径不一致 - 腾讯云开发者社区-腾讯云 (tencent.com) 资源文件夹 | Hexo hexo-renderer-marked 3.1.0 引入了一个新的选项，其允许你无需使用 asset_img 标签插件就可以在 markdown 中嵌入图片。 安装 hexo-asset-img 插件 hexo配置中将post_asset_folder开启 post_asset_folder: true typora进行以下配置： 通过以上配置之后，使用typora进行写作时，只需要将图片复制进文章，typora可以进行实时预览查看，在运行时也不需要关注图片资源路径，为写作带来很大的便利性。 其他配置hexo常用的就是主题相关配置了，快去找一个适合自己的主题并进行美化吧。Themes | Hexo 总结本文主要介绍了hexo建站和在写作时图片的处理方案，hexo作为博客日志类建站工具非常合适，入门简单学习成本也低。","categories":[{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/categories/博客选型/"}],"tags":[{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/tags/博客选型/"}]},{"title":"oh-my-zsh国内镜像安装和更新方法","slug":"china-mirrors-oh-my-zsh","date":"2021-07-05T15:43:13.000Z","updated":"2024-07-01T12:30:37.369Z","comments":true,"path":"2021/07/05/china-mirrors-oh-my-zsh/","link":"","permalink":"http://iogogogo.github.io/2021/07/05/china-mirrors-oh-my-zsh/","excerpt":"","text":"安装依赖 git zsh 安装gitCentOS 升级安装最新版git 下载码云安装包wget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh 编辑install.sh找到以下部分 # Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} 把 REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} 替换为 REPO=${REPO:-mirrors/oh-my-zsh} REMOTE=${REMOTE:-https://gitee.com/${REPO}.git} 编辑后保存, 运行安装即可. (运行前先给install.sh权限) 修改仓库地址cd ~/.oh-my-zsh git remote set-url origin https://gitee.com/mirrors/oh-my-zsh.git git pull oh-my-zsh升级omz update # 推荐使用 # 或者 upgrade_oh_my_zsh # 官方不推荐使用 原文地址: https://touka.dev/tech/oh-my-zsh-china-mirror/","categories":[{"name":"zsh","slug":"zsh","permalink":"http://iogogogo.github.io/categories/zsh/"}],"tags":[{"name":"zsh","slug":"zsh","permalink":"http://iogogogo.github.io/tags/zsh/"}]},{"title":"Spring Boot 2.x使用mybatis","slug":"spring-boot-mybatis","date":"2021-07-05T07:49:31.000Z","updated":"2024-07-01T12:41:05.759Z","comments":true,"path":"2021/07/05/spring-boot-mybatis/","link":"","permalink":"http://iogogogo.github.io/2021/07/05/spring-boot-mybatis/","excerpt":"","text":"orm框架的本质是简化编程中操作数据库的编码，现在我用的比较多的有两个，一个是宣称可以不用写一句SQL的hibernate，一个是可以灵活调试动态sql的mybatis,两者各有特点，在企业级系统开发中可以根据需求灵活使用。 使用注解版pom依赖这里使用最新版spring boot【2.0.4.RELEASE】 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.zz&lt;/groupId> &lt;artifactId>spring-boot-sample-mybatis&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;modules> &lt;module>mybatis-xml&lt;/module> &lt;module>mybatis-annotation&lt;/module> &lt;/modules> &lt;packaging>pom&lt;/packaging> &lt;name>spring-boot-sample-mybatis&lt;/name> &lt;description>spring-boot-sample-mybatis project for Spring Boot&lt;/description> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.0.4.RELEASE&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;properties> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;java.version>1.8&lt;/java.version> &lt;mybatis-spring.version>1.3.2&lt;/mybatis-spring.version> &lt;logback.version>1.2.3&lt;/logback.version> &lt;/properties> &lt;dependencies> &lt;!-- web组件 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;!-- mybatis-spring-boot-starter --> &lt;dependency> &lt;groupId>org.mybatis.spring.boot&lt;/groupId> &lt;artifactId>mybatis-spring-boot-starter&lt;/artifactId> &lt;version>${mybatis-spring.version}&lt;/version> &lt;/dependency> &lt;!-- MySQL 驱动--> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> application.yml文件spring: application: name: life-spring-sample-mybatis datasource: url: jdbc:mysql://localhost:10100/life-mybatis?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false driver-class-name: com.mysql.jdbc.Driver username: root password: root mybatis: type-aliases-package: com.zz.entity server: port: 8080 实体对象这里为了方便，使用了lombok，不了解的同学可以自己Google看一下 @Data @NoArgsConstructor @AllArgsConstructor public class Employee implements Serializable { private long id; private String name; private int age; private Date birthday; private int deptId; } mapper@Repository public interface EmployeeMapper { /** * 使用@Results注解做字段映射 * * @return */ @Select(\"select * from employee\") @Results({ @Result(property = \"deptId\", column = \"dept_id\") }) List&lt;Employee> findAll(); @Select(\"select * from employee where id=#{id}\") Employee findById(long id); @Update(\"update employee set name=#{name},birthday=#{birthday},age=#{age},dept_id=#{deptId} where id=#{id}\") int updateById(Employee employee); @Delete(\"delete from employee where id=#{id}\") int deleteById(long id); @Insert(\"insert into employee(name,birthday,age,dept_id) values(#{name},#{birthday},#{age},#{deptId})\") int save(Employee employee); } controller通过前端完成增删改查@Slf4j @RestController @RequestMapping(\"/api/emp\") public class EmployeeController { @Autowired private EmployeeMapper employeeMapper; @RequestMapping(\"/\") public List&lt;Employee> findAll() { List&lt;Employee> list = employeeMapper.findAll(); list.forEach(item -> log.info(\"emp:{}\", item)); return list; } @RequestMapping(\"/{id}\") public Employee findById(@PathVariable(\"id\") long id) { Employee employee = employeeMapper.findById(id); log.info(\"emp:{}\", employee); return employee; } @RequestMapping(value = \"/\", method = RequestMethod.POST) public int save(@RequestBody Employee employee) { return employeeMapper.save(employee); } @RequestMapping(value = \"/{id}\", method = RequestMethod.DELETE) public int deleteById(@PathVariable(\"id\") long id) { return employeeMapper.deleteById(id); } @RequestMapping(value = \"/{id}\", method = RequestMethod.PUT) public int updateById(@PathVariable(\"id\") long id, @RequestBody Employee employee) { employee.setId(id); return employeeMapper.updateById(employee); } } 运行项目以后就可以使用postman工具进行接口请求测试，对应的使用post、get、put等请求，可以自行测试 localhost:8080/api/emp/ response [ { \"id\": 1, \"name\": \"二丫\", \"age\": 16, \"birthday\": \"2000-01-01T00:00:00.000+0000\", \"deptId\": 1 }, { \"id\": 2, \"name\": \"小强 \", \"age\": 1, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 2 }, { \"id\": 3, \"name\": \"史塔克 \", \"age\": 11, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 3 }, { \"id\": 5, \"name\": \"君临城 \", \"age\": 8, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 4 }, { \"id\": 6, \"name\": \"乌鸦 \", \"age\": 8, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 1 }, { \"id\": 7, \"name\": \"龙母 \", \"age\": 4, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 4 }, { \"id\": 8, \"name\": \"提利昂 \", \"age\": 21, \"birthday\": \"2018-06-01T08:33:52.000+0000\", \"deptId\": 5 }, { \"id\": 9, \"name\": \"小花\", \"age\": 18, \"birthday\": \"2000-01-01T00:00:00.000+0000\", \"deptId\": 0 } ] 使用xml版前面我们可以看到，使用注解版的mybatis可以一行xml文件都不写，但是这个所有的sql都硬编码在mapper文件中，对后期的维护和复用不是特别方便，所有接下来我们看看使用xml完成增删改查 application.yml文件这里和使用注解的区别就是需要指定mapper文件的位置，为了方便我们还有一张dept表，这次使用dept表来进行演示 spring: application: name: life-spring-sample-mybatis datasource: url: jdbc:mysql://localhost:10100/life-mybatis?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false driver-class-name: com.mysql.jdbc.Driver username: root password: root mybatis: # 设置实体对象的位置 type-aliases-package: com.zz.entity # 设置mapper文件存放的位置，这里在classpath目录下的mybatis文件夹中 mapper-locations: classpath:mybatis/*.xml server: port: 8082 dept实体对象@Data @NoArgsConstructor @AllArgsConstructor public class Dept implements Serializable { private long id; private String name; } deptMapper对象可以看到，我们这里只有mapper接口中的方法声明，没有在上面进行注解操作，那么接下来我们就需要编写mapper.xml文件进行数据库操作，在resources/mybatis文件夹下新建DeptMapper.xml文件 @Repository public interface DeptMapper { int save(Dept dept); int deleteById(long id); int updateById(Dept dept); List&lt;Dept> findAll(); Dept findById(long id); } mapper.xml文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" > &lt;mapper namespace=\"com.zz.mapper.DeptMapper\"> &lt;sql id=\"base_column\"> &lt;/sql> &lt;insert id=\"save\"> insert into dept(name) values (#name) &lt;/insert> &lt;update id=\"updateById\"> update dept set name=#{name} where id=#{id} &lt;/update> &lt;delete id=\"deleteById\"> delete from dept where id=#{id} &lt;/delete> &lt;select id=\"findAll\" resultType=\"com.zz.entity.Dept\"> select * from dept &lt;/select> &lt;select id=\"findById\" resultType=\"com.zz.entity.Dept\"> select * from dept where id=#{id} &lt;/select> &lt;/mapper> 控制器对象这里只是为了演示使用xml操作，controller中就不一一写出所有的接口，其实和使用注解完全是一样的 @RestController @RequestMapping(\"/api/dept\") public class DeptController { @Autowired private DeptMapper deptMapper; @GetMapping(\"/\") public List&lt;Dept> findAll() { return deptMapper.findAll(); } } 这里使用postman工具进行简单的测试，可以看到所有的部门数据全部被查出来了 localhost:8082/api/dept/ response [ { \"id\": 1, \"name\": \"信息技术部\" }, { \"id\": 2, \"name\": \"人事部\" }, { \"id\": 3, \"name\": \"PCB事业部\" }, { \"id\": 4, \"name\": \"无线终端部\" }, { \"id\": 5, \"name\": \"测试部\" }, { \"id\": 6, \"name\": \"后勤保障部\" }, { \"id\": 7, \"name\": \"鸡犬不宁部\" } ] 总结 其实使用spring boot-1.x版本和2.x版本操作基本是一致的 注解方便单表的操作，xml适用于复杂的操作，各有优点，没有最好的，只有最合适的 完整代码链接github 参考mybatis","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"MySQL时间戳和时间的获取/相互转换/格式化","slug":"mysql-datetime-func","date":"2021-06-23T15:39:37.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2021/06/23/mysql-datetime-func/","link":"","permalink":"http://iogogogo.github.io/2021/06/23/mysql-datetime-func/","excerpt":"","text":"MySQL时间戳和时间的获取/相互转换/格式化获取当前时间戳mysql> select unix_timestamp(now()); +-----------------------+ | unix_timestamp(now()) | +-----------------------+ | 1584524789 | +-----------------------+ 1 row in set (0.00 sec) mysql> select unix_timestamp(); +------------------+ | unix_timestamp() | +------------------+ | 1584524524 | +------------------+ 1 row in set (0.00 sec) 获取当前时间mysql> select now(); +---------------------+ | now() | +---------------------+ | 2020-03-18 17:39:13 | +---------------------+ 1 row in set (0.00 sec) mysql> select date(now()); +-------------+ | date(now()) | +-------------+ | 2020-03-18 | +-------------+ 1 row in set (0.00 sec) 获取三天前的时间mysql> SELECT NOW() - interval 72 hour; +--------------------------+ | NOW() - interval 72 hour | +--------------------------+ | 2020-03-15 17:39:44 | +--------------------------+ 1 row in set (0.00 sec) 时间转时间戳mysql> select unix_timestamp('2018-01-15 09:45:16'); +---------------------------------------+ | unix_timestamp('2018-01-15 09:45:16') | +---------------------------------------+ | 1515980716 | +---------------------------------------+ 1 row in set (0.00 sec) 时间戳转时间mysql> select from_unixtime(1515980716); +---------------------------+ | from_unixtime(1515980716) | +---------------------------+ | 2018-01-15 09:45:16 | +---------------------------+ 1 row in set (0.02 sec) 时间戳格式化mysql> SELECT from_unixtime(1515980716, '%Y-%m-%d %H:%i:%S'); +------------------------------------------------+ | from_unixtime(1515980716, '%Y-%m-%d %H:%i:%S') | +------------------------------------------------+ | 2018-01-15 09:45:16 | +------------------------------------------------+ 1 row in set (0.00 sec) 时间格式化mysql> select date_format(now(), '%Y-%m-%d'); +--------------------------------+ | date_format(now(), '%Y-%m-%d') | +--------------------------------+ | 2020-03-18 | +--------------------------------+ 1 row in set (0.00 sec) mysql> select date_format('2018-01-15 09:45:16', '%Y-%m-%d'); +------------------------------------------------+ | date_format('2018-01-15 09:45:16', '%Y-%m-%d') | +------------------------------------------------+ | 2018-01-15 | +------------------------------------------------+ 1 row in set (0.00 sec) 函数说明FROM_UNIXTIME作用：将MySQL中以INT(11)存储的时间以”YYYY-MM-DD”格式来显示。 语法：FROM_UNIXTIME(unix_timestamp,format) 返回表示 Unix 时间标记的一个字符串，根据format字符串格式化。format可以包含与DATE_FORMAT()函数列出的条目同样的修饰符。 date_format作用：将MySQL中的日期格式转换成”YYYY-MM-DD”格式来显示。 语法：date_format(now(), ‘%Y-%m-%d’); 根据format字符串格式化date值，下列修饰符可以被用在format字符串中 表达式 含义 %M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"Java8 list分页","slug":"java8-list-partition","date":"2021-04-11T07:57:20.000Z","updated":"2024-07-01T12:30:37.373Z","comments":true,"path":"2021/04/11/java8-list-partition/","link":"","permalink":"http://iogogogo.github.io/2021/04/11/java8-list-partition/","excerpt":"","text":"日常开发中经常遇到list分页的需求，在Java8之前都是使用subList进行截取，在Java8以后，有了新的选择，那就是使用stream，原理很简单，就是使用stream提供的skip和limit方法。 这里的ListUtils是一个接口，在Java8之前接口不能有方法实现，在Java8以后，接口中可以存在static方法并且完成方法实现，另外也可以使用default关键字来完成一个方法实现，可以省略我们写public static关键字（目前没发现其他好处😂） 封装工具类package com.iogogogo.util; import lombok.Data; import java.io.Serializable; import java.util.Collections; import java.util.List; import java.util.stream.Collectors; /** * Created by tao.zeng on 2021/4/8. */ public interface ListUtils { static &lt;T> PageWrapper&lt;T> partition(int pageNo, int pageSize, List&lt;T> records) { if (pageNo &lt;= 0) pageNo = 1; // 计算偏移量 int offset = (pageNo - 1) * pageSize; // 总算总记录数 int totalSize = records.size(); if (offset > totalSize) return new PageWrapper&lt;>(pageNo, pageSize, totalSize, Collections.emptyList()); // 分页结果数据 List&lt;T> collect = records.stream().skip(offset).limit(pageSize).collect(Collectors.toList()); return new PageWrapper&lt;>(pageNo, pageSize, totalSize, collect); } /** * The type Page wrapper. * * @param &lt;T> the type parameter */ /* *public static void main(String[] args) { int totalSize = 11;//数据总量 int pageSize = 3;//一页显示条数 int totalPage;//总页数 // 几种页数计算方法 totalPage = totalSize / pageSize; if (totalSize % pageSize != 0) { totalPage++; } System.out.println(totalPage);//此方法容易理解 System.out.println((totalSize - 1) / pageSize + 1);//此方法使用较多 System.out.println((totalSize + pageSize - 1) / pageSize); } */ @Data class PageWrapper&lt;T> implements Serializable { /** * 当前页，每页显示size */ private int pageNo, pageSize; /** * 总记录数，总页数 */ private long totalSize, totalPage; /** * 分页结果数据 */ private List&lt;T> records; /** * Instantiates a new Page wrapper. * * @param pageNo the page no * @param pageSize the page size * @param totalSize the total size * @param records the records */ public PageWrapper(int pageNo, int pageSize, long totalSize, List&lt;T> records) { this.setPageNo(pageNo); this.pageSize = pageSize; this.records = records; this.totalSize = totalSize; this.totalPage = (totalSize - 1) / pageSize + 1; } /** * Sets page no. * * @param pageNo the page no */ public void setPageNo(int pageNo) { if (pageNo &lt;= 0) this.pageNo = 1; this.pageNo = pageNo; } } } 单元测试package com.iogogogo.util; import org.junit.jupiter.api.Assertions; import org.junit.jupiter.api.Test; import java.util.ArrayList; import java.util.List; import java.util.UUID; /** * Created by tao.zeng on 2021/4/11. */ class ListUtilsTest { @Test public void test() { List&lt;String> list = new ArrayList&lt;>(); for (int i = 0; i &lt; 20; i++) { list.add(UUID.randomUUID().toString()); } ListUtils.PageWrapper&lt;String> wrapper = ListUtils.partition(0, 5, list); Assertions.assertEquals(wrapper.getPageNo(), 1); Assertions.assertEquals(wrapper.getPageSize(), 5); Assertions.assertEquals(wrapper.getTotalPage(), 4); Assertions.assertEquals(wrapper.getRecords().size(), 5); wrapper = ListUtils.partition(30, 20, list); Assertions.assertEquals(wrapper.getPageNo(), 30); Assertions.assertEquals(wrapper.getPageSize(), 20); Assertions.assertEquals(wrapper.getTotalPage(), 1); Assertions.assertEquals(wrapper.getRecords().size(), 0); } }","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"使用Java8实现常用日期解析封装","slug":"java8-date-parser","date":"2021-04-02T13:06:32.000Z","updated":"2024-07-01T12:30:37.373Z","comments":true,"path":"2021/04/02/java8-date-parser/","link":"","permalink":"http://iogogogo.github.io/2021/04/02/java8-date-parser/","excerpt":"","text":"项目上做ELT数据清洗的时候，经常会遇到各种各样的日期格式，使用logstash解析日期是可以指定多个pattern，logstash会按照顺序按个去匹配，直到匹配上则返回，自己写数据处理的时候，也有类似的需求，看了下logstash关于日期解析处理的源码，主要是使用joda-time这个库完成的，在Java8以后，也有类似的日期处理api，下面使用Java8自带的api实现一个简单的封装，整体思路和logstash处理日期的是一样的，通过工厂类，创建出不同的解析器，通过具体的解析器针对pattern进行匹配。 没有什么太复杂的业务逻辑，直接看代码，代码注释也比较全面。 代码地址入口：Java8DateTimeUtils Java8DateTimeUtilspackage com.github.iogogogo.common.util; import com.github.iogogogo.common.util.parser.TimestampParser; import com.github.iogogogo.common.util.parser.TimestampParserFactory; import com.github.iogogogo.common.util.parser.impl.UnixEpochParser; import com.github.iogogogo.common.util.parser.impl.UnixMillisEpochParser; import io.vavr.Tuple; import io.vavr.Tuple2; import lombok.extern.slf4j.Slf4j; import org.apache.commons.collections4.CollectionUtils; import org.apache.commons.lang3.StringUtils; import java.time.Instant; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.ZoneId; import java.time.format.DateTimeFormatter; import java.util.Date; import java.util.List; import java.util.Locale; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; import java.util.stream.Stream; /** * The type Java 8 date time utils. */ @Slf4j public class Java8DateTimeUtils { /** * Now date time local date time. * * @return the local date time */ public static LocalDateTime nowDateTime() { return LocalDateTime.now(); } /** * Now date local date. * * @return the local date */ public static LocalDate nowDate() { return LocalDate.now(); } /** * Try parse local date time. * * @param value the value * @param locale the locale * @param pattern the pattern * @return the local date time */ public static LocalDateTime tryParse(String value, Locale locale, List&lt;String> pattern) { if (StringUtils.isEmpty(value)) throw new NullPointerException(\"value is not null.\"); TimestampParser timestampParser = TimestampParserFactory.makeParser(value); if (timestampParser instanceof UnixEpochParser || timestampParser instanceof UnixMillisEpochParser) { return timestampParser.parse(null); } else { boolean flag; List&lt;String> patterns = pattern.stream().filter(StringUtils::isNotEmpty).collect(Collectors.toList()); List&lt;String> collect = (flag = CollectionUtils.isNotEmpty(patterns)) ? patterns : TimestampParser.PATTERN_LIST; List&lt;DateTimeFormatter> timeFormatters = collect.stream() .peek(x -> { if (log.isDebugEnabled()) log.debug(\"init {} parser ofPattern: {}\", flag ? \"customer\" : \"system\", x); }).map(x -> DateTimeFormatter.ofPattern(x, locale)).collect(Collectors.toList()); return timestampParser.parse(timeFormatters); } } /** * Try parse local date time. * * @param value the value * @param locale the locale * @param pattern the pattern * @return the local date time */ public static LocalDateTime tryParse(String value, Locale locale, String... pattern) { return tryParse(value, locale, Stream.of(pattern).collect(Collectors.toList())); } /** * Try parse local date time. * * @param value the value * @param pattern the pattern * @return the local date time */ public static LocalDateTime tryParse(String value, List&lt;String> pattern) { return tryParse(value, Locale.CHINA, pattern); } /** * Try parse local date time. * * @param value the value * @param pattern the pattern * @return the local date time */ public static LocalDateTime tryParse(String value, String... pattern) { return tryParse(value, Stream.of(pattern).collect(Collectors.toList())); } /** * To instant instant. * * @param localDateTime the local date time * @return the instant */ public static Instant toInstant(LocalDateTime localDateTime) { ZoneId zone = ZoneId.systemDefault(); return localDateTime.atZone(zone).toInstant(); } /** * To epoch milli long. * * @param localDateTime the local date time * @return the long */ public static long toEpochMilli(LocalDateTime localDateTime) { return toInstant(localDateTime).toEpochMilli(); } /** * To epoch second long. * * @param localDateTime the local date time * @return the long */ public static long toEpochSecond(LocalDateTime localDateTime) { return toInstant(localDateTime).toEpochMilli() / 1000; } /** * Of epoch milli instant. * * @param millis the millis * @return the instant */ public static Instant ofEpochMilli(long millis) { return Instant.ofEpochMilli(millis); } /** * Of epoch second instant. * * @param second the second * @return the instant */ public static Instant ofEpochSecond(long second) { return Instant.ofEpochSecond(second); } /** * To java 8 millis local date time. * * @param timestamp the timestamp * @return the local date time */ public static LocalDateTime toJava8Millis(long timestamp) { return toJava8(ofEpochMilli(timestamp)); } /** * To java 8 second local date time. * * @param timestamp the timestamp * @return the local date time */ public static LocalDateTime toJava8Second(long timestamp) { return toJava8(ofEpochSecond(timestamp * 1000)); } /** * To java 8 local date time. * * @param instant the instant * @return the local date time */ public static LocalDateTime toJava8(Instant instant) { ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone); } /** * To java 8 local date time. * * @param date the date * @return the local date time */ public static LocalDateTime toJava8(Date date) { return toJava8(date.toInstant()); } /** * Millis convert tuple 2. * * @param value the value * @param unit the unit * @return the tuple 2 */ public static Tuple2&lt;Long, String> millisConvert(long value, String unit) { return convert(value, unit, \"MS\"); } /** * Convert tuple 2. * * @param value the value * @param srcUnit the src unit * @param targetUnit the target unit * @return the tuple 2 */ public static Tuple2&lt;Long, String> convert(long value, String srcUnit, String targetUnit) { long result; TimeUnit timeUnit = getUnit(targetUnit); switch (srcUnit.toUpperCase()) { case \"SECONDS\": result = TimeUnit.SECONDS.convert(value, timeUnit); return Tuple.of(result, String.format(\"%d%s\", result, \"秒\")); case \"MINUTES\": result = TimeUnit.MINUTES.convert(value, timeUnit); return Tuple.of(result, String.format(\"%d%s\", result, \"分钟\")); case \"HOURS\": result = TimeUnit.HOURS.convert(value, timeUnit); return Tuple.of(result, String.format(\"%d%s\", result, \"小时\")); case \"DAYS\": result = TimeUnit.DAYS.convert(value, timeUnit); return Tuple.of(result, String.format(\"%d%s\", result, \"天\")); case \"MS\": case \"MILLIS\": case \"MILLISECONDS\": default: result = value; return Tuple.of(result, String.format(\"%d%s\", result, \"毫秒\")); } } /** * To millis long. * * @param value the value * @param unit the unit * @return the long */ public static Long toMillis(long value, String unit) { switch (unit.toUpperCase()) { case \"SECONDS\": return TimeUnit.SECONDS.toMillis(value); case \"MINUTES\": return TimeUnit.MINUTES.toMillis(value); case \"HOURS\": return TimeUnit.HOURS.toMillis(value); case \"DAYS\": return TimeUnit.DAYS.toMillis(value); case \"MS\": case \"MILLIS\": case \"MILLISECONDS\": default: return value; } } /** * Gets unit. * * @param unit the unit * @return the unit */ public static TimeUnit getUnit(String unit) { switch (unit.toUpperCase()) { case \"SECONDS\": return TimeUnit.SECONDS; case \"MINUTES\": return TimeUnit.MINUTES; case \"HOURS\": return TimeUnit.HOURS; case \"DAYS\": return TimeUnit.DAYS; case \"MS\": case \"MILLIS\": case \"MILLISECONDS\": default: return TimeUnit.MILLISECONDS; } } } TimestampParserFactorypackage com.github.iogogogo.common.util.parser; import com.github.iogogogo.common.util.parser.impl.LocalDateTimeParser; import com.github.iogogogo.common.util.parser.impl.UnixEpochParser; import com.github.iogogogo.common.util.parser.impl.UnixMillisEpochParser; import org.apache.commons.lang3.math.NumberUtils; /** * Created by tao.zeng on 2021/3/26. */ public class TimestampParserFactory { private final static int UNIX_LENGTH = 10, UNIX_MS_LENGTH = 13; /** * Make parser timestamp parser. * * @param value the value * @return the timestamp parser */ public static TimestampParser makeParser(String value) { if (NumberUtils.isCreatable(value)) { long longValue = NumberUtils.createNumber(value).longValue(); int length = Long.toString(longValue).length(); if (length == UNIX_LENGTH) { return new UnixEpochParser(longValue); } else if (length == UNIX_MS_LENGTH) { return new UnixMillisEpochParser(longValue); } } return new LocalDateTimeParser(value); } } TimestampParserpackage com.github.iogogogo.common.util.parser; import com.fasterxml.jackson.core.type.TypeReference; import com.google.common.collect.Lists; import com.github.iogogogo.common.util.JsonParse; import org.apache.commons.lang3.StringUtils; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.List; /** * Created by tao.zeng on 2021/3/26. */ public interface TimestampParser { /** * The constant PATTERN_LIST. */ List&lt;String> PATTERN_LIST = StringUtils.isNotEmpty(System.getProperty(\"iogogogo.ts.parse.pattern\", \"\")) ? JsonParse.tryParse(System.getProperty(\"iogogogo.ts.parse.pattern\", \"\"), new TypeReference&lt;List&lt;String>>() { }) : defaultPattern(); /** * Default pattern list. * * @return the list */ static List&lt;String> defaultPattern() { return Lists.newArrayList( \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\", // 2020-08-13T08:59:59.904Z \"yyyy-MM-dd HH:mm:ss:SSSSSS\", // 2020-08-13 08:59:59:904001 \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\", // 2020-08-13T08:59:59.904+08:00 \"yyyy-MM-dd HH:mm:ss:SSSSSS\", // 2020-08-13 08:59:59:904001 \"yyyy-MM-dd HH:mm:ss\", // 2020-08-13 08:59:59 \"yyyy-MM-dd HH:mm:ss.SSSZ\", \"yyyy-MM-dd HH:mm:ss.SSS\", \"yyyy-MM-dd HH:mm:ss,SSSZ\", \"yyyy-MM-dd HH:mm:ss,SSS\" ); } /** * Parse local date time. * * @param pattern the pattern * @return the local date time */ LocalDateTime parse(List&lt;DateTimeFormatter> pattern); } LocalDateTimeParserpackage com.github.iogogogo.common.util.parser.impl; import com.github.iogogogo.common.util.parser.TimestampParser; import lombok.extern.slf4j.Slf4j; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.time.format.DateTimeParseException; import java.util.List; import java.util.Objects; /** * Created by tao.zeng on 2021/3/29. */ @Slf4j public class LocalDateTimeParser implements TimestampParser { private final String value; public LocalDateTimeParser(String value) { this.value = value; } @Override public LocalDateTime parse(List&lt;DateTimeFormatter> pattern) { DateTimeParseException lastException = null; LocalDateTime dateTime = null; try { dateTime = LocalDateTime.parse(value); } catch (DateTimeParseException e) { lastException = e; for (DateTimeFormatter formatter : pattern) { try { dateTime = LocalDateTime.parse(value, formatter); log.info(\"match formatter:{}\", formatter); break; } catch (DateTimeParseException ex) { ex.addSuppressed(e); lastException = ex; } } } if (Objects.nonNull(dateTime)) return dateTime; throw lastException; } } UnixEpochParser package com.github.iogogogo.common.util.parser.impl; import com.github.iogogogo.common.util.Java8DateTimeUtils; import com.github.iogogogo.common.util.parser.TimestampParser; import java.time.Instant; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.List; /** * Created by tao.zeng on 2021/3/29. */ public class UnixEpochParser implements TimestampParser { private final static long MAX_EPOCH_SECONDS = Integer.MAX_VALUE; private final long value; public UnixEpochParser(long value) { this.value = value; } @Override public LocalDateTime parse(List&lt;DateTimeFormatter> pattern) { if (value > MAX_EPOCH_SECONDS) { throw new IllegalArgumentException(\"Cannot parse date for value larger than UNIX epoch maximum seconds\"); } Instant instant = Java8DateTimeUtils.ofEpochSecond(value); return Java8DateTimeUtils.toJava8(instant); } } UnixMillisEpochParser package com.github.iogogogo.common.util.parser.impl; import com.github.iogogogo.common.util.Java8DateTimeUtils; import com.github.iogogogo.common.util.parser.TimestampParser; import java.time.Instant; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.List; /** * Created by tao.zeng on 2021/3/29. */ public class UnixMillisEpochParser implements TimestampParser { private final static long MAX_EPOCH_MILLISECONDS = (long) Integer.MAX_VALUE * 1000; private final long value; public UnixMillisEpochParser(long value) { this.value = value; } @Override public LocalDateTime parse(List&lt;DateTimeFormatter> pattern) { if (value > MAX_EPOCH_MILLISECONDS) { throw new IllegalArgumentException(\"Cannot parse date for value larger than UNIX epoch maximum seconds\"); } Instant instant = Java8DateTimeUtils.ofEpochMilli(value); return Java8DateTimeUtils.toJava8(instant); } } 单元测试package com.github.iogogogo; import com.github.iogogogo.common.util.Java8DateTimeUtils; import org.junit.Assert; import org.junit.Test; import java.time.LocalDateTime; import java.util.Date; import java.util.concurrent.TimeUnit; /** * Created by tao.zeng on 2021/4/2. */ public class DateTimeTests { @Test public void test() { String date = \"2020-08-13T08:59:59.904Z\"; LocalDateTime dateTime = Java8DateTimeUtils.tryParse(date); Assert.assertEquals(\"2020-08-13T08:59:59.904\", dateTime.toString()); date = \"2020-08-13 08:59:59:904001\"; dateTime = Java8DateTimeUtils.tryParse(date); Assert.assertEquals(\"2020-08-13T08:59:59.904001\", dateTime.toString()); date = \"2020-08-13T08:59:59.904+08:00\"; dateTime = Java8DateTimeUtils.tryParse(date); Assert.assertEquals(\"2020-08-13T08:59:59.904\", dateTime.toString()); date = \"2020-08-13 08:59:59\"; dateTime = Java8DateTimeUtils.tryParse(date); Assert.assertEquals(\"2020-08-13T08:59:59\", dateTime.toString()); dateTime = LocalDateTime.of(2020, 8, 13, 0, 0); long milli = Java8DateTimeUtils.toEpochMilli(dateTime); Assert.assertEquals(Java8DateTimeUtils.toJava8(new Date(milli)), dateTime); dateTime = Java8DateTimeUtils.tryParse(String.valueOf(milli)); Assert.assertEquals(\"2020-08-13T00:00\", dateTime.toString()); /* ********** 自定义pattern解析********** */ date = \"2021/08/13 08:59:59\"; dateTime = Java8DateTimeUtils.tryParse(date, \"yyyy/MM/dd HH:mm:ss\"); Assert.assertEquals(\"2021-08-13T08:59:59\", dateTime.toString()); date = \"2021/08/13 08-59-59\"; dateTime = Java8DateTimeUtils.tryParse(date, \"yyyy/MM/dd HH:mm:ss\", \"yyyy/MM/dd HH-mm-ss\"); Assert.assertEquals(\"2021-08-13T08:59:59\", dateTime.toString()); date = \"2021/08/13 08.59.59\"; dateTime = Java8DateTimeUtils.tryParse(date, \"yyyy/MM/dd HH:mm:ss\", \"yyyy/MM/dd HH-mm-ss\", \"yyyy/MM/dd HH.mm.ss\"); Assert.assertEquals(\"2021-08-13T08:59:59\", dateTime.toString()); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"\"), TimeUnit.MILLISECONDS); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"MS\"), TimeUnit.MILLISECONDS); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"MILLIS\"), TimeUnit.MILLISECONDS); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"MILLISECONDS\"), TimeUnit.MILLISECONDS); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"MINUTES\"), TimeUnit.MINUTES); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"HOURS\"), TimeUnit.HOURS); Assert.assertEquals(Java8DateTimeUtils.getUnit(\"DAYS\"), TimeUnit.DAYS); long i = 2 * 60 * 1000L; Assert.assertEquals(120000L, (long) Java8DateTimeUtils.millisConvert(i, TimeUnit.MILLISECONDS.name())._1); Assert.assertEquals(120, (long) Java8DateTimeUtils.millisConvert(i, TimeUnit.SECONDS.name())._1); Assert.assertEquals(2, (long) Java8DateTimeUtils.millisConvert(i, TimeUnit.MINUTES.name())._1); Assert.assertEquals(0, (long) Java8DateTimeUtils.millisConvert(i, TimeUnit.DAYS.name())._1); i = 2; Assert.assertEquals(2, (long) Java8DateTimeUtils.toMillis(i, TimeUnit.MILLISECONDS.name())); Assert.assertEquals(2000, (long) Java8DateTimeUtils.toMillis(i, TimeUnit.SECONDS.name())); Assert.assertEquals(120000, (long) Java8DateTimeUtils.toMillis(i, TimeUnit.MINUTES.name())); Assert.assertEquals(172800000, (long) Java8DateTimeUtils.toMillis(i, TimeUnit.DAYS.name())); } }","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"Gitee Pages服务自动更新","slug":"giee-hexo-auto-update","date":"2021-04-02T01:46:26.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2021/04/02/giee-hexo-auto-update/","link":"","permalink":"http://iogogogo.github.io/2021/04/02/giee-hexo-auto-update/","excerpt":"","text":"参考地址1：【Hexo】Gitee Pages服务自动更新 参考地址2：解决 gitee page 无法自动更新","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://iogogogo.github.io/tags/hexo/"}]},{"title":"使用Java计算cron最近执行周期","slug":"java-cron-calc-cycle","date":"2021-04-02T01:32:27.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2021/04/02/java-cron-calc-cycle/","link":"","permalink":"http://iogogogo.github.io/2021/04/02/java-cron-calc-cycle/","excerpt":"","text":"项目中使用cron表达式来作为定时调度的参数，又需要根据执行的周期来计算一些平均数据，所以需要根据cron表达式获取执行周期。 quartz 可以实现获取最近几次执行周期，但是如果没有quartz依赖又需要引入不必要依赖。 spring 5.3 以上提供了 CronExpression，可以用来实现该需求。 使用quartz获取最近执行的时间 /** * &lt;dependency> * &lt;groupId>org.quartz-scheduler&lt;/groupId> * &lt;artifactId>quartz&lt;/artifactId> * &lt;/dependency> * */ import org.quartz.TriggerUtils; import org.quartz.impl.triggers.CronTriggerImpl; import org.quartz.spi.OperableTrigger; /** * Latest list. * &lt;p> * String cron = \"0 0/2 * * * ?\"; * * @param cron the cron * @param count the count * @return the list * @throws ParseException the parse exception */ public static List&lt;LocalDateTime> latest(String cron, int count) throws ParseException { CronTriggerImpl cronTriggerImpl = new CronTriggerImpl(); // 设置cron表达式 cronTriggerImpl.setCronExpression(cron); // 根据count获取最近执行时间 List&lt;Date> dateList = TriggerUtils.computeFireTimes(cronTriggerImpl, null, count); return dateList.stream().map(Java8DateTimeUtils::toJava8).collect(Collectors.toList()); } 使用spring-context获取最近执行时间获取cron当前次执行时间和前后次执行时间import org.springframework.scheduling.support.CronExpression; import java.time.Duration; import java.time.LocalDateTime; /** * Nearby local date time. * &lt;p> * 获取cron当前次执行时间和前后次执行时间 * &lt;p> * String cron = \"0 0/2 * * * ?\"; * * @param cron the cron * @return local date time */ public static Tuple3&lt;LocalDateTime, LocalDateTime, LocalDateTime> nearby(String cron) { // 转换成cron表达式 CronExpression cronExpression = CronExpression.parse(cron); // 下一次执行时间 LocalDateTime next = cronExpression.next(LocalDateTime.now()); Objects.requireNonNull(next); // 两次间隔时间 long between = Duration.between(next, cronExpression.next(next)).getSeconds(); // 当前次执行时间 LocalDateTime current = next.minusSeconds(between); // 上一次执行时间 LocalDateTime previous = current.minusSeconds(between); log.info(\"now:{} previous:{} current:{} next:{}\", Java8DateTimeUtils.nowDateTime(), previous, current, next); return Tuple.of(previous, current, next); } 获取最近几次的执行时间 /** * Nearby list. * &lt;p> * 按照count获取最近几次执行时间 * * @param cron the cron * @param isAfter the is after * @param count the count * @return the list */ public static List&lt;LocalDateTime> nearby(String cron, boolean isAfter, int count) { // 转换成cron表达式 CronExpression cronExpression = CronExpression.parse(cron); // 下一次预计执行时间 LocalDateTime nextFirst = cronExpression.next(LocalDateTime.now()); Objects.requireNonNull(nextFirst); // 下下次预计执行时间 LocalDateTime nextSecond = cronExpression.next(nextFirst); // 两次执行间隔 long between = ChronoUnit.SECONDS.between(nextFirst, nextSecond); List&lt;LocalDateTime> dateTimes = Lists.newArrayList(); int i = 0; while (i++ &lt; count) { Objects.requireNonNull(nextSecond); nextFirst = isAfter ? nextFirst.plusSeconds(between) : nextFirst.minusSeconds(between); dateTimes.add(nextFirst); } return dateTimes; } 【参考】java通过cron表达式来获取执行的周期原文链接：https://www.codeleading.com/article/42705195442/#_17 1、计算固定的周期通过下次执行时间和下下次执行时间之差计算 /** * 根据cron表达式获取执行周期 */ @Test public void getPeriodByCron() { //30s执行一次 String cron = \"0/30 * * * * ?\"; //spring @since 5.3 CronExpression cronExpression = CronExpression.parse(cron); //下次预计的执行时间 LocalDateTime nextFirst = cronExpression.next(LocalDateTime.now()); //下下次预计的执行时间 LocalDateTime nextSecond = cronExpression.next(nextFirst); //计算周期1 long between1 = ChronoUnit.SECONDS.between(nextFirst, nextSecond); Assert.assertEquals(between1, 30); //计算周期2 long between2 = Duration.between(nextFirst, nextSecond).getSeconds(); Assert.assertEquals(between2, 30); } 2、计算多个周期不固定的周期，获取最近几次的预定执行时间 @Test public void getEveryPeriodByCron() { List&lt;Long> periods = Lists.newArrayList(); //每小时的前5分钟每分钟执行一次，这种周期不是固定的 String cron = \"0 0,1,2,3,4,5 * * * ? \"; //spring @since 5.3 CronExpression cronExpression = CronExpression.parse(cron); //下次预计的执行时间 LocalDateTime prevTime = cronExpression.next(LocalDateTime.now()); int i = 0; while (i++ &lt; 10) { Objects.requireNonNull(prevTime); LocalDateTime nextTime = cronExpression.next(prevTime); long between = ChronoUnit.SECONDS.between(prevTime, nextTime); prevTime = nextTime; periods.add(between); } System.out.println(ArrayUtils.toString(periods)); }","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"cron","slug":"cron","permalink":"http://iogogogo.github.io/tags/cron/"}]},{"title":"logstash修改默认时区为东八区","slug":"logstash-compile-md","date":"2020-12-19T02:46:41.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2020/12/19/logstash-compile-md/","link":"","permalink":"http://iogogogo.github.io/2020/12/19/logstash-compile-md/","excerpt":"","text":"上一篇文章我们讲了logstash-filter-date插件怎么支持纳秒并且进行编译，最后提到了一个时区问题，我们说说logstash默认的时区问题，这里主要涉及两个类 org.logstash.StringInterpolation org.logstash.Timestamp 整体的思路和编译logstash-filter-date插件类似，主要就是修改以上两个类的时区，然后在编译即可。 依赖安装 下载源代码 修改源码 网络问题造成下载失败或者缓慢解决方案 构建snapshot package 使用snapshot package测试时区问题 依赖安装 gradle 根据项目gradle/wrapper/gradle-wrapper.properties下载gradle-x.x.x-bin.zip，放在~/.gradle/wrapper/dists/gradle-6.5.1-bin/1m5048aptkfynhbvolwgr4ej9/ https://services.gradle.org/distributions/ ruby jruby rvm rbenv https://rubygems.org/ 下载源代码cd ~/share/tmp # 如果嫌弃下载的慢，可以使用gitee进行导入，然后根据gitee的地址下载 git clone https://github.com/elastic/logstash # 根据tag切换到7.9.3分支 git checkout -b v7.9.3 v7.9.3 网络问题造成下载失败或者缓慢解决方案jruby-complete-9.2.13.0.jar这个包下载会比较慢，可以使用下载工具下载，让将jruby-complete-9.2.13.0.jar放在~/.gradle/caches/modules-2/files-2.1/org.jruby/jruby-complete/9.2.13.0/xxx目录下。 cd ~/share/tmp wget https://repo.maven.apache.org/maven2/org/jruby/jruby-complete/9.2.13.0/jruby-complete-9.2.13.0.jar jruby-dist-9.2.13.0-bin.tar.gz这个包每次编译时会用到，下载也比较慢，可以使用下载工具提前下载好，然后放在$LOGSTASH_HOME/vendor/_/下 cd ~/share/tmp wget https://repo1.maven.org/maven2/org/jruby/jruby-dist/9.2.13.0/jruby-dist-9.2.13.0-bin.tar.gz # 根据实际路径自行替换 cp ~/share/tmp/jruby-dist-9.2.13.0-bin.tar.gz vendor/_ 修改源码org.logstash.StringInterpolation该类需要修改org.logstash.StringInterpolation#evaluate(Event, String)方法 // 修改前 builder.append(t != null ? event.getTimestamp().getTime().toString( DateTimeFormat.forPattern(template.substring(open + 3, close)) .withZone(DateTimeZone.UTC)) : \"\" ); // 修改后，将UTC时区改为东八区 builder.append(t != null ? event.getTimestamp().getTime().toString( DateTimeFormat.forPattern(template.substring(open + 3, close)) .withZone(DateTimeZone.forID(\"+08:00\"))) : \"\" ); org.logstash.Timestamp该类需要修改一个常量，也是将UTC时区改为东八区 // 修改前 private static final Chronology UTC_CHRONOLOGY = ISOChronology.getInstance(DateTimeZone.UTC); // 修改后 private static final Chronology UTC_CHRONOLOGY = ISOChronology.getInstance(DateTimeZone.forID(\"+08:00\")); 构建snapshot packageBuilding Logstashrake bootstrap Building Artifacts# cd $LOGSTASH_HOME ./gradlew assembleTarDistribution 编译日志➜ logstash git:(v7.9.3) ✗ ./gradlew assembleTarDistribution To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: https://docs.gradle.org/6.5.1/userguide/gradle_daemon.html. Daemon will be stopped at the end of the build stopping after processing > Task :downloadJRuby UP-TO-DATE Download https://repo1.maven.org/maven2/org/jruby/jruby-dist/9.2.13.0/jruby-dist-9.2.13.0-bin.tar.gz > Task :logstash-core:compileJava 注: Processing Log4j annotations 注: Annotations processed 注: Processing Log4j annotations 注: No elements to process > Task :installBundler Fetching bundler-1.17.3.gem Successfully installed bundler-1.17.3 1 gem installed > Task :assembleTarDistribution Invoking bundler install... Using rake 12.3.3 Using public_suffix 3.1.1 Using addressable 2.7.0 Using cabin 0.9.0 Using arr-pm 0.0.10 Using atomic 1.1.101 (java) Using backports 3.18.2 Using builder 3.2.4 Using bundler 1.17.3 Using ffi 1.13.1 (java) Using childprocess 0.9.0 Using numerizer 0.1.1 Using chronic_duration 0.10.6 Using clamp 0.6.5 Using coderay 1.1.3 Using concurrent-ruby 1.1.7 Using dotenv 2.7.6 Using multi_json 1.15.0 Using elasticsearch-api 5.0.5 Using multipart-post 2.1.1 Using faraday 0.15.4 Using elasticsearch-transport 5.0.5 Using elasticsearch 5.0.5 Using filesize 0.2.0 Using json 1.8.6 (java) Using fpm 1.3.3 Using gems 1.2.0 Using i18n 1.8.5 Using insist 1.0.0 Using jrjackson 0.4.12 (java) Using jruby-openssl 0.10.4 (java) Using openssl_pkcs8_pure 0.0.0.2 Using manticore 0.7.0 (java) Using minitar 0.9 Using mustermann 1.0.3 Using method_source 1.0.0 Using spoon 0.0.6 Using pry 0.13.1 (java) Using nio4r 2.5.4 (java) Using puma 4.3.6 (java) Using rack 2.2.3 Using rubyzip 1.3.0 Using rack-protection 2.1.0 Using tilt 2.0.10 Using sinatra 2.1.0 Using stud 0.0.23 Using thread_safe 0.3.6 (java) Using polyglot 0.3.5 Using treetop 1.6.11 Using logstash-core 7.9.3 (java) from source at `logstash-core` Using logstash-core-plugin-api 2.1.16 (java) from source at `logstash-core-plugin-api` Using logstash-mixin-ecs_compatibility_support 1.0.0 (java) Using logstash-output-elasticsearch 10.6.2 (java) Using mustache 0.99.8 Using sawyer 0.8.2 Using octokit 4.18.0 Using paquet 0.2.1 Using pleaserun 0.0.31 Using ruby-progressbar 1.10.1 Bundle complete! 25 Gemfile dependencies, 59 gems now installed. Gems in the group development were not installed. Bundled gems are installed into `./vendor/bundle` [plugin:install-default] Installing default plugins Installing logstash-codec-avro, logstash-codec-cef, logstash-codec-collectd, logstash-codec-dots, logstash-codec-edn, logstash-codec-edn_lines, logstash-codec-es_bulk, logstash-codec-fluent, logstash-codec-graphite, logstash-codec-json, logstash-codec-json_lines, logstash-codec-line, logstash-codec-msgpack, logstash-codec-multiline, logstash-codec-netflow, logstash-codec-plain, logstash-codec-rubydebug, logstash-filter-aggregate, logstash-filter-anonymize, logstash-filter-cidr, logstash-filter-clone, logstash-filter-csv, logstash-filter-date, logstash-filter-de_dot, logstash-filter-dissect, logstash-filter-dns, logstash-filter-drop, logstash-filter-elasticsearch, logstash-filter-fingerprint, logstash-filter-geoip, logstash-filter-grok, logstash-filter-http, logstash-filter-json, logstash-filter-kv, logstash-filter-memcached, logstash-filter-metrics, logstash-filter-mutate, logstash-filter-prune, logstash-filter-ruby, logstash-filter-sleep, logstash-filter-split, logstash-filter-syslog_pri, logstash-filter-throttle, logstash-filter-translate, logstash-filter-truncate, logstash-filter-urldecode, logstash-filter-useragent, logstash-filter-uuid, logstash-filter-xml, logstash-input-azure_event_hubs, logstash-input-beats, logstash-input-couchdb_changes, logstash-input-dead_letter_queue, logstash-input-elasticsearch, logstash-input-exec, logstash-input-file, logstash-input-ganglia, logstash-input-gelf, logstash-input-generator, logstash-input-graphite, logstash-input-heartbeat, logstash-input-http, logstash-input-http_poller, logstash-input-imap, logstash-input-jms, logstash-input-pipe, logstash-input-redis, logstash-input-s3, logstash-input-snmp, logstash-input-snmptrap, logstash-input-sqs, logstash-input-stdin, logstash-input-syslog, logstash-input-tcp, logstash-input-twitter, logstash-input-udp, logstash-input-unix, logstash-integration-jdbc, logstash-integration-kafka, logstash-integration-rabbitmq, logstash-output-cloudwatch, logstash-output-csv, logstash-output-elastic_app_search, logstash-output-elasticsearch, logstash-output-email, logstash-output-file, logstash-output-graphite, logstash-output-http, logstash-output-lumberjack, logstash-output-nagios, logstash-output-null, logstash-output-pipe, logstash-output-redis, logstash-output-s3, logstash-output-sns, logstash-output-sqs, logstash-output-stdout, logstash-output-tcp, logstash-output-udp, logstash-output-webhdfs 98% EXECUTING [9m 27s] > :assembleTarDistribution 编译完成目录结构 常见问题 打包报错 Could not find tools.jar. Please check that /Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home contains a valid JDK installation. 解决方案：https://www.cnblogs.com/johnjackson/p/14040958.html In Gemfile: logstash-filter-geoipError Bundler::InstallError, retrying 8/10Bundler::GemspecError: Could not read gem at /Users/tao.zeng/share/workspaces/opensource/logstash/vendor/bundle/jruby/2.5.0/cache/logstash-filter-geoip-6.0.3-java.gem. It may be corrupted.An error occurred while installing logstash-filter-geoip (6.0.3), and Bundler cannot continue.Make sure that gem install logstash-filter-geoip -v &#39;6.0.3&#39; --source &#39;https://rubygems.org/&#39; succeeds before bundling. 该问题是logstash-filter-geoip没有按照，需要手动执行安装，但是由于gem的源特别慢，可以使用国内的源。 参考地址：Ruby Gems 镜像 执行安装命令，后面的source如果设置了全局代理，则可以省略 gem install logstash-filter-geoip -v '6.0.3' --source https://mirrors.aliyun.com/rubygems/ 使用snapshot package测试时区问题➜ logstash-7.9.3 ./lsboot conf/test.conf test bin/logstash -f conf/test.conf -l logs/test --path.data data/test -n test Sending Logstash logs to logs/test which is now configured via log4j2.properties [2020-12-29T19:12:34,823][INFO ][logstash.runner ] Starting Logstash {\"logstash.version\"=>\"7.9.3\", \"jruby.version\"=>\"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc Java HotSpot(TM) 64-Bit Server VM 25.201-b09 on 1.8.0_201-b09 +indy +jit [darwin-x86_64]\"} [2020-12-29T19:12:35,003][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.queue\", :path=>\"data/test/queue\"} [2020-12-29T19:12:35,007][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.dead_letter_queue\", :path=>\"data/test/dead_letter_queue\"} [2020-12-29T19:12:35,101][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified [2020-12-29T19:12:35,139][INFO ][logstash.agent ] No persistent UUID file found. Generating new UUID {:uuid=>\"ea54c753-bafe-4a0c-b064-5409e9fe1114\", :path=>\"data/test/uuid\"} [2020-12-29T19:12:37,276][INFO ][org.reflections.Reflections] Reflections took 44 ms to scan 1 urls, producing 22 keys and 45 values [2020-12-29T19:12:38,937][INFO ][logstash.javapipeline ][main] Starting pipeline {:pipeline_id=>\"main\", \"pipeline.workers\"=>8, \"pipeline.batch.size\"=>125, \"pipeline.batch.delay\"=>50, \"pipeline.max_inflight\"=>1000, \"pipeline.sources\"=>[\"/Users/tao.zeng/share/software/logstash-7.9.3/conf/test.conf\"], :thread=>\"#\"} [2020-12-29T19:12:39,895][INFO ][logstash.javapipeline ][main] Pipeline Java execution initialization time {\"seconds\"=>0.95} [2020-12-29T19:12:39,952][INFO ][logstash.inputs.stdin ][main] Automatically switching from json to json_lines codec {:plugin=>\"stdin\"} [2020-12-29T19:12:39,999][INFO ][logstash.javapipeline ][main] Pipeline started {\"pipeline.id\"=>\"main\"} The stdin plugin is now waiting for input: [2020-12-29T19:12:40,062][INFO ][logstash.agent ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]} [2020-12-29T19:12:40,310][INFO ][logstash.agent ] Successfully started Logstash API endpoint {:port=>9600} [ { \"type\":\"test\", \"parent\": \"TOTAL\", \"children\": [ \"TRANSCODE\", \"HOSTNAME\", \"MICROAPP\" ] } ] { \"children\" => [ [0] \"TRANSCODE\", [1] \"HOSTNAME\", [2] \"MICROAPP\" ], \"type\" => \"test\", \"parent\" => \"TOTAL\", \"unix_ts\" => 1609240365076, \"host\" => \"TaoZeng.MBP\", \"@timestamp\" => 2020-12-29T19:12:45.076+08:00, # 默认时区已经改为东八区的时间 \"name\" => \"哈哈哈\", \"@version\" => \"1\" }","categories":[],"tags":[{"name":"logstash","slug":"logstash","permalink":"http://iogogogo.github.io/tags/logstash/"}]},{"title":"logstash日期插件支持纳秒","slug":"logstash-filter-date-compile","date":"2020-12-18T08:01:58.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2020/12/18/logstash-filter-date-compile/","link":"","permalink":"http://iogogogo.github.io/2020/12/18/logstash-filter-date-compile/","excerpt":"","text":"最近项目上遇到时间为纳秒的情况，用到logstash解析时是不支持纳秒的，这里提供一个思路就是自己修改logstash的日期插件，让他支持纳秒，具体涉及的插件是logstash-filter-date 前期准备 下载源代码 下载logstash 安装必要编译组件 修改源代码 打包编译 替换默认的logstash-filter-date-${version}.jar 测试纳秒解析 下载源码cd ~/share/tmp # 如果下载太慢，可以先用gitee同步该仓库，然后在使用gitee地址下载 git clone https://github.com/logstash-plugins/logstash-filter-date.git # gitee地址 git clone https://gitee.com/iogogogo/logstash-filter-date.git # 切换到最新的tag分支，目前是v3.1.9 git checkout -b v3.1.9 v3.1.9 下载logstash因为我用到的logstash版本为7.9.3，所以下载的logstash也是7.9.3，理论上编译出来的logstash-filter-date是通用的 cd ~/share/tmp wget https://artifacts.elastic.co/downloads/logstash/logstash-7.9.3.tar.gz 安装编译组件 安装jruby https://www.ruby-lang.org/zh_cn/downloads/ 安装rvm https://rvm.io/ 安装rbenv https://ruby-china.org/wiki/rbenv-guide 修改源代码将源代码导入idea源码导入idea会下载gradle组件和对应的依赖，这里需要保证网络畅通。 添加纳秒解析找到src/main/java/org/logstash/filters/parser包位置，新建一个纳秒解析类 /* * Licensed to Elasticsearch under one or more contributor * license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright * ownership. Elasticsearch licenses this file to you under * the Apache License, Version 2.0 (the \"License\"); you may * not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.logstash.filters.parser; import org.joda.time.Instant; import java.math.BigDecimal; /** * Created by tao.zeng on 2020/12/12. */ public class UnixNanosecondParser implements TimestampParser { private static long MAX_EPOCH_NANOSECOND = (long) Integer.MAX_VALUE * 1000 * 1000; @Override public Instant parse(String value) { return parse(Long.parseLong(value)); } @Override public Instant parse(Long value) { return new Instant(value / 1000); } @Override public Instant parse(Double value) { // XXX: Should we accept a double? return parse(value.longValue()); } @Override public Instant parseWithTimeZone(String value, String timezone) { return parse(value); } @Override public Instant parse(BigDecimal value) { long lv = value.longValue(); if (lv > MAX_EPOCH_NANOSECOND) { throw new IllegalArgumentException(\"Cannot parse date for value larger than UNIX NS maximum seconds\"); } return new Instant(lv / 1000); } } 在解析工厂类添加纳秒解析org.logstash.filters.parser.TimestampParserFactory /* * Licensed to Elasticsearch under one or more contributor * license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright * ownership. Elasticsearch licenses this file to you under * the Apache License, Version 2.0 (the \"License\"); you may * not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.logstash.filters.parser; import org.joda.time.DateTimeZone; import java.util.Locale; public class TimestampParserFactory { private DateTimeZone timezone; private static final String ISO8601 = \"ISO8601\"; private static final String UNIX = \"UNIX\"; private static final String UNIX_MS = \"UNIX_MS\"; /** * 新增纳秒 */ private static final String UNIX_NS = \"UNIX_NS\"; private static final String TAI64N = \"TAI64N\"; /* * zone is a String because it can be dynamic and come from the event while we parse it. */ public static TimestampParser makeParser(String pattern, Locale locale, String zone) { if (locale == null) { locale = Locale.getDefault(); } String tz = zone; if (tz == null) { tz = DateTimeZone.getDefault().getID(); } else if (zone.contains(\"%{\")) { tz = null; } switch (pattern) { case ISO8601: // Short-hand for a few ISO8601-ish formats return new CasualISO8601Parser(tz); case UNIX: // Unix epoch in seconds return new UnixEpochParser(); case TAI64N: // TAI64N format return new TAI64NParser(); case UNIX_MS: // Unix epoch in milliseconds return new UnixMillisEpochParser(); case UNIX_NS: // Unix epoch in nanoseconds // 纳秒解析类 return new UnixNanosecondParser(); default: return new JodaParser(pattern, locale, tz); } } public static TimestampParser makeParser(String pattern) { return makeParser(pattern, (Locale) null, null); } public static TimestampParser makeParser(String pattern, String locale, String zone) { return makeParser(pattern, locale == null ? null : Locale.forLanguageTag(locale), zone); } } 注释一个单元测试因为该类会因为找不到方法而导致编译报错，可以注释忽略org.logstash.filters.DateFilterTest#commonAssertions private void commonAssertions(Event event, ParseExecutionResult code, String expected) { /*Assert.assertSame(ParseExecutionResult.SUCCESS, code); String actual = ((Timestamp) event.getField(\"[result_ts]\")).toIso8601(); Assert.assertTrue(String.format(\"Unequal - expected: %s, actual: %s\", expected, actual), expected.equals(actual));*/ } 修改配置文件build.gradle修改build.gradle文件中63、66两行的logstash-core配置，改为下载的标准logstash/logstash-core目录 // 默认配置 testCompile fileTree(dir: logstashCoreGemPath, include: '**/*.jar') compileOnly fileTree(dir: logstashCoreGemPath, include: '**/*.jar') // 修改为下载的logstash/logstash-core的绝对路径 testCompile fileTree(dir: '/Users/tao.zeng/share/software/logstash-7.9.3/logstash-core', include: '**/*.jar') compileOnly fileTree(dir: '/Users/tao.zeng/share/software/logstash-7.9.3/logstash-core', include: '**/*.jar') Rakefile修改Rakefile文件的lsc_path配置为logstash/logstash-core目录 // 默认配置 lsc_path = `bundle show logstash-core` // 修改为下载的logstash/logstash-core的绝对路径 lsc_path = `/Users/tao.zeng/share/software/logstash-7.9.3/logstash-core` 打包编译执行gradle的build任务，生成新的logstash-date-filter-{version}.jar，新生成文件目录如下： # 有个好奇的是明明是3.1.9的tag包，但是在源码里面确实3.1.6的版本，所以打包出来也是3.1.6的版本号，解压logstash发现也是该版本号，所以不用在意版本号 build/libs/logstash-filter-date-3.1.6.jar 19:38:39: Executing task 'build'... :buildSrc:compileJava UP-TO-DATE :buildSrc:compileGroovy UP-TO-DATE :buildSrc:processResources UP-TO-DATE :buildSrc:classes UP-TO-DATE :buildSrc:jar UP-TO-DATE :buildSrc:assemble UP-TO-DATE :buildSrc:compileTestJava UP-TO-DATE :buildSrc:compileTestGroovy UP-TO-DATE :buildSrc:processTestResources UP-TO-DATE :buildSrc:testClasses UP-TO-DATE :buildSrc:test UP-TO-DATE :buildSrc:check UP-TO-DATE :buildSrc:build UP-TO-DATE :distTar UP-TO-DATE :distZip UP-TO-DATE :compileJava :processResources UP-TO-DATE :classes :jar :assemble :compileTestJava :processTestResources UP-TO-DATE :testClasses :test :check :build BUILD SUCCESSFUL Total time: 7.276 secs 19:38:47: Task execution finished 'build'. 替换logstash中默认的jar解压logstash-7.9.3.tar.gzcd ~/share/tmp # 解压 tar -zxvf logstash-7.9.3.tar.gz 查找logstash-filter-date-3.1.6.jarcd logstash-7.9.3 && find . -name 'logstash-filter-date*' # 日志 ➜ logstash-7.9.3 find . -name 'logstash-filter-date*' ./vendor/bundle/jruby/2.5.0/specifications/logstash-filter-date-3.1.9.gemspec ./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9 ./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9/logstash-filter-date.gemspec ./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9/lib/logstash-filter-date_jars.rb ./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9/vendor/jar-dependencies/org/logstash/filters/logstash-filter-date ./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9/vendor/jar-dependencies/org/logstash/filters/logstash-filter-date/3.1.6/logstash-filter-date-3.1.6.jar 可以看到原先的jar在./vendor/bundle/jruby/2.5.0/gems/logstash-filter-date-3.1.9/vendor/jar-dependencies/org/logstash/filters/logstash-filter-date/3.1.6/这个目录下面，我们只需要用修改过的jar替换掉就可以了。 测试纳秒解析为了方便测试，我们将上一篇文章的启动脚本复制过来，并且新建一个配置文件conf/test.conf ➜ logstash-7.9.3 ll total 1280 -rw-r--r-- 1 tao.zeng staff 2.2K 10 16 20:23 CONTRIBUTORS -rw-r--r-- 1 tao.zeng staff 3.9K 10 16 20:24 Gemfile -rw-r--r-- 1 tao.zeng staff 22K 10 16 20:25 Gemfile.lock -rw-r--r-- 1 tao.zeng staff 13K 10 16 20:23 LICENSE.txt -rw-r--r-- 1 tao.zeng staff 587K 10 16 20:23 NOTICE.TXT drwxr-xr-x 22 tao.zeng staff 704B 10 16 21:35 bin drwxr-xr-x 3 tao.zeng staff 96B 12 18 20:00 conf drwxr-xr-x 8 tao.zeng staff 256B 10 16 21:35 config drwxr-xr-x 2 tao.zeng staff 64B 10 16 20:23 data drwxr-xr-x 6 tao.zeng staff 192B 10 16 21:35 lib drwxr-xr-x 6 tao.zeng staff 192B 10 16 21:35 logstash-core drwxr-xr-x 5 tao.zeng staff 160B 10 16 21:35 logstash-core-plugin-api -rwxr-xr-x@ 1 tao.zeng staff 1.3K 12 18 20:00 lsboot drwxr-xr-x 5 tao.zeng staff 160B 10 16 21:35 modules drwxr-xr-x 3 tao.zeng staff 96B 10 16 21:35 tools drwxr-xr-x 4 tao.zeng staff 128B 10 16 21:35 vendor drwxr-xr-x 14 tao.zeng staff 448B 10 16 21:35 x-pack 编写测试配置conf/test.confinput { stdin { codec => \"json\" } } filter { mutate { add_field => { \"name\" => \"哈哈哈\" } } # https://zerlong.com/886.html ruby { code => 'event.set(\"unix_ts\",(event.get(\"@timestamp\").to_f.round(3)*1000).to_i)' } date { # 注意这里的UNIX_NS就是我们在TimestampParserFactory新建的纳秒解析器，官方版本是不支持的 match => [\"unix_ns\", \"UNIX_NS\"] target => \"date_ns\" } } output { stdout {} } 测试数据{ \"unix_ns\": 1607206093000000, \"tags\": \"test\" } 启动测试➜ logstash-7.9.3 ./lsboot conf/test.conf test bin/logstash -f conf/test.conf -l logs/test --path.data data/test -n test Sending Logstash logs to logs/test which is now configured via log4j2.properties [2020-12-18T20:13:19,801][INFO ][logstash.runner ] Starting Logstash {\"logstash.version\"=>\"7.9.3\", \"jruby.version\"=>\"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc Java HotSpot(TM) 64-Bit Server VM 25.201-b09 on 1.8.0_201-b09 +indy +jit [darwin-x86_64]\"} [2020-12-18T20:13:19,932][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.queue\", :path=>\"data/test/queue\"} [2020-12-18T20:13:19,935][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.dead_letter_queue\", :path=>\"data/test/dead_letter_queue\"} [2020-12-18T20:13:20,029][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified [2020-12-18T20:13:20,061][INFO ][logstash.agent ] No persistent UUID file found. Generating new UUID {:uuid=>\"e4188c10-0621-4967-a957-8aa14f1a2945\", :path=>\"data/test/uuid\"} [2020-12-18T20:13:21,802][INFO ][org.reflections.Reflections] Reflections took 33 ms to scan 1 urls, producing 22 keys and 45 values [2020-12-18T20:13:23,160][INFO ][logstash.javapipeline ][main] Starting pipeline {:pipeline_id=>\"main\", \"pipeline.workers\"=>8, \"pipeline.batch.size\"=>125, \"pipeline.batch.delay\"=>50, \"pipeline.max_inflight\"=>1000, \"pipeline.sources\"=>[\"/Users/tao.zeng/share/tmp/logstash-7.9.3/conf/test.conf\"], :thread=>\"#\"} [2020-12-18T20:13:23,871][INFO ][logstash.javapipeline ][main] Pipeline Java execution initialization time {\"seconds\"=>0.7} [2020-12-18T20:13:23,922][INFO ][logstash.inputs.stdin ][main] Automatically switching from json to json_lines codec {:plugin=>\"stdin\"} [2020-12-18T20:13:23,962][INFO ][logstash.javapipeline ][main] Pipeline started {\"pipeline.id\"=>\"main\"} The stdin plugin is now waiting for input: [2020-12-18T20:13:24,041][INFO ][logstash.agent ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]} [2020-12-18T20:13:24,244][INFO ][logstash.agent ] Successfully started Logstash API endpoint {:port=>9600} { \"unix_ns\": 1607206093000000, \"tags\": \"test\" } { \"unix_ts\" => 1608293606313, \"date_ns\" => 2020-12-05T22:08:13.000Z, \"@timestamp\" => 2020-12-18T12:13:26.313Z, \"tags\" => \"test\", \"unix_ns\" => 1607206093000000, \"host\" => \"TaoZeng.MBP\", \"@version\" => \"1\", \"name\" => \"哈哈哈\" } 以上，1607206093000000纳秒时间戳已经支持转换成date类型的数据，但是转换的结果却还有时区显示的问题，这里有两个方案 第一是在target的时候指定时区； 第二是修改logstash源码，把时区默认修改为东八区，这个我们下一次说怎么修改。 logstash 时间戳时区问题 以上，就是logstash-filter-date插件添加纳秒支持并且替换，编译好的logstash-filter-date-3.1.6.jar","categories":[],"tags":[{"name":"logstash","slug":"logstash","permalink":"http://iogogogo.github.io/tags/logstash/"}]},{"title":"logstash 启动脚本","slug":"lsboot","date":"2020-12-09T06:42:09.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2020/12/09/lsboot/","link":"","permalink":"http://iogogogo.github.io/2020/12/09/lsboot/","excerpt":"","text":"logstash 通用启动脚本 #!/bin/bash # FileName: lsboot # Description: 启动logstash实例 # Dispatcher: # Description: Usage: lsboot xxx.conf # CreateDate: 2020-12-06 if [ $# -lt 1 ];then echo -e \" \\e[033m Usage: $0 [FileName: e.g.: xxx.conf OR path/xxx.conf] \\e[0m\" exit 1 fi #config file OR path conFile=$1 conFilePath=$(cd `dirname $conFile`;pwd) appName=$(basename ${conFile} | sed s/.conf.*//) currPath=$(cd `dirname $0`;pwd) LS_HOME=${LS_HOME:-$currPath} cd $LS_HOME check_pid(){ pids=`ps -ef | grep -v grep | grep -w \"\\-f ${conFile}\" | awk '{print $2}'` #echo \"PID : ${pids}\" } [[ $2 == \"test\" ]] &amp;&amp; appName=test &amp;&amp; rm -rf data/test &amp;&amp; rm -rf logs/test #./stop.sh #sleep 1 check_pid cmd=\"bin/logstash -f ${conFile} -l logs/${appName} --path.data data/${appName} -n ${appName}\" if [ $pids ];then echo \" APP $appName was running on :\" echo -e \" \\e[032m 【 `pwdx $pids` 】\\e[0m\" echo \" If restart, kill $pids first.\" exit 0 else cd $LS_HOME echo \"$cmd\" if [ ${appName} == \"test\" ];then $cmd else eval $cmd &amp; sleep 1 check_pid [[ -n \"${pids}\" ]] &amp;&amp; echo -e \"\\e[032m success \\e[0m: $appName boot on: $pids\" || echo -e \" \\e[31m [ $appName : $conFile ] Boot Failed. \\e[0m \" fi fi #sleep 1 #ps -ef | grep -v grep | grep -w \"${conFile}\" | awk '{print $2\"\\t\"$NF}' exit 0 logstash将时间转换成unix时间戳 # https://zerlong.com/886.html ruby { code => 'event.set(\"unix_ts\",(event.get(\"@timestamp\").to_f.round(3)*1000).to_i)' }","categories":[],"tags":[{"name":"Logstash","slug":"Logstash","permalink":"http://iogogogo.github.io/tags/Logstash/"}]},{"title":"CentOS 升级安装最新版git","slug":"soft-install-git","date":"2020-09-01T08:27:13.000Z","updated":"2024-07-01T12:30:37.377Z","comments":true,"path":"2020/09/01/soft-install-git/","link":"","permalink":"http://iogogogo.github.io/2020/09/01/soft-install-git/","excerpt":"","text":"准备安装必要依赖 yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc yum install -y gcc perl-ExtUtils-MakeMaker 卸载旧版本Git如果旧版本不存在，此步可忽略 yum remove -y git 下载最新版Git 切换目录 cd /usr/local/src git release版本地址 https://mirrors.edge.kernel.org/pub/software/scm/git/ 下载并解压 wget --no-check-certificate https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.9.5.tar.gz tar -xvf git-2.9.5.tar.gz cd /usr/local/src/git-2.9.5 编译安装Gitmake prefix=/usr/local/git all make prefix=/usr/local/git install 配置环境变量echo \"export PATH=$PATH:/usr/local/git/bin\" >> /etc/profile source /etc/profile","categories":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/tags/Git/"}]},{"title":"maven.test.skip和skipTests的区别","slug":"maven-skip-test","date":"2020-08-20T14:15:07.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/08/20/maven-skip-test/","link":"","permalink":"http://iogogogo.github.io/2020/08/20/maven-skip-test/","excerpt":"","text":"-DskipTests不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。 pom中配置跳过 &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-surefire-plugin&lt;/artifactId> &lt;version>2.5&lt;/version> &lt;configuration> &lt;skipTests>true&lt;/skipTests> &lt;/configuration> &lt;/plugin> -Dmaven.test.skip=true不执行测试用例，也不编译测试用例类，不但跳过单元测试的运行，也跳过测试代码的编译。 pom中配置跳过 &lt;plugin> &lt;groupId>org.apache.maven.plugin&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;version>2.1&lt;/version> &lt;configuration> &lt;skip>true&lt;/skip> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-surefire-plugin&lt;/artifactId> &lt;version>2.5&lt;/version> &lt;configuration> &lt;skip>true&lt;/skip> &lt;/configuration> &lt;/plugin>","categories":[{"name":"Maven","slug":"Maven","permalink":"http://iogogogo.github.io/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://iogogogo.github.io/tags/Maven/"}]},{"title":"【转】Spring Kafka 笔记","slug":"spring-kafka-note","date":"2020-08-17T14:41:29.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2020/08/17/spring-kafka-note/","link":"","permalink":"http://iogogogo.github.io/2020/08/17/spring-kafka-note/","excerpt":"","text":"Spring-Kafka史上最强入门教程","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/categories/Kafka/"},{"name":"Spring","slug":"Kafka/Spring","permalink":"http://iogogogo.github.io/categories/Kafka/Spring/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/tags/Kafka/"}]},{"title":"Hadoop常用运维命令","slug":"hadoop-ops-command","date":"2020-08-03T09:44:57.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2020/08/03/hadoop-ops-command/","link":"","permalink":"http://iogogogo.github.io/2020/08/03/hadoop-ops-command/","excerpt":"","text":"一、HADOOP集群启动1. 格式化zk在zk的leader节点服务器上，Hadoop的bin目录中执行如下命令：改为在 nn的active节点上 sh hdfs zkfc -formatZK 2. 启动journalnode集群hadoop任意节点服务器执行 hadoop-daemons.sh start journalnode 3. 格式化namenode在nn节点执行 hadoop namenode -format 4. 启动NameNode在hdaoop01节点上执行如下命令，启动NameNode节点： hadoop-daemon.sh start namenode 首先把hdaoop02服务器的 namenode节点变为standby namenode节点。执行命令如下： hdfs namenode -bootstrapStandby 启动hadoop02服务器的namenode节点，执行命令如下： hadoop-daemon.sh start namenode 5. 启动DataNode在hadoop01,hadoop02,hadoop03服务器上分别启动datanode节点，在这三台服务器上分别执行如下命令： hadoop-daemon.sh start datanode 6. 启动zkfcFalioverControllerActive是失败恢复线程。这个线程需要在NameNode节点所在的服务器上启动，在hadoop01,hadoop02服务器上执行如下命令： hadoop-daemon.sh start zkfc 7. 启动Resourcemanager在hdaoop01服务器上启动主Resourcemanager节点，执行如下命令：启动成功后，hadoop01,hadoop02,hadoop03服务器上的nodemanager 也会跟随启动 start-yarn.sh 在hadoop02服务器上启动副 Resoucemanager节点，执行如下命令： yarn-daemon.sh start resourcemanager 二、YARN运维命令1. yarn application1、-list 列出所有 application 信息 yarn application -list 2、-appStates 跟-list一起使用，用来筛选不同状态的application，多个用”,”分隔；所有状态ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUNNING,FINISHED,FAILED,KILLED yarn application -list -appStates RUNNING 3、-appTypes 跟-list一起使用，用来筛选不同类型的application，多个用”,”分隔；如 MAPREDUCE yarn application -list -appTypes MAPREDUCE 4、-kill 杀死一个application，需要指定一个Application ID yarn application -kill application_1526100291229_206393 5、-status 列出 某个application 的状态 yarn application -status application_1526100291229_206393 6、-movetoqueue 移动application到其他的queue，不能单独使用7、-queue 与 movetoqueue命令一起使用，指定移动到哪个queue yarn application -movetoqueue application_1526100291229_206393 -queue other 2. yarn node查看各个node上的任务数 yarn node --list 3. yarn logsyarn logs -applicationId application_1583405966138_0013","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://iogogogo.github.io/categories/Hadoop/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://iogogogo.github.io/tags/Hadoop/"}]},{"title":"Redis查看集群信息以及key分布非slot","slug":"redis-cluster-info","date":"2020-07-29T08:08:34.000Z","updated":"2024-07-01T12:30:37.377Z","comments":true,"path":"2020/07/29/redis-cluster-info/","link":"","permalink":"http://iogogogo.github.io/2020/07/29/redis-cluster-info/","excerpt":"","text":"进入redis集群redis-cli -h ip -p port -c 查看集群节点cluster nodes 查看key对应的slotcluster keyslot key 查看slot和节点的对应关系cluster slots","categories":[{"name":"Redis","slug":"Redis","permalink":"http://iogogogo.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://iogogogo.github.io/tags/Redis/"}]},{"title":"Guava中的CaseFormat","slug":"guava-case-format","date":"2020-07-25T05:47:19.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2020/07/25/guava-case-format/","link":"","permalink":"http://iogogogo.github.io/2020/07/25/guava-case-format/","excerpt":"","text":"在数据库中，按照阿里巴巴java开发手册，数据库字段全部小写并且按照_进行单词之间的分割，但是我们Java中的命名风格又是按照驼峰方式，一般返回给前端的DTO对象也按照驼峰方式，前端同学在对所有列进行排序时，会按照我们返回给他的props发送给后端，这时候后端收到的就是驼峰方式的props，但是拿到数据库查询这肯定是一个不存在的字段，那么有什么好的方式去解决这个问题呢？ 这时候发现了guava中的CaseFormat工具类。 com.google.common.base.CaseFormat是一种实用工具类，以提供不同的ASCII字符格式之间的转换。 类声明@GwtCompatible public enum CaseFormat extends Enum&lt;CaseFormat> 枚举常量 枚举常量 说明 LOWER_CAMEL Java变量的命名规则，如 lowerCamel LOWER_HYPHEN 连字符连接变量的命名规则，如 lower-hyphen LOWER_UNDERSCORE C ++变量命名规则，如 lower_underscore UPPER_CAMEL Java和C++类的命名规则，如 UpperCamel UPPER_UNDERSCORE Java和C++常量的命名规则，如 UPPER_UNDERSCORE 方法 方法 说明 Converter&lt;String,String&gt; converterTo(CaseFormat targetFormat) 返回一个转换，从这个格式转换targetFormat字符串。 String to(CaseFormat format, String str) 从这一格式指定格式的指定字符串 str 转换。 static CaseFormat valueOf(String name) 返回此类型具有指定名称的枚举常量。 static CaseFormat[] values() 返回一个包含该枚举类型的常量数组中的顺序被声明。 测试@Test public void test() { String appCiNum = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, \"appCiNum\"); System.out.println(appCiNum); Assert.assertEquals(appCiNum, \"app_ci_num\"); appCiNum = CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.LOWER_CAMEL, \"app_ci_num\"); System.out.println(appCiNum); Assert.assertEquals(appCiNum, \"appCiNum\"); } 只要我们自己定的DTO是标准的，那么排序是前端同学就按照我们返回给他的字段在传回来，我们只需要用CaseFormat进行转换即可，不然还得依次进行match匹配","categories":[{"name":"Guava","slug":"Guava","permalink":"http://iogogogo.github.io/categories/Guava/"}],"tags":[{"name":"Guava","slug":"Guava","permalink":"http://iogogogo.github.io/tags/Guava/"}]},{"title":"Map对key或者value进行排序","slug":"map-sort","date":"2020-07-25T04:21:58.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2020/07/25/map-sort/","link":"","permalink":"http://iogogogo.github.io/2020/07/25/map-sort/","excerpt":"","text":"开发中偶尔会遇到一些比较特殊的需求，比如对一个map进行排序，并且是对key或者value进行排序，那么我们可以用Java8中提供的stream来进行实现 排序工具类封装排序工具类 package com.iogogogo.common.util; import com.google.common.collect.Lists; import com.google.common.collect.Maps; import java.lang.reflect.Field; import java.util.Iterator; import java.util.LinkedList; import java.util.Map; /** * Created by tao.zeng on 2020/5/25. */ public class MapSortUtils { /** * Sort by key map. * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the map */ public static &lt;K extends Comparable&lt;? super K>, V> Map&lt;K, V> sortByKey(Map&lt;K, V> map) { // 这里使用了guava简化了map对象的创建，没有guava直接使用 new LinkedHashMap&lt;>(); Map&lt;K, V> result = Maps.newLinkedHashMap(); map.entrySet().stream() .sorted(Map.Entry.comparingByKey()).forEachOrdered(e -> result.put(e.getKey(), e.getValue())); return result; } /** * Sort reversed by key map. * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the map */ public static &lt;K extends Comparable&lt;? super K>, V> Map&lt;K, V> sortReversedByKey(Map&lt;K, V> map) { Map&lt;K, V> result = Maps.newLinkedHashMap(); map.entrySet().stream() .sorted(Map.Entry.&lt;K, V>comparingByKey() .reversed()).forEachOrdered(e -> result.put(e.getKey(), e.getValue())); return result; } /** * Sort by value map. * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the map */ public static &lt;K, V extends Comparable&lt;? super V>> Map&lt;K, V> sortByValue(Map&lt;K, V> map) { Map&lt;K, V> result = Maps.newLinkedHashMap(); map.entrySet().stream() .sorted(Map.Entry.comparingByValue()).forEachOrdered(e -> result.put(e.getKey(), e.getValue())); return result; } /** * Sort reversed by value map. * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the map */ public static &lt;K, V extends Comparable&lt;? super V>> Map&lt;K, V> sortReversedByValue(Map&lt;K, V> map) { Map&lt;K, V> result = Maps.newLinkedHashMap(); map.entrySet().stream() .sorted(Map.Entry.&lt;K, V>comparingByValue() .reversed()).forEachOrdered(e -> result.put(e.getKey(), e.getValue())); return result; } /** * Gets first key. * * @param &lt;K> the type parameter * @param map the map * @return the first key */ public static &lt;K> K getFirstKey(Map&lt;K, ?> map) { return map.keySet().iterator().next(); } /** * Gets last key. * * @param &lt;K> the type parameter * @param map the map * @return the last key */ public static &lt;K> K getLastKey(Map&lt;K, ?> map) { Iterator&lt;K> iterator = map.keySet().iterator(); LinkedList&lt;K> list = Lists.newLinkedList(); while (iterator.hasNext()) { list.add(iterator.next()); } return list.getLast(); } /** * Gets first. * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the first */ public static &lt;K, V> Map.Entry&lt;K, V> getFirst(Map&lt;K, V> map) { return map.entrySet().iterator().next(); } /** * Gets last. * &lt;p> * 通过反射获取LinkedHashMap中的末尾元素： * &lt;p> * 时间复杂度O(1)，访问tail属性 * * @param &lt;K> the type parameter * @param &lt;V> the type parameter * @param map the map * @return the last * @throws IllegalAccessException the illegal access exception * @throws NoSuchFieldException the no such field exception */ @SuppressWarnings(\"unchecked\") public static &lt;K, V> Map.Entry&lt;K, V> getLast(Map&lt;K, V> map) throws IllegalAccessException, NoSuchFieldException { Field tail = map.getClass().getDeclaredField(\"tail\"); tail.setAccessible(true); return (Map.Entry&lt;K, V>) tail.get(map); } } 测试结果package com.iogogogo.common.tests; import com.iogogogo.common.util.MapSortUtils; import com.google.common.collect.Maps; import org.junit.Assert; import org.junit.Before; import org.junit.Test; import java.util.Map; /** * Created by tao.zeng on 2020/7/25. */ public class MapSortTest { private final static Map&lt;String, Integer> DEF_DATA = Maps.newHashMap(); @Before public void before() { DEF_DATA.put(\"c\", 20); DEF_DATA.put(\"a\", 54); DEF_DATA.put(\"z\", 23); DEF_DATA.put(\"d\", 55); } @Test public void testKeySort() { // 按照key进行正序排序 Map&lt;String, Integer> sortByKey = MapSortUtils.sortByKey(DEF_DATA); // 获取map中的第一个key String firstKey = MapSortUtils.getFirstKey(sortByKey); // 获取map中的最后一个key String lastKey = MapSortUtils.getLastKey(sortByKey); Assert.assertEquals(firstKey, \"a\"); Assert.assertEquals(lastKey, \"z\"); // 按照key对map进行倒序排序 Map&lt;String, Integer> reversedByKey = MapSortUtils.sortReversedByKey(DEF_DATA); firstKey = MapSortUtils.getFirstKey(reversedByKey); lastKey = MapSortUtils.getLastKey(reversedByKey); Assert.assertEquals(firstKey, \"z\"); Assert.assertEquals(lastKey, \"a\"); } @Test public void testValue() throws NoSuchFieldException, IllegalAccessException { // 按照value进行正序排序 Map&lt;String, Integer> sortByValue = MapSortUtils.sortByValue(DEF_DATA); Map.Entry&lt;String, Integer> first = MapSortUtils.getFirst(sortByValue); Map.Entry&lt;String, Integer> last = MapSortUtils.getLast(sortByValue); Assert.assertEquals(first.getKey(), \"c\"); Assert.assertEquals(20, (int) first.getValue()); Assert.assertEquals(last.getKey(), \"d\"); Assert.assertEquals(55, (int) last.getValue()); // 按照value进行倒序排序 Map&lt;String, Integer> reversedByValue = MapSortUtils.sortReversedByValue(DEF_DATA); // 获取排序以后的第一个个最后一个元素 first = MapSortUtils.getFirst(reversedByValue); last = MapSortUtils.getLast(reversedByValue); Assert.assertEquals(first.getKey(), \"d\"); Assert.assertEquals(55, (int) first.getValue()); Assert.assertEquals(last.getKey(), \"c\"); Assert.assertEquals(20, (int) last.getValue()); } }","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"map","slug":"map","permalink":"http://iogogogo.github.io/tags/map/"}]},{"title":"MyBatis对象中属性 包含List<String>一对多映射处理方式","slug":"mybatis-one-collection-basic-type","date":"2020-07-19T14:37:38.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/07/19/mybatis-one-collection-basic-type/","link":"","permalink":"http://iogogogo.github.io/2020/07/19/mybatis-one-collection-basic-type/","excerpt":"","text":"在使用MyBatis查询数据库时，经常会有一对多的情况，那么在一对多的情况时，如果是一个Collection&lt;String&gt;或者Collection&lt;Integer&gt; 类型，那么我们的ResultMap该如何定义？ 方法很简单，这时候我们就需要使用到构造函数注入了，通过Integer和String的构造函数注入，具体的字段名称自己对好入座即可。 &lt;resultMap type=\"User\" id=\"user_map\"> &lt;id property=\"id\" column=\"\"/> &lt;result property=\"username\" column=\"username\"/> &lt;collection property=\"age\" ofType=\"int\"> &lt;constructor> &lt;arg column=\"age\"/> &lt;!-- 对号入座数据库column名称即可 --> &lt;/constructor> &lt;/collection> &lt;collection property=\"authorities\" ofType=\"java.lang.String\"> &lt;constructor> &lt;arg column=\"permission\"/> &lt;!-- 对号入座数据库column名称即可 --> &lt;/constructor> &lt;/collection> &lt;/resultMap>","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://iogogogo.github.io/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://iogogogo.github.io/tags/MyBatis/"}]},{"title":"MySQL查看所有连接的客户端ip","slug":"mysql-show-client-connection","date":"2020-06-29T05:54:14.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/06/29/mysql-show-client-connection/","link":"","permalink":"http://iogogogo.github.io/2020/06/29/mysql-show-client-connection/","excerpt":"","text":"有时候我们需要查看当前的mysql数据库中， 有哪些客户端保持了连接， 每个客户端分别保持了多少连接，可以使用下面的语句查询结果，可以直观的看到连接数。 SELECT substring_index(host, ':',1) AS hostname,state,count(*) FROM information_schema.processlist GROUP BY state,hostname; 输出结果： mysql> SELECT substring_index(host, ':',1) AS hostname,state,count(*) FROM information_schema.processlist GROUP BY state,hostname; +----------------+-----------------------+----------+ | hostname | state | count(*) | +----------------+-----------------------+----------+ | 10.2.1.12 | | 2 | | 192.168.21.125 | | 2 | | vm21122 | | 52 | | localhost | executing | 1 | | 192.168.21.125 | Receiving from client | 1 | +----------------+-----------------------+----------+ 5 rows in set (0.00 sec) mysql> 会列出每个ip当前的状态，以及当前的连接数 。这个在处理类似碰到数据库 Too Many Connections 等的错误的时候比较有用。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"【转】How can I prevent gson from converting integers to doubles","slug":"gson-how-can-i-prevent-gson-from-converting-integers-to-doubles","date":"2020-06-28T02:17:53.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2020/06/28/gson-how-can-i-prevent-gson-from-converting-integers-to-doubles/","link":"","permalink":"http://iogogogo.github.io/2020/06/28/gson-how-can-i-prevent-gson-from-converting-integers-to-doubles/","excerpt":"","text":"处理Gson中，json转换map造成的int变double的问题。 原文链接 MapDeserializerDoubleAsIntFix.java /** *最近在研究网络请求数据解析的问题，发现json数据被强制转换为map结构的时候，会出现int变成double的问题 *在stackoverflow上看到了一个这个How can I prevent gson from converting integers to doubles 的问题，采用了这个答案 *https://stackoverflow.com/a/36529534/5279354答案 */ import com.google.gson.JsonArray; import com.google.gson.JsonDeserializationContext; import com.google.gson.JsonDeserializer; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.gson.JsonParseException; import com.google.gson.JsonPrimitive; import com.google.gson.internal.LinkedTreeMap; import java.lang.reflect.Type; import java.util.ArrayList; import java.util.List; import java.util.Map; import java.util.Set; public class MapDeserializerDoubleAsIntFix implements JsonDeserializer&lt;Map&lt;String, Object>> { @Override public Map&lt;String, Object> deserialize(JsonElement jsonElement, Type type, JsonDeserializationContext jsonDeserializationContext) throws JsonParseException { return (Map&lt;String, Object>) read(jsonElement); } public Object read(JsonElement in) { if(in.isJsonArray()){ List&lt;Object> list = new ArrayList&lt;>(); JsonArray arr = in.getAsJsonArray(); for (JsonElement anArr : arr) { list.add(read(anArr)); } return list; }else if(in.isJsonObject()){ Map&lt;String, Object> map = new LinkedTreeMap&lt;String, Object>(); JsonObject obj = in.getAsJsonObject(); Set&lt;Map.Entry&lt;String, JsonElement>> entitySet = obj.entrySet(); for(Map.Entry&lt;String, JsonElement> entry: entitySet){ map.put(entry.getKey(), read(entry.getValue())); } return map; }else if( in.isJsonPrimitive()){ JsonPrimitive prim = in.getAsJsonPrimitive(); if(prim.isBoolean()){ return prim.getAsBoolean(); }else if(prim.isString()){ return prim.getAsString(); }else if(prim.isNumber()){ Number num = prim.getAsNumber(); // here you can handle double int/long values // and return any type you want // this solution will transform 3.0 float to long values if(Math.ceil(num.doubleValue()) == num.longValue()) return num.longValue(); else{ return num.doubleValue(); } } } return null; } @Test public void test2() { String json = \"{\\\"data\\\":[{\\\"id\\\":1,\\\"quantity\\\":2,\\\"name\\\":\\\"apple\\\"}, {\\\"id\\\":3,\\\"quantity\\\":4,\\\"name\\\":\\\"orange\\\"}]}\"; System.out.println(\"json == \" + json); // Map&lt;String, Object> map = new LinkedTreeMap&lt;>(); // map = new Gson().fromJson(json, map.getClass()); // System.out.println(map); GsonBuilder gsonBuilder = new GsonBuilder(); gsonBuilder.registerTypeAdapter(new TypeToken&lt;Map &lt;String, Object>>(){}.getType(), new MapDeserializerDoubleAsIntFix()); Gson gson = gsonBuilder.create(); Map&lt;String, Object> map = gson.fromJson(json, new TypeToken&lt;Map&lt;String, Object>>(){}.getType()); System.out.println(map); } } 参考文章 https://gist.github.com/xingstarx/5ddc14ff6ca68ba4097815c90d1c47cc https://blog.csdn.net/ligeforrent/article/details/93759524","categories":[{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/categories/Gson/"}],"tags":[{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/tags/Gson/"}]},{"title":"当Gson遇上Java8中的日期API","slug":"gson-java8-datetime","date":"2020-06-23T13:45:00.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2020/06/23/gson-java8-datetime/","link":"","permalink":"http://iogogogo.github.io/2020/06/23/gson-java8-datetime/","excerpt":"","text":"&emsp;Java8开始，JDK中提供了一组新的日期API，当我们需要序列化数据成json时，经常会用到Gson。当Java8中的日期API遇上Gson时，能否按照预期的想法正常的处理我们的数据呢？ 使用Gson序列化与反序列化@Test public void test() { LocalDateTime dateTime = LocalDateTime.now(); LocalDate date = LocalDate.now(); Gson gson = new Gson(); String json = gson.toJson(dateTime); log.info(\"dateTime Serialization:{}\", json); log.info(\"dateTime Deserialization:{}\", gson.fromJson(json, LocalDateTime.class)); System.out.println(); json = gson.toJson(date); log.info(\"date Serialization:{}\", json); log.info(\"date Deserialization:{}\", gson.fromJson(json, LocalDate.class)); } LocalDateTime 序列化的结果 dateTime Serialization:{\"date\":{\"year\":2020,\"month\":6,\"day\":23},\"time\":{\"hour\":21,\"minute\":58,\"second\":20,\"nano\":987000000}} 反序列化结果 dateTime Deserialization:2020-06-23T21:58:20.987 LocalDate 序列化的结果 date Serialization:{\"year\":2020,\"month\":6,\"day\":23} 反序列化结果 date Deserialization:2020-06-23 我们会发现，序列化的结果不是我们想要的，正常应该是一个ISO格式的时间才对，但是却成了一个JsonObject。很显然这是不满足我们需求的。 分析序列化结果不是ISO格式的原因通过源码分析，LocalDateTime中引用了LocalDate /** * The date part. */ private final LocalDate date; /** * The time part. */ private final LocalTime time; 其中LocalDate和LocalTime的部分源码如下 LocalDate /** * The year. */ private final int year; /** * The month-of-year. */ private final short month; /** * The day-of-month. */ private final short day; LocalTime /** * The hour. */ private final byte hour; /** * The minute. */ private final byte minute; /** * The second. */ private final byte second; /** * The nanosecond. */ private final int nano; &emsp;可以看到，LocalDate和LocalTime，我们序列化Java8中的日期API，实际上是把成员变量序列化，是正常的一个序列化对象的逻辑。但是我们肯定是不希望这样的结果，对我们来说并不是特别友好。那么怎么解决这个问题呢？ 自定义Gson的Adapter解决该问题Gson本身给我们提供了各种各样的配置，其中有一个就是可以自定义序列化或者反序列化的Adapter，那么既然现在我们序列化不是我们想要的结果，就可以通过自定义Adapter来解决这个问题，废话不说，直接上代码演示。 自定义LocalDateAdapter/** * Created by tao.zeng on 2020/6/23. * &lt;p> * 处理LocalDate的序列化与反序列化 */ public final static class LocalDateAdapter implements JsonSerializer&lt;LocalDate>, JsonDeserializer&lt;LocalDate> { @Override public JsonElement serialize(LocalDate date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE)); } @Override public LocalDate deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDate.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE); } } 自定义LocalDateTimeAdapter/** * Created by tao.zeng on 2020/6/23. * &lt;p> * 处理LocalDateTime序列化与反序列化 */ public final static class LocalDateTimeAdapter implements JsonSerializer&lt;LocalDateTime>, JsonDeserializer&lt;LocalDateTime> { @Override public JsonElement serialize(LocalDateTime date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE_TIME)); } @Override public LocalDateTime deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDateTime.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE_TIME); } } 使用自定义Adapter既然我们现在自定义了Adapter，那么在使用时就需要将它注册到gson对象中去。在创建gson对象时就不能直接使用Gson gson = new Gson()，而是要使用GsonBuilder去进行构建。 // 实例化gson对象时注册Adapter Gson gson = new GsonBuilder() .registerTypeAdapter(LocalDate.class, new JsonParse.LocalDateAdapter()) .registerTypeAdapter(LocalDateTime.class, new JsonParse.LocalDateTimeAdapter()) .create(); 上面我们的代码序列化与反序列时就使用注册了Adapter的gson对象即可 @Test public void test() { LocalDateTime dateTime = LocalDateTime.now(); LocalDate date = LocalDate.now(); Gson gson = new GsonBuilder() .registerTypeAdapter(LocalDate.class, JsonParse.LocalDateAdapter.class) .registerTypeAdapter(LocalDateTime.class, JsonParse.LocalDateTimeAdapter.class) .create(); String json = gson.toJson(dateTime); log.info(\"dateTime Serialization:{}\", json); log.info(\"dateTime Deserialization:{}\", gson.fromJson(json, LocalDateTime.class)); System.out.println(); json = gson.toJson(date); log.info(\"date Serialization:{}\", json); log.info(\"date Deserialization:{}\", gson.fromJson(json, LocalDate.class)); } LocalDateTimedateTime Serialization:\"2020-06-23T22:22:10.816\" dateTime Deserialization:2020-06-23T22:22:10.816 LocalDatedate Serialization:\"2020-06-23\" date Deserialization:2020-06-23 可以看到，在自定义Adapter以后，序列化的结果就是我们想要的ISO类型，当然你也可以根据自己的需求将日期格式序列话成自己想要的任意格式。 Json序列化与反序列化工具类分享一个日常使用工具类，除了上文说到的关于日期处理的解决方案，还有另外一个问题的解决方案。这个留着下一篇文章讲。 package com.iogogogo.util; import com.google.gson.*; import com.google.gson.internal.LinkedTreeMap; import com.google.gson.reflect.TypeToken; import lombok.extern.slf4j.Slf4j; import java.lang.reflect.Type; import java.nio.charset.StandardCharsets; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.ArrayList; import java.util.List; import java.util.Map; import java.util.Set; /** * Created by tao.zeng on 2020/6/23. */ @Slf4j public class JsonParse { public static Type MAP_STR_OBJ_TYPE = new TypeToken&lt;Map&lt;String, Object>>() { }.getType(); public static Gson GSON = new GsonBuilder() .registerTypeAdapter(MAP_STR_OBJ_TYPE, new MapDeserializerDoubleAsIntFix()) .registerTypeAdapter(LocalDate.class, new LocalDateAdapter()) .registerTypeAdapter(LocalDateTime.class, new LocalDateTimeAdapter()) .create(); /** * To json string. * * @param bean the bean * @return the string */ public static String toJson(Object bean) { return GSON.toJson(bean); } /** * To json string. * * @param builder the builder * @param bean the bean * @return the string */ public static String toJson(GsonBuilder builder, Object bean) { return builder.create().toJson(bean); } /** * Parse t. * * @param &lt;T> the type parameter * @param json the json * @param clz the clz * @return the t */ public static &lt;T> T parse(String json, Class&lt;T> clz) { return GSON.fromJson(json, clz); } /** * Parse t. * * @param &lt;T> the type parameter * @param builder the builder * @param json the json * @param clz the clz * @return the t */ public static &lt;T> T parse(GsonBuilder builder, String json, Class&lt;T> clz) { return builder.create().fromJson(json, clz); } /** * Parse t. * * @param &lt;T> the type parameter * @param json the json * @param type the type * @return the t */ public static &lt;T> T parse(String json, Type type) { return GSON.fromJson(json, type); } /** * Parse t. * * @param &lt;T> the type parameter * @param builder the builder * @param json the json * @param type the type * @return the t */ public static &lt;T> T parse(GsonBuilder builder, String json, Type type) { return builder.create().fromJson(json, type); } /** * To json bytes byte [ ]. * * @param value the value * @return the byte [ ] */ public static byte[] toJsonBytes(Object value) { return toJson(value).getBytes(StandardCharsets.UTF_8); } /** * Created by tao.zeng on 2020/6/4. * &lt;p> * 处理LocalDate的序列化与反序列化 */ public final static class LocalDateAdapter implements JsonSerializer&lt;LocalDate>, JsonDeserializer&lt;LocalDate> { @Override public JsonElement serialize(LocalDate date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE)); } @Override public LocalDate deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDate.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE); } } /** * Created by tao.zeng on 2020/6/4. * &lt;p> * 处理LocalDateTime序列化与反序列化 */ public final static class LocalDateTimeAdapter implements JsonSerializer&lt;LocalDateTime>, JsonDeserializer&lt;LocalDateTime> { @Override public JsonElement serialize(LocalDateTime date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE_TIME)); } @Override public LocalDateTime deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDateTime.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE_TIME); } } /** * Created by tao.zeng on 2020/6/4. * &lt;p> * https://gist.github.com/xingstarx/5ddc14ff6ca68ba4097815c90d1c47cc * &lt;p> * https://stackoverflow.com/questions/36508323/how-can-i-prevent-gson-from-converting-integers-to-doubles/36529534#36529534 * &lt;p> * &lt;p> * 解决json数据转换为map结构的时候，会出现int变成double的问题 */ public final static class MapDeserializerDoubleAsIntFix implements JsonDeserializer&lt;Map&lt;String, Object>> { @SuppressWarnings(\"unchecked\") @Override public Map&lt;String, Object> deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { return (Map&lt;String, Object>) read(element); } private Object read(JsonElement in) { if (in.isJsonArray()) { List&lt;Object> list = new ArrayList&lt;>(); JsonArray arr = in.getAsJsonArray(); for (JsonElement anArr : arr) { list.add(read(anArr)); } return list; } else if (in.isJsonObject()) { Map&lt;String, Object> map = new LinkedTreeMap&lt;>(); JsonObject obj = in.getAsJsonObject(); Set&lt;Map.Entry&lt;String, JsonElement>> entitySet = obj.entrySet(); for (Map.Entry&lt;String, JsonElement> entry : entitySet) { map.put(entry.getKey(), read(entry.getValue())); } return map; } else if (in.isJsonPrimitive()) { JsonPrimitive prim = in.getAsJsonPrimitive(); if (prim.isBoolean()) { return prim.getAsBoolean(); } else if (prim.isString()) { return prim.getAsString(); } else if (prim.isNumber()) { Number num = prim.getAsNumber(); // here you can handle double int/long values // and return any type you want // this solution will transform 3.0 float to long values if (Math.ceil(num.doubleValue()) == num.longValue()) return num.longValue(); else { return num.doubleValue(); } } } return null; } } }","categories":[{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/categories/Gson/"}],"tags":[{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/tags/Gson/"},{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Nginx开启gzip压缩","slug":"nginx-enable-gzip","date":"2020-06-18T11:54:43.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/06/18/nginx-enable-gzip/","link":"","permalink":"http://iogogogo.github.io/2020/06/18/nginx-enable-gzip/","excerpt":"","text":"在server节点下新增如下内容，开启gzip压缩。注意后端需要保证返回的 Content-Type: application/json;charset=UTF-8 gzip on; gzip_min_length 1k; gzip_comp_level 6; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain application/x-javascript text/css application/xml application/javascript application/json; 成功以后可以看到 Content-Encoding: gzip","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://iogogogo.github.io/tags/Nginx/"}]},{"title":"正则表达式","slug":"tools-regex","date":"2020-03-18T14:20:22.000Z","updated":"2024-07-01T12:30:37.380Z","comments":true,"path":"2020/03/18/tools-regex/","link":"","permalink":"http://iogogogo.github.io/2020/03/18/tools-regex/","excerpt":"","text":"正则表达式元字符 元字符 说明 . 匹配除了换行符以外的任意字符 * 指定*前边的内容可以连续重复使用任意次以使整个表达式得到匹配 .* 任意数量的不包含换行的字符 \\b 单词的开头或结尾，也就是单词的分界处 \\w 匹配字母、数字、下划线、汉字 \\s 匹配任意空白字符 \\d 匹配数字 ^ 匹配字符串开始 $ 匹配字符串结束 反义 元字符 说明 \\W 匹配非字母、下划线、数字、汉字 \\S 匹配不是空白字符串 \\D 匹配任意非数字的字符 \\B 匹配不是单词开始或者结束的位置 [^x] 匹配除了x以外的任意字符","categories":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://iogogogo.github.io/categories/正则表达式/"}],"tags":[]},{"title":"vertica开启ROS","slug":"vertica-enable-ros","date":"2020-03-12T07:07:01.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"2020/03/12/vertica-enable-ros/","link":"","permalink":"http://iogogogo.github.io/2020/03/12/vertica-enable-ros/","excerpt":"","text":"vertica默认批量插入是关闭的，需要手动设置DataSourceProperties开启，详细参考JDBC Connection Properties，文档中该参数介绍如下： DirectBatchInsert Determines whether a batch insert stored data directly into ROS (true) or using AUTO;) mode (false). When you load data using AUTO mode, Vertica inserts the data first into the WOS. If the WOS is full, Vertica inserts the data directly into ROS. For details about load options, see Choosing a Load Method. Set After Connection:VerticaConnection.setProperty() Default Value: false 在jdbc方式和spring中集成数据源方式略有不同，下面分开介绍 JDBC方式jdbc方式配置比较灵活，可以在DriverManager.getConnection获取连接设置属性 也可以获取到connection以后设置 获取连接时 Properties myProp = new Properties(); myProp.put(\"user\", \"ExampleUser\"); myProp.put(\"password\", \"password123\"); // Enable directBatchInsert for this connection myProp.put(\"DirectBatchInsert\", \"true\"); Connection conn; try { conn = DriverManager.getConnection( \"jdbc:vertica://VerticaHost:5433/ExampleDB\", myProp); . . . 获取连接后 ((VerticaConnection)conn).setProperty(\"DirectBatchInsert\", true); 使用HikariDataSource连接池当我们使用spring框架开发时，一般会使用数据库连接池对象，spring boot中默认的连接池是HikariCP，下面介绍HikariCP`如何配置该参数，思路可以参考使用jdbc时获取连接以后的方式。 但是又因为spring中的bean是基于proxy进行创建的，所有我们获取到的连接对象不再是VerticaConnection，而是HikariProxyConnection，但是该对象并没有setProperty()方法，所以不能使用强制类型转换并且设置该属性。 Connection connection = dataSource.getConnection(); boolean flag1 = connection instanceof com.vertica.jdbc.VerticaConnection; // false boolean flag2 = connection instanceof com.zaxxer.hikari.pool.HikariProxyConnection; //true 正确做法如下： 获取到当前连接的HikariDataSource对象，然后给该对象设置DataSourceProperties即可开启ROS，并且可以使用连接池管理jdbc连接 public DataSource config(DataSource dataSource, HikariConfig config, boolean isVertica) { HikariDataSource hikariDataSource = null; if (dataSource instanceof HikariDataSource) { // 连接池配置 hikariDataSource = (HikariDataSource) dataSource; if (isVertica) { Properties properties = new Properties(); // Loading Batches Directly into ROS Enable directBatchInsert for this connection properties.put(\"DirectBatchInsert\", \"true\"); hikariDataSource.setDataSourceProperties(properties); } hikariDataSource.setPoolName(config.getPoolName()); hikariDataSource.setAutoCommit(config.isAutoCommit()); hikariDataSource.setConnectionTestQuery(config.getConnectionTestQuery()); hikariDataSource.setIdleTimeout(config.getIdleTimeout()); hikariDataSource.setConnectionTimeout(config.getConnectionTimeout()); hikariDataSource.setMaximumPoolSize(config.getMaximumPoolSize()); hikariDataSource.setMaxLifetime(config.getMaxLifetime()); hikariDataSource.setMinimumIdle(config.getMinimumIdle()); } return hikariDataSource == null ? dataSource : hikariDataSource; }","categories":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/categories/Vertica/"}],"tags":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/tags/Vertica/"}]},{"title":"Maven加载本地jar文件","slug":"maven-install-local-jar","date":"2020-02-28T02:40:52.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/02/28/maven-install-local-jar/","link":"","permalink":"http://iogogogo.github.io/2020/02/28/maven-install-local-jar/","excerpt":"","text":"日常开发中都是maven加载在远程仓库的jar文件，如果远程仓库没有相应的jar文件，一般做法就是自己传到一个特定的nexus服务器上，但是本地开发测试的时候可能nexus服务器不太方便，那么我们可以使用maven加载本地的jar文件 mvn install:install-file -Dfile=vertica-jdbc-9.2.0.jar -DgroupId=com.vertica -DartifactId=vertica-jdbc -Dversion=9.2.0 -Dpackaging=jar 参数说明 -Dfile 指定本地jar文件的路径 -DgroupId 指定本地jar的groupId -DartifactId 指定本地jar的artifactId -Dversion 指定本地jar的version -Dpackaging 指定本地jar的packaging，这里使用的是jar，表示是一个jar文件 pom中使用&lt;dependency> &lt;groupId>com.vertica&lt;/groupId> &lt;artifactId>vertica-jdbc&lt;/artifactId> &lt;version>9.2.0&lt;/version> &lt;/dependency>","categories":[{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/tags/maven/"}]},{"title":"IntelliJ IDEA 2019 创建maven web项目","slug":"idea-web-project","date":"2020-02-26T14:51:03.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2020/02/26/idea-web-project/","link":"","permalink":"http://iogogogo.github.io/2020/02/26/idea-web-project/","excerpt":"","text":"IntelliJ IDEA 2019 创建maven web项目本文介绍使用IDEA创建不使用模板的web项目。 新建项目 配置项目修改项目结构设置 添加web moduleProject那边没有什么需要修改配置的地方，不过需要的话可以修改Project compiler output，这里我们使用默认就可以了。 此项目无任何适配服务组件（因为是手工创建Maven，没有选择任何Maven模板），因此需要我们进行添加。 这里选择一个Web组件就表示这是一个web project了 配置Web Resource Directories这里要选择scr/main目录，并且在后面手动添加一个webapp目录。 点OK，Web的资源目录便设置好了。 配置Deployment Description这一步是配置web.xml文件的位置，我们需要放在上一步webapp下面去。 修改完成的结果 到这里我们可以看到底部有一个警告，是我们还没有引入aftifact，接下来配置Aftifacts。 Aftifacts配置这个Aftifacts描述了当前项目发布的信息。现在进行添加，从Modeles中选择。 选择Modules 弹出窗直接选择我们的这个module，然后点击ok就可以了 配置完成以后的结果 再回过头去看Modules菜单下的警告也没有了。 项目结构这里我们就可以看到我们web项目必须要有的web.xml文件，并且我们在里面添加了一个welcome-file，当项目启动时打开我我们的index.html文件。 配置Tomcat下载Tomcat首先进入Tomcat官网，这里我们选择了一个Tomcat-9.0.3的版本进行下载。 配置Tomcat Server 配置Deployment 配置Server 运行web项目在webapp目录下面新建index.html文件，项目结构如下。 接下来启动项目 然后我们访问http://localhost:8080/，就可以看到显示了我们`index.html`的内容了。 新建Servletpackage com.iogogogo.servlet; import javax.servlet.ServletException; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.nio.charset.StandardCharsets; /** * Created by tao.zeng on 2020/2/26. */ @WebServlet(\"/index\") public class IndexServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 解决乱码 request.setCharacterEncoding(StandardCharsets.UTF_8.displayName()); response.setCharacterEncoding(StandardCharsets.UTF_8.name()); String name = request.getParameter(\"name\"); request.setAttribute(\"name\", name); System.out.println(name); response.getWriter().println(name); } } 然后重启项目我们在地址栏输入http://localhost:8080/index?name=哈哈哈就可以看到页面输出了哈哈哈 常见问题 无法使用servlet包下面的类 解决方案：在Modules加入Tomcat依赖","categories":[{"name":"工具使用","slug":"工具使用","permalink":"http://iogogogo.github.io/categories/工具使用/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://iogogogo.github.io/tags/Maven/"},{"name":"IDEA","slug":"IDEA","permalink":"http://iogogogo.github.io/tags/IDEA/"}]},{"title":"Spring事务管理","slug":"spring-transaction","date":"2020-02-16T06:42:08.000Z","updated":"2024-07-01T12:30:37.380Z","comments":true,"path":"2020/02/16/spring-transaction/","link":"","permalink":"http://iogogogo.github.io/2020/02/16/spring-transaction/","excerpt":"","text":"什么是事务事务是逻辑上的一组操作，要么都执行，要么都不执行。 原子性 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性 执行事务前后，数据保持一致； 持久性 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 隔离性 并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事务之间数据库是独立的； Spring 事务接口介绍 PlatformTransactionManager 事务管理器 TransactionDefinition 事务定义形象（隔离、传播、超时、只读） TransactionStatus 事务具体的运行状态 PlatformTransactionManagerSpring并不直接管理事务，而是提供了多种事务管理器 ，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 Spring事务管理器的接口是： org.springframework.transaction.PlatformTransactionManager ，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。 事务 说明 org.springframework.jdbc.datasource.DataSourceTransactionManager 使用Spring Jdbc或者MyBatis进行持久化数据时使用 org.springframework.orm.hibernate5.HibernateTransactionManager 使用Hibernate5.0版本进行持久化数据使用 org.springframework.orm.jpa.JpaTransactionManager 使用Jpa持久化使用 org.springframework.kafka.transaction.KafkaTransactionManager 使用Kafka事务时使用 TransactionDefinition事务管理器接口 PlatformTransactionManager 通过 getTransaction(TransactionDefinition definition) 方法来得到一个事务，这个方法里面的参数是 TransactionDefinition类 ，这个类就定义了一些基本的事务属性。 隔离级别在不考虑隔离性的情况下，会引发如下问题 脏度 一个事务读取了另一个事务改写但为提交的数据，如果这些数据被回滚，则独到的数据时无效的 不可重复度 在同一事务中，多次读取同一数据返回的结果不一致 幻读 一个事务读取了几行记录后，另一个事务插入一些记录，幻读就发生了 在后来的查询中，第一个事务就会发现有些原来没有的记录 隔离级别 导致的问题 ISOLATION_DEFAULT 使用数据库默认的隔离级别（spring默认） ISOLATION_READ_UNCOMMITTED 允许读取还未提交的改变了的数据，可能导致脏、幻、不可重复读 ISOLATION_READ_COMMITTED 允许在并发事务已经提交后读取。可防止脏读，但幻、不可重复读任可发生 ISOLATION_REPEATABLE_READ 对相同字段的多次读取是一致的，除非数据被事务本身改变。可防止脏、不可重复读，但幻读仍可能发生 ISOLATION_SERIALIZABLE 完全服从ACID的隔离级别，事务只能一个一个执行，避免了脏读、不可重复读、幻读。执行效率慢，使用时慎重 注：MySQL使用的是REPEATABLE_READ；Oracle使用的是READ_COMMITTED 传播行为解决业务层方法之间的相互调用的问题，事务传递方式。 常量名称 常量解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring 默认的事务的传播。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 如果事务存在，挂起当前事务，创建一个新的事务 PROPAGATION_NOT_SUPPORTED 以非事务方式运行，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效。 TransactionStatusTransactionStatus接口用来记录事务的状态 该接口定义了一组方法,用来获取或判断事务的相应状态信息. PlatformTransactionManager.getTransaction(…)方法返回一个 TransactionStatus 对象。返回的TransactionStatus 对象可能代表一个新的或已经存在的事务（如果在当前调用堆栈有一个符合条件的事务）。 Spring中的事务管理编程式的事务管理使用TransactionTemplate手动管理事务，需要修改代码，侵入性相对较大，一般不使用 声明式的事务管理TransactionProxyFactoryBean需要为每个进行事务管理的类，配置一个TransactionProxyFactoryBean进行增强处理 基于AspectJ的AOP方式（xml）早期纯粹的spring mvc配置形式，一旦配置好以后不需要修改任何代码 基于@Transactional注解方式现在spring boot常用方式，只需要在需要事务处理的类或者方法添加@Transactional。下面使用注解方式简单做一个转账的事务模拟。 使用转账模拟事务管理使用转账模拟一下事务处理，这里演示两种操作数据库的方式，用于对比查看 项目结构➜ example-transaction git:(master) ✗ tree . ├── example-transaction.iml ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── iogogogo │ │ └── transfer │ │ ├── TransferApplication.java │ │ ├── entity │ │ │ └── TransferAccount.java │ │ ├── jpa │ │ │ └── TransferRepository.java │ │ ├── mapper │ │ │ └── TransferMapper.java │ │ └── service │ │ ├── TransferService.java │ │ └── impl │ │ └── TransferServiceImpl.java │ └── resources │ ├── application.yml │ └── transfer.sql └── test └── java └── com └── iogogogo └── transfer └── TransferApplicationTests.java 新建数据库表drop table if exists transfer_account; create table transfer_account ( id int primary key auto_increment, name varchar(255) unique not null, money float default null ); insert into transfer_account (id, name, money) values (1, 'jack.zhang', 1000); insert into transfer_account (id, name, money) values (2, 'kevin.yu', 1000); select * from transfer_account; pom配置&lt;dependencies> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;version>3.3.1.tmp&lt;/version> &lt;/dependency> &lt;/dependencies> application.ymlserver: port: 8084 spring: datasource: url: jdbc:mysql://localhost:3306/transfer?characterEncoding=utf8&amp;useSSL=false&amp;allowMultiQueries=true username: root password: MySQL@123 driver-class-name: com.mysql.cj.jdbc.Driver hikari: # http://blog.didispace.com/Springboot-2-0-HikariCP-default-reason/ minimum-idle: 5 maximum-pool-size: 20 auto-commit: true idle-timeout: 30000 pool-name: TransferHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 jpa: database-platform: org.hibernate.dialect.MySQL57Dialect open-in-view: false show-sql: true hibernate: ddl-auto: update properties: hibernate: use_sql_comments: true format_sql: true logging: level: com.iogogogo.transfer.mapper: debug Jpa操作数据库package com.iogogogo.transfer.jpa; import com.iogogogo.transfer.entity.TransferAccount; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.data.jpa.repository.Modifying; import org.springframework.data.jpa.repository.Query; import org.springframework.data.repository.query.Param; import org.springframework.stereotype.Repository; /** * Created by tao.zeng on 2020/2/16. */ @Repository public interface TransferRepository extends JpaRepository&lt;TransferAccount, Long> { /** * @param in 转入人 * @param money 金额 */ @Modifying @Query(value = \"update transfer_account set money = money + ?2 where name = ?1\", nativeQuery = true) void inMoney(String in, float money); /** * @param out 转出人 * @param money 金额 */ @Modifying @Query(value = \"update transfer_account set money = money - :money where name = :name\", nativeQuery = true) void outMoney(@Param(\"name\") String out, @Param(\"money\") float money); } 业务层模拟一个转账操作package com.iogogogo.transfer.service.impl; import com.iogogogo.transfer.jpa.TransferRepository; import com.iogogogo.transfer.mapper.TransferMapper; import com.iogogogo.transfer.service.TransferService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.support.TransactionTemplate; /** * Created by tao.zeng on 2020/2/16. */ @Service public class TransferServiceImpl implements TransferService { @Autowired private TransferRepository transferRepository; @Autowired private TransferMapper transferMapper; @Autowired private TransactionTemplate transactionTemplate; @Override public void transfer(String in, String out, float money) { // 这里使用的是jpa操作数据库 transferRepository.outMoney(out, money); transferRepository.inMoney(in, money); } } 新建测试类package com.iogogogo.transfer; import com.iogogogo.transfer.service.TransferService; import lombok.extern.slf4j.Slf4j; import org.junit.Ignore; import org.junit.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.junit4.SpringRunner; /** * Created by tao.zeng on 2020/2/16. */ @Slf4j @Ignore @org.junit.runner.RunWith(SpringRunner.class) @org.springframework.boot.test.context.SpringBootTest(classes = TransferApplication.class) public class TransferApplicationTests { @Autowired private TransferService transferService; @Test public void test1() { transferService.transfer(\"jack.zhang\", \"kevin.yu\", 200); } } 但我们运行时，会抛出如下异常： org.springframework.dao.InvalidDataAccessApiUsageException: Executing an update/delete query; nested exception is javax.persistence.TransactionRequiredException: Executing an update/delete query at org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:403) at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:257) at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:528) at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:153) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:149) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) at com.sun.proxy.$Proxy99.outMoney(Unknown Source) at com.iogogogo.transfer.service.impl.TransferServiceImpl.transfer(TransferServiceImpl.java:28) at com.iogogogo.transfer.TransferApplicationTests.test1(TransferApplicationTests.java:24) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74) at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84) at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58) Caused by: javax.persistence.TransactionRequiredException: Executing an update/delete query at org.hibernate.internal.AbstractSharedSessionContract.checkTransactionNeededForUpdateOperation(AbstractSharedSessionContract.java:409) at org.hibernate.query.internal.AbstractProducedQuery.executeUpdate(AbstractProducedQuery.java:1601) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.orm.jpa.SharedEntityManagerCreator$DeferredQueryInvocationHandler.invoke(SharedEntityManagerCreator.java:409) at com.sun.proxy.$Proxy115.executeUpdate(Unknown Source) at org.springframework.data.jpa.repository.query.JpaQueryExecution$ModifyingExecution.doExecute(JpaQueryExecution.java:238) at org.springframework.data.jpa.repository.query.JpaQueryExecution.execute(JpaQueryExecution.java:88) at org.springframework.data.jpa.repository.query.AbstractJpaQuery.doExecute(AbstractJpaQuery.java:154) at org.springframework.data.jpa.repository.query.AbstractJpaQuery.execute(AbstractJpaQuery.java:142) at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.doInvoke(RepositoryFactorySupport.java:618) at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:605) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:366) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:99) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) ... 39 more 那是因为使用jpa的时候，涉及到@Modifying就表示是增删改操作，那么就必须添加@Transactional，当然如果是单纯的查询就不需要了（spring考虑的挺全面）。当加上@Transactional就可以正常运行了。 我们可以在代码上手动给他添加一个异常，再来看结果。这里我们加了一个int i = 1 / 0;会产生一个除以0的异常，因为有@Transactional的存在，整个执行是不能成功的。 @Override @Transactional public void transfer(String in, String out, float money) { // 这里使用的是jpa操作数据库 transferRepository.outMoney(out, money); int i = 1 / 0; transferRepository.inMoney(in, money); } MyBatis-Plus操作数据库package com.iogogogo.transfer.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.iogogogo.transfer.entity.TransferAccount; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Update; import org.springframework.stereotype.Repository; /** * Created by tao.zeng on 2020/2/16. */ @Repository public interface TransferMapper extends BaseMapper&lt;TransferAccount> { /** * @param in 转入人 * @param money 金额 */ @Update(\"update transfer_account set money = money + #{money} where name = #{name}\") void inMoney(@Param(\"name\") String in, @Param(\"money\") float money); /** * @param out 转出人 * @param money 金额 */ @Update(\"update transfer_account set money = money - #{money} where name = #{name}\") void outMoney(@Param(\"name\") String out, @Param(\"money\") float money); } 业务层模拟一个转账操作package com.iogogogo.transfer.service.impl; import com.iogogogo.transfer.jpa.TransferRepository; import com.iogogogo.transfer.mapper.TransferMapper; import com.iogogogo.transfer.service.TransferService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import org.springframework.transaction.support.TransactionTemplate; /** * Created by tao.zeng on 2020/2/16. */ @Service public class TransferServiceImpl implements TransferService { @Autowired private TransferRepository transferRepository; @Autowired private TransferMapper transferMapper; @Autowired private TransactionTemplate transactionTemplate; @Override public void transfer(String in, String out, float money) { // 这里使用的是MyBatis-Plus操作数据库 transferMapper.outMoney(out, money); // int i = 1 / 0; transferMapper.inMoney(in, money); } } 在没有异常情况下，就算不加@Transactional是可以直接操作成功的，但是如果 int i = 1 / 0;存在，outMoney方法还是可以正常执行的，这样就会造成钱被扣了但是对方却没有收到的情况，所以这时候就需要添加@Transactional让他进行事务处理，这里mybatis就没有jpa处理的好了。 @Transactional 介绍 参数 描述 readOnly 该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false。例如：@Transactional(readOnly=true) rollbackFor 该属性用于设置需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则进行事务回滚。例如：指定单一异常类：@Transactional(rollbackFor=RuntimeException.class)指定多个异常类：@Transactional(rollbackFor={RuntimeException.class, Exception.class}) rollbackForClassName 该属性用于设置需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时，则进行事务回滚。例如：指定单一异常类名称：@Transactional(rollbackForClassName=”RuntimeException”)指定多个异常类名称：@Transactional(rollbackForClassName={“RuntimeException”,”Exception”}) noRollbackFor 该属性用于设置不需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，不进行事务回滚。例如：指定单一异常类：@Transactional(noRollbackFor=RuntimeException.class)指定多个异常类：@Transactional(noRollbackFor={RuntimeException.class, Exception.class}) noRollbackForClassName 该属性用于设置不需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时，不进行事务回滚。例如：指定单一异常类名称：@Transactional(noRollbackForClassName=”RuntimeException”)指定多个异常类名称：@Transactional(noRollbackForClassName={“RuntimeException”,”Exception”}) propagation 该属性用于设置事务的传播行为，具体取值可参考表6-7。例如：@Transactional(propagation=Propagation.NOT_SUPPORTED,readOnly=true) isolation 该属性用于设置底层数据库的事务隔离级别，事务隔离级别用于处理多事务并发的情况，通常使用数据库的默认隔离级别即可，基本不需要进行设置 timeout 该属性用于设置事务的超时秒数，默认值为-1表示永不超时 以上参考：spring事务注解 总结以上介绍了一下spring中的事务接口和事务的传播行为以及隔离级别，也通过转账的例子演示了有事务和没有事务的区别，再有了spring boot以后，基本都是使用注解的形式进行事务处理。 源码地址：https://github.com/iogogogo/life-example/tree/master/example-transaction","categories":[{"name":"Spring","slug":"Spring","permalink":"http://iogogogo.github.io/categories/Spring/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://iogogogo.github.io/tags/spring/"},{"name":"transaction","slug":"transaction","permalink":"http://iogogogo.github.io/tags/transaction/"}]},{"title":"Spring Aop AspectJ 摘录笔记","slug":"spring-aop","date":"2020-02-16T04:41:18.000Z","updated":"2024-07-01T12:30:37.377Z","comments":true,"path":"2020/02/16/spring-aop/","link":"","permalink":"http://iogogogo.github.io/2020/02/16/spring-aop/","excerpt":"","text":"原文链接：https://juejin.im/post/5a55af9e518825734d14813f @AspectJAspectJ是一个AOP框架，它能够对java代码进行AOP编译（一般在编译期进行），让java代码具有AspectJ的AOP功能（当然需要特殊的编译器），可以这样说AspectJ是目前实现AOP框架中最成熟，功能最丰富的语言，更幸运的是，AspectJ与java程序完全兼容，几乎是无缝关联，因此对于有java编程基础的工程师，上手和使用都非常容易. 其实AspectJ单独就是一门语言，它需要专门的编译器(ajc编译器). Spring AOP 与ApectJ的目的一致，都是为了统一处理横切业务，但与AspectJ不同的是，Spring AOP并不尝试提供完整的AOP功能(即使它完全可以实现)，Spring AOP 更注重的是与Spring IOC容器的结合，并结合该优势来解决横切业务的问题，因此在AOP的功能完善方面，相对来说AspectJ具有更大的优势，同时,Spring注意到AspectJ在AOP的实现方式上依赖于特殊编译器(ajc编译器)，因此Spring很机智回避了这点，转向采用动态代理技术的实现原理来构建Spring AOP的内部机制（动态织入），这是与AspectJ（静态织入）最根本的区别。在AspectJ 1.5后，引入@Aspect形式的注解风格的开发，Spring也非常快地跟进了这种方式，因此Spring 2.0后便使用了与AspectJ一样的注解。请注意，Spring 只是使用了与 AspectJ 5 一样的注解，但仍然没有使用 AspectJ 的编译器，底层依是动态代理技术的实现，因此并不依赖于 AspectJ 的编译器。 所以，Spring AOP虽然是使用了那一套注解，其实实现AOP的底层是使用了动态代理(JDK或者CGLib)来动态植入。 切点:定位到具体方法的一个表达式 切面: 切点+建言 建言(增强):定位到方法后干什么事 前置通知 @Before前置通知通过@Before注解进行标注，并可直接传入切点表达式的值，该通知在目标函数执行前执行，注意JoinPoint，是Spring提供的静态变量，通过joinPoint 参数，可以获取目标对象的信息,如类名称,方法参数,方法名称等，该参数是可选的。 @Before(\"execution(* com.iogogogo.aop.service.*.*(..))\") public void before(JoinPoint joinPoint) { log.info(\"前置通知 CLASS_METHOD : {}\", joinPoint.getSignature().getDeclaringTypeName() + \".\" + joinPoint.getSignature().getName()); log.info(\"前置通知 ARGS : {}\", Arrays.toString(joinPoint.getArgs())); } 后置通知 @AfterReturning通过@AfterReturning注解进行标注，该函数在目标函数执行完成后执行，并可以获取到目标函数最终的返回值returnVal，当目标函数没有返回值时，returnVal将返回null，必须通过returning = “returnVal”注明参数的名称而且必须与通知函数的参数名称相同。请注意，在任何通知中这些参数都是可选的，需要使用时直接填写即可，不需要使用时，可以完成不用声明出来。当出现异常则不执行。 @AfterReturning(value = \"execution(* com.iogogogo.aop.service.*.*(..))\", returning = \"returnVal\") public void AfterReturning(JoinPoint joinPoint, Object returnVal) { log.info(\"后置通知 CLASS_METHOD : {}\", joinPoint.getSignature().getDeclaringTypeName() + \".\" + joinPoint.getSignature().getName()); log.info(\"后置通知 ARGS : {}\", Arrays.toString(joinPoint.getArgs())); log.info(\"后置通知 returnVal {} \", returnVal); } 异常通知 @AfterThrowing该通知只有在异常时才会被触发，并由throwing来声明一个接收异常信息的变量，同样异常通知也用于Joinpoint参数，需要时加上即可。 @AfterThrowing(value = \"execution(* com.iogogogo.aop.service.*.*(..))\", throwing = \"e\") public void afterThrowable(Throwable e) { log.error(\"异常: \", e); } 最终通知 @After该通知有点类似于finally代码块，只要应用了无论什么情况下都会执行。 @After(\"execution(* com.iogogogo.aop.service.*.*(..))\") public void after(JoinPoint joinPoint) { log.info(\"最终通知 CLASS_METHOD : {}\", joinPoint.getSignature().getDeclaringTypeName() + \".\" + joinPoint.getSignature().getName()); log.info(\"最终通知 ARGS : {}\", Arrays.toString(joinPoint.getArgs())); } 环绕通知 @Around环绕通知既可以在目标方法前执行也可在目标方法之后执行，更重要的是环绕通知可以控制目标方法是否指向执行，但即使如此，我们应该尽量以最简单的方式满足需求，在仅需在目标方法前执行时，应该采用前置通知而非环绕通知。第一个参数必须是ProceedingJoinPoint，通过该对象的proceed()方法来执行目标函数，proceed()的返回值就是环绕通知的返回值。同样的，ProceedingJoinPoint对象也是可以获取目标对象的信息、如类名称、方法参数、方法名称等等。 @Around(\"execution(* com.iogogogo.aop.service.*.*(..))\") public Object around(ProceedingJoinPoint joinPoint) throws Throwable { log.info(\"环绕通知前....\"); // 执行目标函数 Object obj = joinPoint.proceed(); log.info(\"环绕通知后....{}\", obj); return obj; } execution 语法// scope ：方法作用域，如public,private,protect // returnt-type：方法返回值类型 // fully-qualified-class-name：方法所在类的完全限定名称 // parameters 方法参数 execution(&lt;scope> &lt;return-type> &lt;fully-qualified-class-name>.*(parameters)) execution(* com.iogogogo.*.*(..)) com.iogogogo包下所有类的所有方法 execution(* com.iogogogo.Dog.*(..)) Dog类下的所有方 execution(* com.iogogogo.Dog*.*(..)) Dog开头的类下的所有方法 切点 @Pointcut在使用切入点时，还可以抽出来一个@Pointcut来供使用，可以避免重复的execution在不同的注解里写很多遍。 @Pointcut(\"execution(public * com.iogogogo.aop.service.*.*(..))\") public void pointcut() { } 使用 @Before(value = \"pointcut()\") public void before() { log.info(\"使用@Pointcut 的前置通知\"); } AOP切面的优先级有时候，我们对一个方法会有多个切面的问题，这个时候还会涉及到切面的执行顺序的问题。 我们可以定义每个切面的优先级， Spring 中提供注解 @Order(i) ，当 i 的值越小，优先级越高。 环绕和前后置通知的区别对于有变量缓存需求，线程安全的应用场景，前后置通知实现比较困难，而环绕通知实现就非常容易； https://www.cnblogs.com/yaphetsfang/articles/11378821.html","categories":[{"name":"Spring","slug":"Spring","permalink":"http://iogogogo.github.io/categories/Spring/"}],"tags":[{"name":"AspectJ","slug":"AspectJ","permalink":"http://iogogogo.github.io/tags/AspectJ/"},{"name":"Aop","slug":"Aop","permalink":"http://iogogogo.github.io/tags/Aop/"}]},{"title":"使用wget或者curl下载github release文件","slug":"cmd-download-file","date":"2020-02-14T04:22:38.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2020/02/14/cmd-download-file/","link":"","permalink":"http://iogogogo.github.io/2020/02/14/cmd-download-file/","excerpt":"","text":"有时候需要在服务器下载GitHub上的release资源，这时候我们可以使用wget或者curl进行处理，这里拿携程开源的配置中心Apollo为例，下载他的release版本 wgetwget --no-check-certificate --content-disposition https://github.com/ctripcorp/apollo/releases/download/v1.5.1/apollo-adminservice-1.5.1-github.zip curlcurl -LJO https://github.com/ctripcorp/apollo/releases/download/v1.5.1/apollo-adminservice-1.5.1-github.zip","categories":[{"name":"tools","slug":"tools","permalink":"http://iogogogo.github.io/categories/tools/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://iogogogo.github.io/tags/linux/"}]},{"title":"Spring Boot 2.x Redis多数据源配置","slug":"spring-boot-redis-multi-instance","date":"2020-01-10T13:53:42.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2020/01/10/spring-boot-redis-multi-instance/","link":"","permalink":"http://iogogogo.github.io/2020/01/10/spring-boot-redis-multi-instance/","excerpt":"","text":"Spring Boot 2.x版本升级以后，Redis连接库由原来的Jedis换成了Lettuce，但是提供给上层使用的api没有变化，在日常使用过程中难免会有需要使用多个库的情况，或者使用多个Redis实例，那么这个时候就需要维护两个Redis连接池或者说两个RedisTemplate。 实现思路 多数据源最终表现其实就是 RedisConnectionFactory 不同 Spring Boot 通过RedisStandaloneConfiguration维护了一套默认的RedisConnectionFactory，要实现多个实例或者使用多个db，理论上只需要自己在维护一套RedisConnectionFactory即可。 不管是Jedis或是Lettuce，都是通用的，所以我们可以将两个的实现方式都整理出来，区别如下： Lettuce使用的是LettuceConnectionFactory Jedis使用的是JedisConnectionFactory 创建Redis服务为了方便测试，直接使用docker创建一个Redis服务，以下是一个完整的启动脚本 --restart=always设置了Redis服务随着docker进程的启动而启动 -p 6379:6379 将docker启动的服务端口映射到宿主机，这里是必须的，否则宿主机和redis的端口是不能通信的 --requirepass &quot;redis&quot; 设置密码为redis --appendonly yes保存aof持久化文件 -v ~/share/docker/data/redis:/data \\ 将docker启动的redis的数据映射到宿主机目录 mkdir -p ~/share/docker/data/redis chmod 755 -R ~/share/docker/data/redis docker run -dit --restart=always --name redis \\ -v ~/share/docker/data/redis:/data \\ -p 6379:6379 \\ redis:latest redis-server --requirepass \"redis\" --appendonly yes 如果觉得不需要设置这么多，可以使用以下最简单的脚本，仅仅将端口做了映射，其他的都是最简单的配置 docker run -dit --name redis -p 6379:6379 redis:latest 关于docker的一些文章，详细请参考docker官网，这里不做过多赘述 项目pom配置使用Spring Boot集成Redis，只需要将spring-boot-starter-data-redis和commons-pool2加到依赖即可 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.commons&lt;/groupId> &lt;artifactId>commons-pool2&lt;/artifactId> &lt;/dependency> 自定义RedisConfigure这里这一步是最重要的，因为Spring Boot默认帮我们维护了一个RedisConnectionFactory，前面说了要使用不同的Redis实例就需要自己在维护一个RedisConnectionFactory，这里就以使用两个redis的database为例 配置文件spring.redis开头的都是Spring Boot自动注入需要加载的配置，我们为了在使用一个db2，这里加了一个spring.redis-db-2开头的配置 spring: redis: database: 0 host: localhost port: 6379 password: timeout: 60000 lettuce: pool: max-active: 8 # 连接池最大连接数（使用负值表示没有限制） 默认 8 max-wait: -1 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 max-idle: 8 # 连接池中的最大空闲连接 默认 8 min-idle: 0 # 连接池中的最小空闲连接 默认 0 redis-db-2: database: 2 host: 127.0.0.1 port: 6379 password: timeout: 60000 lettuce: pool: max-active: 8 max-wait: 8 max-idle: 8 min-idle: 0 RedisConfigurepackage com.iogogogo.redis.configure; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import io.vavr.Tuple; import io.vavr.Tuple6; import org.apache.commons.lang3.StringUtils; import org.apache.commons.pool2.impl.GenericObjectPoolConfig; import org.springframework.beans.factory.annotation.Value; import org.springframework.cache.annotation.EnableCaching; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.connection.RedisPassword; import org.springframework.data.redis.connection.RedisStandaloneConfiguration; import org.springframework.data.redis.connection.jedis.JedisClientConfiguration; import org.springframework.data.redis.connection.jedis.JedisConnectionFactory; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.time.Duration; /** * Created by tao.zeng on 2020-01-10. * * @Value(\"${spring.redis-db-2.database}\") int database, * @Value(\"${spring.redis-db-2.host}\") String host, * @Value(\"${spring.redis-db-2.port}\") int port, * @Value(\"${spring.redis-db-2.password}\") String password, * @Value(\"${spring.redis-db-2.timeout}\") long timeout, * @Value(\"${spring.redis-db-2.lettuce.pool.max-active}\") int maxActive, * @Value(\"${spring.redis-db-2.lettuce.pool.max-wait}\") int maxWait, * @Value(\"${spring.redis-db-2.lettuce.pool.max-idle}\") int maxIdle, * @Value(\"${spring.redis-db-2.lettuce.pool.min-idle}\") int minIdle */ @EnableCaching @Configuration public class RedisConfigure { @Bean public RedisTemplate redisTemplateDB_2(Tuple6&lt;RedisStandaloneConfiguration, Long, Integer, Integer, Integer, Integer> redisConfigurationDB_2) { Long timeout = redisConfigurationDB_2._2(); int maxActive = redisConfigurationDB_2._3(), maxWait = redisConfigurationDB_2._4(), maxIdle = redisConfigurationDB_2._5(), minIdle = redisConfigurationDB_2._6(); /* ========= 基本配置 ========= */ RedisStandaloneConfiguration standaloneConfiguration = redisConfigurationDB_2._1(); /* ========= 连接池通用配置 ========= */ GenericObjectPoolConfig genericObjectPoolConfig = new GenericObjectPoolConfig(); genericObjectPoolConfig.setMaxTotal(maxActive); genericObjectPoolConfig.setMaxWaitMillis(maxWait); genericObjectPoolConfig.setMaxIdle(maxIdle); genericObjectPoolConfig.setMinIdle(minIdle); /* ========= jedis pool ========= */ // jedisConnectionFactory(standaloneConfiguration, genericObjectPoolConfig, timeout); /* ========= lettuce pool ========= */ LettuceConnectionFactory connectionFactory = lettuceConnectionFactory(standaloneConfiguration, genericObjectPoolConfig, timeout); // 连接池初始化 connectionFactory.afterPropertiesSet(); // 创建 RedisTemplate return createRedisTemplate(connectionFactory); } /** * lettuceConnectionFactory * * @param standaloneConfiguration Redis标准配置 * @param genericObjectPoolConfig Redis通用配置 * @param timeout 超时时间 * @return */ private LettuceConnectionFactory lettuceConnectionFactory(RedisStandaloneConfiguration standaloneConfiguration, GenericObjectPoolConfig genericObjectPoolConfig, long timeout) { LettucePoolingClientConfiguration.LettucePoolingClientConfigurationBuilder builder = LettucePoolingClientConfiguration.builder(); builder.poolConfig(genericObjectPoolConfig); builder.commandTimeout(Duration.ofSeconds(timeout)); return new LettuceConnectionFactory(standaloneConfiguration, builder.build()); } /** * jedisConnectionFactory * * @param standaloneConfiguration Redis标准配置 * @param genericObjectPoolConfig Redis通用配置 * @param timeout 超时时间 * @return */ private JedisConnectionFactory jedisConnectionFactory(RedisStandaloneConfiguration standaloneConfiguration, GenericObjectPoolConfig genericObjectPoolConfig, long timeout) { JedisClientConfiguration.DefaultJedisClientConfigurationBuilder builder = (JedisClientConfiguration.DefaultJedisClientConfigurationBuilder) JedisClientConfiguration .builder(); builder.connectTimeout(Duration.ofSeconds(timeout)); builder.usePooling(); builder.poolConfig(genericObjectPoolConfig); return new JedisConnectionFactory(standaloneConfiguration, builder.build()); } /** * @param redisConnectionFactory * @return */ @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { return createRedisTemplate(redisConnectionFactory); } /** * json 实现 redisTemplate * &lt;p> * 该方法不能加 @Bean 否则不管如何调用，RedisConnectionFactory 都会是默认配置 * * @param redisConnectionFactory * @return */ private RedisTemplate createRedisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate&lt;String, Object> redisTemplate = new RedisTemplate&lt;>(); redisTemplate.setConnectionFactory(redisConnectionFactory); Jackson2JsonRedisSerializer&lt;Object> jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;>(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.setKeySerializer(stringRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } /** * 自定义Redis的配置加载 * * @param database * @param password * @param host * @param port * @param timeout * @param maxActive * @param maxWait * @param maxIdle * @param minIdle * @return */ @Bean public Tuple6&lt;RedisStandaloneConfiguration, Long, Integer, Integer, Integer, Integer> redisConfigurationDB_2(@Value(\"${spring.redis-db-2.database}\") int database, @Value(\"${spring.redis-db-2.password}\") String password, @Value(\"${spring.redis-db-2.host}\") String host, @Value(\"${spring.redis-db-2.port}\") int port, @Value(\"${spring.redis-db-2.timeout}\") long timeout, @Value(\"${spring.redis-db-2.lettuce.pool.max-active}\") int maxActive, @Value(\"${spring.redis-db-2.lettuce.pool.max-wait}\") int maxWait, @Value(\"${spring.redis-db-2.lettuce.pool.max-idle}\") int maxIdle, @Value(\"${spring.redis-db-2.lettuce.pool.min-idle}\") int minIdle) { RedisStandaloneConfiguration standaloneConfiguration = new RedisStandaloneConfiguration(); standaloneConfiguration.setDatabase(database); standaloneConfiguration.setHostName(host); standaloneConfiguration.setPort(port); if (StringUtils.isNotEmpty(password)) { RedisPassword redisPassword = RedisPassword.of(password); standaloneConfiguration.setPassword(redisPassword); } return Tuple.of(standaloneConfiguration, timeout, maxActive, maxWait, maxIdle, minIdle); } } 这个配置有点长，但是都有注释，而且这里也用到了上篇文章中讲到的tuple（在方法有多个返回值时，元组真香）,其实就已经可以使用两个不同的RedisTemplate了，这时候我们在启动项目时分别注入redisTemplate和redisTemplateDB_2，别问我为啥名字是这两货。 通过debug查看配置是否成功启动类我们实现CommandLineRunner，然后通过debug查看redisTemplate和redisTemplateDB2的RedisConnectionFactory 并且我们在database=0存储了一个string数据，在database=2存储了一个hash数据 package com.iogogogo.redis; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.data.redis.core.RedisTemplate; /** * Created by tao.zeng on 2020-01-10. */ @Slf4j @SpringBootApplication public class RedisApplication implements CommandLineRunner { @Autowired private RedisTemplate redisTemplate; @Autowired private RedisTemplate redisTemplateDB_2; public static void main(String[] args) { SpringApplication.run(RedisApplication.class, args); } @Override public void run(String... args) { log.info(\"redisTemplate:{}\", redisTemplate); redisTemplate.opsForValue().set(\"iogogogo\", \"redisTemplate save value\"); log.info(\"redisTemplateDB_2:{}\", redisTemplateDB2); redisTemplateDB2.opsForHash().put(\"iogogogo\", \"iogogogo-hash\", \"redisTemplateDB_2 save value\"); } } redisTemplate redisTemplateDB_2 登录redis查看两个Template存储的string和hash数据 使用RedisDesktopManager连接到我们新建的redis服务，并且查看数据 使用redis-cli查看 因为我们的redis服务是docker启动的，所以要使用redis-cli查看就需要进入docker容器内进行查看，进入容器也很简单，使用docker exec -it fd3da052e6f1 bash，这里的fd3da052e6f1是docker启动的containerId，可以使用docker ps查看 root@fd3da052e6f1:/data# redis-cli 127.0.0.1:6379> 127.0.0.1:6379> keys * 1) \"iogogogo\" 127.0.0.1:6379> get iogogogo \"\\\"redisTemplate save value\\\"\" 127.0.0.1:6379> 127.0.0.1:6379> 127.0.0.1:6379> select 2 # 选择2这个数据库 OK 127.0.0.1:6379[2]> 127.0.0.1:6379[2]> 127.0.0.1:6379[2]> keys * 1) \"iogogogo\" 127.0.0.1:6379[2]> HVALS iogogogo 1) \"\\xac\\xed\\x00\\x05t\\x00\\x1bredisTemplateDB2 save value\" 127.0.0.1:6379[2]> 127.0.0.1:6379[2]> 通过以上日志我们可以看到分别在不同的数据库已经存储了不同的数据，到这里我们redis配置多实例就已经完成。但是我们每次注入的时候都要记得自己创建的Bean的名字，这样对其他人不太友好，那么我们可以进一步封装一下，自定义一个handler进行获取RedisTemplate，这样会不会更便捷呢？ 自定义RedisHandler和RedisOperations 做这一步主要是为了将下层的RedisTemplate进行统一的封装，对外只是一个RedisHandler和RedisOperations，RedisHandler提供获取RedisOperations的方法，RedisOperations里面可以封装一些常用的redis操作，这样就只需要和RedisOperations进行操作，从而避免同时操作多个RedisTemplate 项目结构 ➜ example-redis git:(master) ✗ tree ./ ./ ├── example-redis.iml ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── iogogogo │ │ └── redis │ │ ├── RedisApplication.java │ │ └── configure │ │ ├── RedisConfigure.java │ │ ├── handler │ │ │ └── RedisHandler.java │ │ └── util │ │ └── RedisOperations.java │ └── resources │ └── application.yml └── test └── java RedisOperations 该类可以作为redis的工具类使用，自己添加一些常用的方法 package com.iogogogo.redis.configure.util; import lombok.extern.slf4j.Slf4j; import org.springframework.data.redis.core.RedisTemplate; /** * Created by tao.zeng on 2020-01-10. */ @Slf4j public class RedisOperations { private RedisTemplate redisTemplate; private RedisOperations() { } public RedisOperations(RedisTemplate redisTemplate) { this.redisTemplate = redisTemplate; } public RedisTemplate redisTemplate() { return redisTemplate; } } RedisHandler RedisHandler提供了统一操作RedisTemplate的入口，对用户来说下层的RedisTemplate是谁就不需要关心了 package com.iogogogo.redis.configure.handler; import com.iogogogo.redis.configure.util.RedisOperations; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Component; /** * Created by tao.zeng on 2020-01-10. */ @Component public class RedisHandler { @Autowired private RedisTemplate redisTemplate; @Autowired private RedisTemplate redisTemplateDB_2; private RedisOperations redisOperations, redisDB2Operations; public RedisOperations redisOperations() { if (redisOperations == null) { redisOperations = new RedisOperations(redisTemplate); } return redisOperations; } public RedisOperations redisDB2Operations() { if (redisDB2Operations == null) { redisDB2Operations = new RedisOperations(redisTemplateDB_2); } return redisDB2Operations; } } 最终结果我们在启动时看一下经过RedisHandler保证的RedisTemplate是否和我们想的一致，修改以后的启动类 package com.iogogogo.redis; import com.iogogogo.redis.configure.handler.RedisHandler; import com.iogogogo.redis.configure.util.RedisOperations; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.data.redis.core.RedisTemplate; /** * Created by tao.zeng on 2020-01-10. */ @Slf4j @SpringBootApplication public class RedisApplication implements CommandLineRunner { @Autowired private RedisTemplate redisTemplate; @Autowired private RedisTemplate redisTemplateDB_2; @Autowired private RedisHandler redisHandler; public static void main(String[] args) { SpringApplication.run(RedisApplication.class, args); } @Override public void run(String... args) { log.info(\"redisTemplate:{}\", redisTemplate); redisTemplate.opsForValue().set(\"iogogogo\", \"redisTemplate save value\"); log.info(\"redisTemplateDB_2:{}\", redisTemplateDB_2); redisTemplateDB_2.opsForHash().put(\"iogogogo\", \"iogogogo-hash\", \"redisTemplateDB_2 save value\"); // 通过统一的RedisOperations对Redis进行操作 // 这里可以自己封装一些常用的方法，这样就能把下层的RedisTemplate进行封装，对外仅仅只是一个RedisOperations而已 // 当然这里也提供对应的方法获取不同RedisTemplate对象最后的封装实例 RedisOperations redisOperations = redisHandler.redisOperations(); RedisOperations redisDB2Operations = redisHandler.redisDB2Operations(); log.info(\"redisOperations redisTemplate:{}\", redisOperations.redisTemplate()); log.info(\"redisDB2Operations redisTemplate:{}\", redisDB2Operations.redisTemplate()); } } 启动日志 2020-01-10 23:54:39.579 INFO 66673 --- [ main] com.iogogogo.redis.RedisApplication : Started RedisApplication in 8.672 seconds (JVM running for 10.951) 2020-01-10 23:54:39.580 INFO 66673 --- [ main] com.iogogogo.redis.RedisApplication : redisTemplate:org.springframework.data.redis.core.RedisTemplate@44924587 2020-01-10 23:54:39.679 INFO 66673 --- [ main] io.lettuce.core.EpollProvider : Starting without optional epoll library 2020-01-10 23:54:39.682 INFO 66673 --- [ main] io.lettuce.core.KqueueProvider : Starting without optional kqueue library 2020-01-10 23:54:39.910 INFO 66673 --- [ main] com.iogogogo.redis.RedisApplication : redisTemplateDB2:org.springframework.data.redis.core.RedisTemplate@7fb66650 2020-01-10 23:54:39.927 INFO 66673 --- [ main] com.iogogogo.redis.RedisApplication : redisOperations redisTemplate:org.springframework.data.redis.core.RedisTemplate@44924587 2020-01-10 23:54:39.929 INFO 66673 --- [ main] com.iogogogo.redis.RedisApplication : redisDB2Operations redisTemplate:org.springframework.data.redis.core.RedisTemplate@7fb66650 通过日志我们可以看到 redisTemplate和redisOperations redisTemplate是同一个对象 redisTemplateDB2 和redisDB2Operations redisTemplate也是同一个对象 总结通过本文，我们可以看到一个项目如果需要使用使用多个redis连接获取使用不同的数据库，完全可以使用自定义RedisConnectionFactory来完成，第二点就是如果定义的RedisTemplate过多，我们可以在上面定义一个RedisHandler来进行封装下层的API操作，暴露一个统一的入口进行简化处理。 参考链接：https://www.bbsmax.com/A/lk5aAmO251/ 示例代码：https://github.com/iogogogo/life-example/tree/master/example-redis","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://iogogogo.github.io/tags/Redis/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Java中使用元组","slug":"java-tuple","date":"2020-01-09T04:26:39.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2020/01/09/java-tuple/","link":"","permalink":"http://iogogogo.github.io/2020/01/09/java-tuple/","excerpt":"","text":"元组（Tuple）是固定数量的不同类型的元素的组合。元组与集合的不同之处在于，元组中的元素类型可以是不同的，而且数量固定。元组的好处在于可以把多个元素作为一个单元传递。如果一个方法需要返回多个值，可以把这多个值作为元组返回，而不需要创建额外的类来表示。根据元素数量的不同，Vavr 总共提供了 Tuple0、Tuple1 到 Tuple8 等 9 个类。每个元组类都需要声明其元素类型。如 Tuple2&lt;String, Integer&gt;表示的是两个元素的元组，第一个元素的类型为 String，第二个元素的类型为 Integer。对于元组对象，可以使用 _1、_2 到 _8 来访问其中的元素。所有元组对象都是不可变的，在创建之后不能更改。 元组通过接口 Tuple 的静态方法 of 来创建。元组类也提供了一些方法对它们进行操作。由于元组是不可变的，所有相关的操作都返回一个新的元组对象。在 清单 1 中，使用 Tuple.of 创建了一个 Tuple2 对象。Tuple2 的 map 方法用来转换元组中的每个元素，返回新的元组对象。而 apply 方法则把元组转换成单个值。其他元组类也有类似的方法。除了 map 方法之外，还有 map1、map2、map3 等方法来转换第 N 个元素；update1、update2 和 update3 等方法用来更新单个元素。 Python和Scala语言中有自带元组，Jdk中是没有这个数据类型的，虽然使用数组或者map也能达到想要的效果，但总归是没有元组方便。 比如说一个方法有多个返回值时，虽然可以用Object[]或者Map进行封装，但是在拆箱的时候类型会缺失，所以还是不太方便。Java中有很多元组库，这里推荐一个我经常使用的vavr，当然Tuple只是这个库中的一小部分，该库提供了强大的函数式编程的能力，可以像写Scala一样写Java 引入pom依赖目前最新的稳定版是0.10.2 &lt;!-- https://mvnrepository.com/artifact/io.vavr/vavr --> &lt;dependency> &lt;groupId>io.vavr&lt;/groupId> &lt;artifactId>vavr&lt;/artifactId> &lt;version>0.10.2&lt;/version> &lt;/dependency> 常用方法使用创建元组对象@Test public void test1() { Tuple3&lt;String, LocalDateTime, Long> tuple3 = Tuple.of(\"TupleTests\", LocalDateTime.now(), Long.MAX_VALUE); System.out.println(tuple3); } 可以看到我们通过Tuple.of创建了一个有三个元素的元组对象，输出结果 (TupleTests, 2020-01-09T20:40:26.137, 9223372036854775807) 更新元组内容@Test public void test1() { Tuple3&lt;String, LocalDateTime, Long> tuple3 = Tuple.of(\"TupleTests\", LocalDateTime.now(), Long.MAX_VALUE); System.out.println(tuple3); tuple3 = tuple3.update1(\"哈哈哈哈\"); System.out.println(tuple3); } 通过update1-n方法，可以实现元组内容的更新，更新结果 (TupleTests, 2020-01-09T20:42:27.623, 9223372036854775807) (哈哈哈哈, 2020-01-09T20:42:27.623, 9223372036854775807) 方法多个返回值使用元组接收这个需求其实之前在Java8 处理常见的日期周期这篇文章已经用过了，比如我们需要获取一个周期数据，有开始和结束，那么元组无疑是最好的选择。比如我们需要封装一个方法获取今天的最小时间和最大时间，那么这里就需要两个返回值，虽然我们可以用Object[]或者Map之类的容器达到我们的效果，但是如果我返回值得类型都不尽想同，那么在获取的时候就要进行类型转换，加到了转换出错的概率，但是使用元组就不会有这个问题。 获取一天的开始和结束时间 public Tuple2&lt;LocalDateTime, LocalDateTime> getNowRange() { LocalDate now = LocalDate.now(); // 一天中从零时开始 LocalDateTime startTime = now.atTime(LocalTime.MIN); // 一天到23:59:59秒结束 LocalDateTime endTime = now.atTime(LocalTime.MAX); return Tuple.of(startTime, endTime); } 获取返回值 @Test public void test2() { Tuple2&lt;LocalDateTime, LocalDateTime> tuple2 = getNowRange(); // 这里通过 _n 或者 _n() 获取每一个元组中的一列数据 System.out.println(\"开始时间:\" + tuple2._1()); System.out.println(\"结束时间:\" + tuple2._2); } 我们可以看到getNowRange同时有两个放回值，通过Tuple2进行保存，过 _n 或者 _n() 获取每一个元组中的一列数据。最后获取的结果为 开始时间:2020-01-09T00:00 结束时间:2020-01-09T23:59:59.999999999 总结以上就是元组最常用的一些方法，其实我理解的元组就是一种列式存储的数据容器，和我们平时用的Collection接口下的一些List，Set不同，他们都是以行的形式存储，有了Tuple以后，在日常开发中也多了一种数据在内存中存储的选择。 当然元组只是vavr库中的一小部分，更多使用方法还是要看官方文档 参考文章：使用 Vavr 进行函数式编程","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"CentOS7 安装 MySQL5.7.X","slug":"software-install-mysql5-7-x-centos7","date":"2020-01-08T11:31:55.000Z","updated":"2024-07-01T12:30:37.377Z","comments":true,"path":"2020/01/08/software-install-mysql5-7-x-centos7/","link":"","permalink":"http://iogogogo.github.io/2020/01/08/software-install-mysql5-7-x-centos7/","excerpt":"","text":"安装前准备MySQL安装需要准备root账户 卸载MariaDB相关组件 由于MariaDB与MySQL类似，在安装时候会提示与已经安装的RPM包有冲突，因此需要卸载一些包含有MariaDB关键字的RPM包。 执行rpm -qa | grep mysql检查需要卸载的包 执行rpm -qa | grep mariadb检查需要卸载的包 如发现存在mariadb与mysql则使用rpm -e --nodeps xxx进行卸载 [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -qa | grep mariadb # 检查mariadb mariadb-libs-5.5.64-1.el7.x86_64 # 如有就进行卸载 [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -e --nodeps mariadb-libs-5.5.64-1.el7.x86_64 下载安装文件这里我直接在官网拿到了MySQL5.7.28的下载地址，通过wget进行下载 wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar 解压安装文件这里解压文件以后，直接放到新文件夹mysql-5.7.28-1.el7.x86_64了，可以看到目录下面有很多rpm包 tar xvf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar -C mysql-5.7.28-1.el7.x86_64 [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# ll 总用量 595272 -rw-r--r-- 1 7155 31415 45109364 9月 30 16:04 mysql-community-client-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 318768 9月 30 16:04 mysql-community-common-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 7037096 9月 30 16:04 mysql-community-devel-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 49329100 9月 30 16:04 mysql-community-embedded-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 23354908 9月 30 16:04 mysql-community-embedded-compat-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 136837816 9月 30 16:04 mysql-community-embedded-devel-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 4374364 9月 30 16:04 mysql-community-libs-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 1353312 9月 30 16:04 mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 208694824 9月 30 16:05 mysql-community-server-5.7.28-1.el7.x86_64.rpm -rw-r--r-- 1 7155 31415 133129992 9月 30 16:05 mysql-community-test-5.7.28-1.el7.x86_64.rpm 开始安装检查3306端口MySQL默认使用3306端口，安装前查看端口是否被占用 netstat -anp|grep 3306 安装相应的rpm包 mysql-community-common-5.7.28-1.el7.x86_64.rpm mysql-community-libs-5.7.28-1.el7.x86_64.rpm mysql-community-client-5.7.28-1.el7.x86_64.rpm mysql-community-server-5.7.28-1.el7.x86_64.rpm 以上四个文件按照顺序依次安装，顺序不能错乱 rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm 以下为安装日志，只要之前的mariadb和mysql卸载干净了，一般不会有问题 [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm 警告：mysql-community-common-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-common-5.7.28-1.e################################# [100%] [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm 警告：mysql-community-libs-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-libs-5.7.28-1.el7################################# [100%] [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm 警告：mysql-community-client-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-client-5.7.28-1.e################################# [100%] [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm 警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-server-5.7.28-1.e################################# [100%] 后续工作启动MySQL服务systemctl start mysqld 查看MySQL服务状态systemctl status mysqld 输出日志 [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# systemctl status mysqld ● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 三 2020-01-08 21:02:06 CST; 6s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 22483 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 22450 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 22486 (mysqld) Tasks: 27 Memory: 193.8M CGroup: /system.slice/mysqld.service └─22486 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.468981Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.469015Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.470439Z 0 [Warning] CA certificate ca.pem is self signed. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.470543Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.471329Z 0 [Note] Server hostname (bind-address): '*'; port: 3306 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.471412Z 0 [Note] IPv6 is available. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.471436Z 0 [Note] - '::' resolves to '::'; 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.471467Z 0 [Note] Server socket created on IP: '::'. 1月 08 21:02:06 vm31_123 mysqld[22483]: 2020-01-08T13:02:06.485478Z 0 [Note] Event Scheduler: Loaded 0 events 1月 08 21:02:06 vm31_123 systemd[1]: Started MySQL Server. 修改默认密码查看MySQL安装成功以后生成的零时密码sudo cat /var/log/mysqld.log |grep 'temporary password' 输出结果，可以看到我们的mysql零时密码是;2o1:2h%!ruT [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# sudo cat /var/log/mysqld.log |grep 'temporary password' 2020-01-08T12:21:09.914526Z 1 [Note] A temporary password is generated for root@localhost: ;2o1:2h%!ruT 使用零时密码登录修改输入mysql -uroot -p以后会提示我们输入密码，这时候输入刚刚生成的零时密码;2o1:2h%!ruT即可登录 接下来就可以使用ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MySQL@123&#39;;（此处MySQL@123为数据库密码，根据需求自行设置更改） [root@vm31_123 mysql-5.7.28-1.el7.x86_64]# mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.28 Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'MySQL@123'; Query OK, 0 rows affected (0.00 sec) mysql> 设置外部IP访问MySQL为了能够让外部访问数据库，需要将root的Host值改为’%’，具体步骤如下： 查看允许连接到本数据库的信息，执行命令select host,user from mysql.user; 默认root只能通过localhost连接，不能远程访问。 选择数据库：use mysql; 先执行：update user set Host=&#39;%&#39; where User=&#39;root&#39;; 再执行:flush privileges; # 刷新权限 mysql> use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> update user set Host='%' where User='root'; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> flush privileges; Query OK, 0 rows affected (0.00 sec) mysql> 当设置完host=%以后，就可以使用我们熟悉navicat或者sequel进行连接了 修改MySQL默认编码为utf8当我们MySQL安装完成以后，默认编码不一定是utf8，虽然在建库建表的时候可以指定，但是始终不方便，那么接下来我们将MySQL默认编码设置为utf8 查看MySQL默认编码使用show variables like &#39;character_set_%&#39;; mysql> show variables like 'character_set_%'; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | latin1 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 可以看到character_set_server这里是latin1，并不是我们想要的utf8，这时候我们就需要编辑/etc/my.cnf文件进行设置 编辑my.cnf文件sudo vim /etc/my.cnf进行编辑，加入以下内容，然后保存重启MySQL服务systemctl restart mysqld 注意：my.cnf中默认包含[mysqld]，修改的时候就在原来的基础上改就好了，不要重复了 [client] default-character-set=utf8 [mysqld] collation-server = utf8_unicode_ci init-connect='SET NAMES utf8' character-set-server = utf8 [mysql] default-character-set=utf8 再次查看修改以后的编码mysql> show variables like 'character_set_%'; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 到这里，MySQL的默认编码就是我么熟悉的utf8了 忘记MySQL密码当忘记MySQL密码或者MySQL密码错误是会提示错误ERROR 1045 (28000): Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES) 如果找不到MySQL密码时可以使用跳过mysql权限表启动的方式进行密码重置 停止MySQL服务 systemctl stop mysqld 跳过mysql权限表启动 /usr/bin/mysqld_safe --skip-grant-tables 无密码登录 mysql -uroot 选择mysql数据库 use mysql; 重置密码 update user set authentication_string=password('MySQL@123') where user='root'; 刷新权限 flush privileges; 常见问题 修改默认配置，当插入或更新的数据比较大时，需要修改/etc/my.cnf配置文件 在[mysqlId]下加上 max_allowed_packet=20M (可以通过 mysql –help | grep my.cnf查找文件路径) 当重启服务器后，MySQL无法正常启动，遇到以下问题 Job for mysqld.service failed. See &#39;systemctl status mysqld.service&#39; and &#39;journalctl -xn&#39; for details. 查看日志，出现如下错误内容： [ERROR] /usr/sbin/mysqld: Can't create/write to file '/var/run/mysqld/mysqld.pid' (Errcode: 2 - No such file or directory) [ERROR] Can't start server: can't create PID file: No such file or directory Copy 解决方案： ##授权 chown mysql.mysql /var/run/mysqld/ ##启动 /etc/init.d/mysqld start","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"Java8 中的日期类序列化问题","slug":"java8-date-gson","date":"2020-01-07T13:59:27.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2020/01/07/java8-date-gson/","link":"","permalink":"http://iogogogo.github.io/2020/01/07/java8-date-gson/","excerpt":"","text":"自从习惯了使用Java8 中的日期类以后，就已经完全抛弃了java.sql、java.util中的日期处理类，但是Java8中的日期类在序列化与反序列化时不是我们正常看到的标准格式，这里记录一下如何使用Gson进行序列化和反序列化时正常对Java8的日期类进行处理 默认序列化结果这里写了一个很简单的test，对LocalDate、LocalDateTime进行序列化与反序列化 package com.iogogogo; import com.google.gson.Gson; import lombok.Data; import lombok.extern.slf4j.Slf4j; import org.junit.Test; import java.io.Serializable; import java.time.LocalDate; import java.time.LocalDateTime; /** * Created by tao.zeng on 2020-01-07. */ @Slf4j public class Java8DateTests { @Test public void test1() { DateMetric dateMetric = new DateMetric(); dateMetric.setLocalDate(LocalDate.now()); dateMetric.setLocalDateTime(LocalDateTime.now()); // serializer Gson gson = new Gson(); String json = gson.toJson(dateMetric); log.info(\"serializer:{}\", json); // deserializer log.info(\"deserializer:{}\", gson.fromJson(json, DateMetric.class)); } @Data private class DateMetric implements Serializable { private LocalDate localDate; private LocalDateTime localDateTime; } } 查看结果，可以看到反序列化的结果是我们自己想要的，但是序列化的结果并不是我们想要的yyyy-MM-dd HH:mm:ss 这种格式，那么这时候就需要用到GsonBuilder来注册registerTypeAdapter 22:09:01.345 [main] INFO com.iogogogo.Java8DateTests - serializer:{\"localDate\":{\"year\":2020,\"month\":1,\"day\":7},\"localDateTime\":{\"date\":{\"year\":2020,\"month\":1,\"day\":7},\"time\":{\"hour\":22,\"minute\":9,\"second\":1,\"nano\":271000000}}} 22:09:01.356 [main] INFO com.iogogogo.Java8DateTests - deserializer:Java8DateTests.DateMetric(localDate=2020-01-07, localDateTime=2020-01-07T22:09:01.271) 自定义序列化与反序列化的Adapter/** * 处理LocalDate的序列化与反序列化 */ final static class LocalDateAdapter implements JsonSerializer&lt;LocalDate>, JsonDeserializer&lt;LocalDate> { public JsonElement serialize(LocalDate date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE)); } @Override public LocalDate deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDate.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE); } } /** * 处理LocalDateTime序列化与反序列化 */ final static class LocalDateTimeAdapter implements JsonSerializer&lt;LocalDateTime>, JsonDeserializer&lt;LocalDateTime> { public JsonElement serialize(LocalDateTime date, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(date.format(DateTimeFormatter.ISO_LOCAL_DATE_TIME)); } @Override public LocalDateTime deserialize(JsonElement element, Type type, JsonDeserializationContext context) throws JsonParseException { String timestamp = element.getAsJsonPrimitive().getAsString(); return LocalDateTime.parse(timestamp, DateTimeFormatter.ISO_LOCAL_DATE_TIME); } } 使用GsonBuilder创建gson对象@Test public void test2() { DateMetric dateMetric = new DateMetric(); dateMetric.setLocalDate(LocalDate.now()); dateMetric.setLocalDateTime(LocalDateTime.now()); // serializer Gson gson = new GsonBuilder() .registerTypeAdapter(LocalDate.class, new LocalDateAdapter()) .registerTypeAdapter(LocalDateTime.class, new LocalDateTimeAdapter()) .create(); String json = gson.toJson(dateMetric); log.info(\"serializer:{}\", json); // deserializer log.info(\"deserializer:{}\", gson.fromJson(json, DateMetric.class)); } 结果 22:16:15.738 [main] INFO com.iogogogo.Java8DateTests - serializer:{\"localDate\":\"2020-01-07\",\"localDateTime\":\"2020-01-07T22:16:15.662\"} 22:16:15.745 [main] INFO com.iogogogo.Java8DateTests - deserializer:Java8DateTests.DateMetric(localDate=2020-01-07, localDateTime=2020-01-07T22:16:15.662) 输出json进行格式化处理平时输出的json都是一行文本，如果需要对json的输出结果需要进行格式化处理的话，也可以使用GsonBuilder的setPrettyPrinting()方法 @Test public void test2() { DateMetric dateMetric = new DateMetric(); dateMetric.setLocalDate(LocalDate.now()); dateMetric.setLocalDateTime(LocalDateTime.now()); // serializer Gson gson = new GsonBuilder() .setPrettyPrinting() // 设置输出格式格式化显示 .registerTypeAdapter(LocalDate.class, new LocalDateAdapter()) .registerTypeAdapter(LocalDateTime.class, new LocalDateTimeAdapter()) .create(); String json = gson.toJson(dateMetric); log.info(\"serializer:\\n{}\", json); // deserializer log.info(\"deserializer:{}\", gson.fromJson(json, DateMetric.class)); } 输出结果 22:21:03.307 [main] INFO com.iogogogo.Java8DateTests - serializer: { \"localDate\": \"2020-01-07\", \"localDateTime\": \"2020-01-07T22:21:03.218\" } 22:21:03.313 [main] INFO com.iogogogo.Java8DateTests - deserializer:Java8DateTests.DateMetric(localDate=2020-01-07, localDateTime=2020-01-07T22:21:03.218) 对已有的json进行格式化处理如果我们的json文本已经存在，那我我们想通过gson进行格式化展示该怎么做呢？ 这里做法也很简单，不过JsonObject和JsonArray略有区别，不过都是需要将json读取成JsonObject或者JsonArray对象 JsonObject 格式化原始JsonObject数据 {\"localDate\":{\"year\":2020,\"month\":1,\"day\":7},\"localDateTime\":{\"date\":{\"year\":2020,\"month\":1,\"day\":7},\"time\":{\"hour\":22,\"minute\":9,\"second\":1,\"nano\":271000000}}} @Test public void jsonObjectFormatter() { JsonObject jsonObject = JsonParser.parseString(JSON_STRING).getAsJsonObject(); Gson gson = new GsonBuilder().setPrettyPrinting().create(); System.out.println(gson.toJson(jsonObject)); } 输出结果： { \"localDate\": { \"year\": 2020, \"month\": 1, \"day\": 7 }, \"localDateTime\": { \"date\": { \"year\": 2020, \"month\": 1, \"day\": 7 }, \"time\": { \"hour\": 22, \"minute\": 9, \"second\": 1, \"nano\": 271000000 } } } JsonArray 格式化原始JsonArray数据 [{\"localDate\":{\"year\":2020,\"month\":1,\"day\":7},\"localDateTime\":{\"date\":{\"year\":2020,\"month\":1,\"day\":7},\"time\":{\"hour\":22,\"minute\":9,\"second\":1,\"nano\":271000000}}}] @Test public void jsonArrayFormatter() { JsonArray jsonArray = JsonParser.parseString(JSON_STRING_ARRAY).getAsJsonArray(); Gson gson = new GsonBuilder().setPrettyPrinting().create(); System.out.println(gson.toJson(jsonArray)); } 输出结果： [ { \"localDate\": { \"year\": 2020, \"month\": 1, \"day\": 7 }, \"localDateTime\": { \"date\": { \"year\": 2020, \"month\": 1, \"day\": 7 }, \"time\": { \"hour\": 22, \"minute\": 9, \"second\": 1, \"nano\": 271000000 } } } ] 总结本文主要介绍了使用Gson对Java8中的日志进行序列化与反序列化格式的处理，以及使用gson对json进行格式化的输出。 参考地址：Serialize Java 8 LocalDate as yyyy-mm-dd with Gson 完整代码：Java8DateTests","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/tags/Gson/"},{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Spring Boot 整合kafka","slug":"spring-boot-kafka","date":"2020-01-06T15:28:32.000Z","updated":"2024-07-01T12:30:37.378Z","comments":true,"path":"2020/01/06/spring-boot-kafka/","link":"","permalink":"http://iogogogo.github.io/2020/01/06/spring-boot-kafka/","excerpt":"","text":"关于kafka的介绍这里就不在过多说明，可以看之前写过一遍文章使用docker-compose构建kafka集群 文章里面有关于kafka的一些介绍以及环境搭建，文章中的环境搭建是基于docker和docker-compose的，如果不想通过docker构建，也可以直接下载kafka的安装包直接在机器上启动，之前的文章链接kafka常用操作笔记。这里也不再叙述，今天主要来看Spring Boot中如何对接kafka进行数据的消费与生产。 配置POM第一步当然是先引入pom依赖 &lt;dependency> &lt;groupId>org.springframework.kafka&lt;/groupId> &lt;artifactId>spring-kafka&lt;/artifactId> &lt;/dependency> 配置kafka基本信息spring: kafka: bootstrap-servers: localhost:9092 # 多个使用`,`隔开 producer: key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer retries: 0 # 失败重试次数 batch-size: 16384 buffer-memory: 33554432 acks: -1 # 取值 all, -1, 0, 1 consumer: enable-auto-commit: true auto-commit-interval: 5000 group-id: group-test auto-offset-reset: earliest # 消费offset取值earliest,latest,none（默认：latest） key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer # 自定义producer topic kafka: producer: topic: test-producer 详细的配置介绍：spring-kafka生产者消费者配置详解 启动zookeeper和kafka服务启动zookeeper./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties 启动kafka./bin/kafka-server-start.sh -daemon config/server.properties 通过jps检查进程 ➜ kafka_2.11-2.3.0 jps 27442 40473 QuorumPeerMain # zookeeper进程 40795 Kafka # kafka进程 40847 Jps 生产消息为了方便看数据，我们定义一个Metric类，用来保存数据，并每隔3s往kafka服务器发送一次数据，并且在程序启动以后，通过CommandLineRunner初始化发送 metric类 import com.google.gson.annotations.SerializedName; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.io.Serializable; import java.time.LocalDateTime; import java.util.Map; /** * Created by tao.zeng on 2020-01-07. */ @Data @NoArgsConstructor @AllArgsConstructor public class Metric implements Serializable { private String hostname; private long total; @SerializedName(\"succ_cnt\") private long succCnt; @SerializedName(\"succ_rate\") private float succRate; private int status; private LocalDateTime timestamp; private Map&lt;String, Object> tags; } Spring Boot启动类 import com.google.common.collect.Maps; import com.iogogogo.common.util.DecimalUtils; import com.iogogogo.common.util.IdHelper; import com.iogogogo.common.util.JsonParse; import com.iogogogo.kafka.pojo.Metric; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.kafka.core.KafkaTemplate; import java.time.LocalDateTime; import java.util.Map; import java.util.Random; import java.util.concurrent.TimeUnit; /** * Created by tao.zeng on 2020-01-06. * 动态配置多个topic * https://github.com/spring-projects/spring-kafka/issues/361 */ public class KafkaApplication implements CommandLineRunner { @Autowired private KafkaTemplate kafkaTemplate; /** * 这里对应我们在yml中自定义的配置，用于获取发送数据用的topic */ @Value(\"${kafka.producer.topic}\") private String producerTopic; public static void main(String[] args) { SpringApplication.run(KafkaApplication.class, args); } @Override public void run(String... args) throws Exception { Random random = new Random(); while (true) { writer2Kafka(random); // 每隔3s向kafka发送数据 TimeUnit.SECONDS.sleep(3); } } private void writer2Kafka(Random random) { Metric metric = new Metric(); metric.setHostname(\"NODE-\" + IdHelper.id()); metric.setTotal(random.nextInt(10000)); metric.setSuccCnt(random.nextInt(9900)); float v = DecimalUtils.divide(metric.getSuccCnt(), metric.getTotal()); metric.setSuccRate(v); metric.setStatus(random.nextInt(2)); metric.setTimestamp(LocalDateTime.now()); Map&lt;String, Object> tagMap = Maps.newHashMap(); tagMap.put(\"cpu_util\", random.nextFloat() * 100); tagMap.put(\"mem_util\", random.nextFloat() * 100); metric.setTags(tagMap); kafkaTemplate.send(producerTopic, JsonParse.toJson(metric)); kafkaTemplate.flush(); } } 启动程序后，如果topic不存在则会自动创建topic（我们并没有关闭自动创建topic），通过kafka-consumeer命令可以看到topic中的数据 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-producer --from-beginning # 样例数据 {\"hostname\":\"NODE-55\",\"total\":6704,\"succ_cnt\":1441,\"succ_rate\":0.2149463,\"status\":0,\"timestamp\":\"2020-01-07T21:29:21.501\",\"tags\":{\"mem_util\":5.2691402,\"cpu_util\":97.53448}} {\"hostname\":\"NODE-23\",\"total\":9579,\"succ_cnt\":2191,\"succ_rate\":0.22872952,\"status\":0,\"timestamp\":\"2020-01-07T21:29:25.422\",\"tags\":{\"mem_util\":27.203756,\"cpu_util\":43.626713}} {\"hostname\":\"NODE-8\",\"total\":6889,\"succ_cnt\":786,\"succ_rate\":0.114094935,\"status\":0,\"timestamp\":\"2020-01-07T21:29:28.428\",\"tags\":{\"mem_util\":18.526094,\"cpu_util\":87.67309}} {\"hostname\":\"NODE-142\",\"total\":8753,\"succ_cnt\":4227,\"succ_rate\":0.48292014,\"status\":0,\"timestamp\":\"2020-01-07T21:29:31.436\",\"tags\":{\"mem_util\":87.426476,\"cpu_util\":12.49879}} {\"hostname\":\"NODE-198\",\"total\":2261,\"succ_cnt\":4251,\"succ_rate\":1.8801415,\"status\":0,\"timestamp\":\"2020-01-07T21:29:34.444\",\"tags\":{\"mem_util\":5.665392,\"cpu_util\":69.29729}} {\"hostname\":\"NODE-46\",\"total\":2846,\"succ_cnt\":6600,\"succ_rate\":2.3190444,\"status\":0,\"timestamp\":\"2020-01-07T21:29:37.451\",\"tags\":{\"mem_util\":66.49958,\"cpu_util\":18.604118}} {\"hostname\":\"NODE-47\",\"total\":5110,\"succ_cnt\":9650,\"succ_rate\":1.888454,\"status\":1,\"timestamp\":\"2020-01-07T21:29:40.459\",\"tags\":{\"mem_util\":92.13784,\"cpu_util\":60.55072}} Processed a total of 195 messages 通过命令，我们可以看到kafka中已经有新写进去的数据，那么我们在Spring Boot中又该如何对数据进行消费呢？ 消费消息生产数据很简单，消费数据也不难，主要使用Spring Boot提供的注解@KafkaListener，这时候我们需要自定义一个consumer类，刚刚我们是往test-producer这个topic里面写，现在通过程序消费这个topic @KafkaListener 常用的参数 topic 设置消费的topic groupId 指定消费组 MetricConsumer import com.iogogogo.common.util.JsonParse; import com.iogogogo.kafka.pojo.Metric; import lombok.extern.slf4j.Slf4j; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; import java.util.Optional; /** * Created by tao.zeng on 2020-01-07. */ @Slf4j @Component public class MetricConsumer { @KafkaListener(topics = \"test-producer\") public void event(ConsumerRecord&lt;String, String> record) { Optional&lt;String> kafkaMessage = Optional.ofNullable(record.value()); kafkaMessage.ifPresent(x -> { Metric metric = JsonParse.parse(x, Metric.class); log.info(\"消费kafka中的数据:{}\", metric); }); } } 消费到的数据结果 2020-01-07 21:38:10.646 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-128, total=7849, succCnt=9252, succRate=1.1787488, status=1, timestamp=2020-01-07T21:38:10.639, tags={mem_util=83.20216, cpu_util=2.36848}) 2020-01-07 21:38:13.651 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-199, total=3799, succCnt=595, succRate=0.15662016, status=0, timestamp=2020-01-07T21:38:13.647, tags={mem_util=37.34904, cpu_util=56.30006}) 2020-01-07 21:38:16.662 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-82, total=2797, succCnt=3004, succRate=1.0740079, status=1, timestamp=2020-01-07T21:38:16.654, tags={mem_util=87.53287, cpu_util=53.029602}) 2020-01-07 21:38:19.671 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-102, total=3232, succCnt=3041, succRate=0.9409035, status=0, timestamp=2020-01-07T21:38:19.664, tags={mem_util=87.7293, cpu_util=51.062298}) 2020-01-07 21:38:22.679 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-173, total=904, succCnt=759, succRate=0.83960176, status=0, timestamp=2020-01-07T21:38:22.672, tags={mem_util=3.923422, cpu_util=36.679466}) 2020-01-07 21:38:25.685 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-4, total=2250, succCnt=8072, succRate=3.5875556, status=1, timestamp=2020-01-07T21:38:25.681, tags={mem_util=71.37522, cpu_util=2.6286244}) 2020-01-07 21:38:28.696 INFO 42501 --- [ntainer#0-0-C-1] c.i.kafka.consumer.MetricConsumer : 消费kafka中的数据:Metric(hostname=NODE-87, total=2798, succCnt=3955, succRate=1.4135096, status=0, timestamp=2020-01-07T21:38:28.689, tags={mem_util=98.27863, cpu_util=23.622477}) 但是大家发现了一点，就是我们的topic都是写死在程序里面的，不能动态传递读取配置文件，这样的肯定是不可以的，那么如何动态配置又是一个新的问题，有人可能会说这里使用@Value进行注入，但是实际这样是编译不过去的，因为注解属性的值必须是一个constant，解决方法就是使用SPEL表达式 Issues地址：动态配置多个topic 修改以后的代码 package com.iogogogo.kafka.consumer; import com.iogogogo.common.util.JsonParse; import com.iogogogo.kafka.pojo.Metric; import lombok.extern.slf4j.Slf4j; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; import java.util.Optional; /** * Created by tao.zeng on 2020-01-07. * &lt;p> * 动态配置多个topic * * https://github.com/spring-projects/spring-kafka/issues/361 */ @Slf4j @Component public class MetricConsumer { /** * 注意这里的topic配置 * 当然groupId也可以使用SPEL表达书进行配置，这里就不在赘述 * * @param record */ @KafkaListener(topics = \"#{'${kafka.producer.topic}'}\", groupId = \"metric-group\") public void event(ConsumerRecord&lt;String, String> record) { Optional&lt;String> kafkaMessage = Optional.ofNullable(record.value()); kafkaMessage.ifPresent(x -> { Metric metric = JsonParse.parse(x, Metric.class); log.info(\"消费kafka中的数据:{}\", metric); }); } } 修改完成，重启进程，查看依旧可以正常消费到数据，并且topic是动态配置的，如果需要配置多个使用spilt进行分割即可 总结本文主要介绍了Spring Boot与kafka 的整合，日常开发中除了kafka还有其他的各种消息中间件，整合方式大同小异，毕竟Spring Boot已经帮我们封装的很好了，唯一需要注意的就是注解属性的动态注入，这里需要使用SPEL表达式。 完整代码：https://github.com/iogogogo/life-example/tree/master/example-kafka","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"},{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/tags/Kafka/"}]},{"title":"Spring Boot 使用jpa和H2数据库","slug":"spring-boot-jpa-h2","date":"2020-01-05T09:44:18.000Z","updated":"2024-07-01T12:30:37.377Z","comments":true,"path":"2020/01/05/spring-boot-jpa-h2/","link":"","permalink":"http://iogogogo.github.io/2020/01/05/spring-boot-jpa-h2/","excerpt":"","text":"日常测试时没有数据库可用时，使用H2不失为一种解决方案，而且H2也经常用在持久层的单元测试，Spring Boot中使用H2也很简单，只要一些配置即可。 项目结构与pom.xml先看看整体的项目结构 ➜ example-h2 git:(master) ✗ tree /Users/tao.zeng/share/life-example/example-h2 /Users/tao.zeng/share/life-example/example-h2 ├── example-h2.iml ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── example │ │ └── h2 │ │ ├── H2DbApplication.java │ │ ├── entity │ │ │ └── UserEntity.java │ │ └── repository │ │ └── UserRepository.java │ └── resources │ ├── application.yml │ └── db │ ├── data.sql │ └── schema.sql └── test └── java └── com └── iogogogo └── h2 └── H2DbApplicationTests.java 15 directories, 9 files 这里使用H2数据，为了方便测试也使用jpa进行数据库操作，第一步肯定是需要引入maven依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-jpa&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.h2database&lt;/groupId> &lt;artifactId>h2&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;/dependency> 创建数据库脚本与初始化数据脚本 schema.sql create table user_info ( id bigint auto_increment primary key not null, name varchar(255) not null, birthday datetime not null, remark varchar(2048) default null ); data.sql insert into user_info values (1, '阿牛', '2020-01-05 15:40:00', '哈哈哈'); 配置文件server: port: 8081 spring: datasource: url: jdbc:h2:mem:h2-test;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE username: sa password: platform: h2 driver-class-name: org.h2.Driver hikari: # http://blog.didispace.com/Springboot-2-0-HikariCP-default-reason/ minimum-idle: 5 maximum-pool-size: 20 auto-commit: true idle-timeout: 30000 pool-name: H2HikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 schema: classpath:db/schema.sql data: classpath:db/data.sql jpa: database-platform: org.hibernate.dialect.H2Dialect show-sql: true hibernate: ddl-auto: update properties: hibernate: use_sql_comments: true format_sql: true h2: console: # 进行该配置，程序开启时就会启动h2 web console。当然这是默认的，如果你不想在启动程序时启动h2 web console，那么就设置为false。 enabled: true # 进行该配置，你就可以通过 URL/h2-console访问h2 web console。 path: /h2-console settings: trace: false # 进行该配置后，h2 web console 就可以在远程访问了。否则只能在本机访问。 web-allow-others: false application.yml中，分别有datasource、jpa、h2等配置 datasouce其中url使用了h2的配置连接字符串，并且使用了hikari数据库连接池，详细信息请查看Springboot 2.0选择HikariCP作为默认数据库连接池的五大理由 jpajpa中配置了数据库方言database-platform，显示sql等配置 h2spring.datasource.schema=classpath:db/schema.sql进行该配置后，每次启动程序，程序都会运行resources/db/schema.sql文件，对数据库的结构进行操作。 spring.datasource.data=classpath:db/data.sql进行该配置后，每次启动程序，程序都会运行resources/db/data.sql文件，对数据库的数据操作。 h2 web console配置h2 web console是一个数据库GUI管理应用，就和phpMyAdmin类似。程序运行时，会自动启动h2 web console。当然你也可以进行如下的配置。 spring.h2.console.settings.web-allow-others=true，进行该配置后，h2 web console就可以在远程访问了。否则只能在本机访问。 spring.h2.console.path=/h2-console，进行该配置，你就可以通过 URL/h2-console访问h2 web console。 spring.h2.console.enabled=true，进行该配置，程序开启时就会启动h2 web console。当然这是默认的，如果你不想在启动程序时启动h2 web console，那么就设置为false。 实体类package com.example.h2.entity; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import javax.persistence.Column; import javax.persistence.Entity; import javax.persistence.Id; import javax.persistence.Table; import java.io.Serializable; import java.time.LocalDateTime; /** * Created by tao.zeng on 2020-01-05. */ @Data @Entity @NoArgsConstructor @AllArgsConstructor @Table(name = \"user_info\") public class UserEntity implements Serializable { @Id private Long id; private String name; @Column(name = \"birthday\") private LocalDateTime birthday; private String remark; public UserEntity(String name, LocalDateTime birthday, String remark) { this.name = name; this.birthday = birthday; this.remark = remark; } } repositorypackage com.example.h2.repository; import com.example.h2.entity.UserEntity; import org.springframework.data.jpa.repository.JpaRepository; /** * Created by tao.zeng on 2020-01-05. */ public interface UserRepository extends JpaRepository&lt;UserEntity, Long> { } 测试为了方便查看结果，写一个测试类查看结果 import com.example.h2.H2DbApplication; import com.example.h2.entity.UserEntity; import com.example.h2.repository.UserRepository; import lombok.extern.slf4j.Slf4j; import org.junit.Ignore; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.time.LocalDateTime; import java.util.Optional; import java.util.UUID; /** * Created by tao.zeng on 2020-01-05. */ @Slf4j @Ignore @RunWith(SpringRunner.class) @SpringBootTest(classes = H2DbApplication.class) public class H2DbApplicationTests { @Autowired private UserRepository userRepository; @Test public void test() { // 新增数据 UserEntity entity = userRepository.save(new UserEntity(\"阿牛\" + UUID.randomUUID().toString(), LocalDateTime.now(), \"新增测试\")); log.info(\"新增结果:{}\\n\", entity); // 修改数据 entity = userRepository.save(new UserEntity(1L, \"哈哈哈哈\", LocalDateTime.now(), \"修改以后的结果\")); log.info(\"按照id修改结果:{}\\n\", entity); // 按照id查询 Optional&lt;UserEntity> optional = userRepository.findById(1L); optional.ifPresent(x -> log.info(\"按照id查询结果:{}\\n\", x)); // 查询所有 log.info(\"查询所有\"); Iterable&lt;UserEntity> iterable = userRepository.findAll(); iterable.forEach(x -> log.info(\"item:{}\", x)); // 删除数据 userRepository.deleteById(1L); // 删除id=1的数据以后 System.out.println(); log.info(\"删除id=1的数据以后\"); iterable = userRepository.findAll(); iterable.forEach(x -> log.info(\"item:{}\", x)); } } 测试结果如下 2020-01-05 18:07:40.499 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : 新增结果:UserEntity(id=2, name=阿牛33dc0a6d-29cd-4e79-9ae4-ad64b1588e69, birthday=2020-01-05T18:07:40.383, remark=新增测试) 2020-01-05 18:07:40.527 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : 按照id修改结果:UserEntity(id=1, name=哈哈哈哈, birthday=2020-01-05T18:07:40.500, remark=修改以后的结果) 2020-01-05 18:07:40.578 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : 按照id查询结果:UserEntity(id=1, name=哈哈哈哈, birthday=2020-01-05T18:07:40.500, remark=修改以后的结果) 2020-01-05 18:07:40.578 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : 查询所有 2020-01-05 18:07:40.586 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : item:UserEntity(id=1, name=哈哈哈哈, birthday=2020-01-05T18:07:40.500, remark=修改以后的结果) 2020-01-05 18:07:40.586 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : item:UserEntity(id=2, name=阿牛33dc0a6d-29cd-4e79-9ae4-ad64b1588e69, birthday=2020-01-05T18:07:40.383, remark=新增测试) 2020-01-05 18:07:40.602 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : 删除id=1的数据以后 2020-01-05 18:07:40.604 INFO 28214 --- [ main] com.iogogogo.h2.H2DbApplicationTests : item:UserEntity(id=2, name=阿牛33dc0a6d-29cd-4e79-9ae4-ad64b1588e69, birthday=2020-01-05T18:07:40.383, remark=新增测试) 完整代码https://github.com/iogogogo/life-example/tree/master/example-h2","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Java8 处理常见的日期周期","slug":"java8-date-cycle","date":"2020-01-04T05:56:18.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2020/01/04/java8-date-cycle/","link":"","permalink":"http://iogogogo.github.io/2020/01/04/java8-date-cycle/","excerpt":"","text":"日常开发中，经常会有获取周、月、季度的开始和结束时间的需求，Java8之前的date类和Calendar结合也可以实现，但是还是比较复杂，下面使用Java8的日期api获取周月季的周期。 获取当前是周几LocalDateTime now = LocalDateTime.now(); System.out.println(now); System.out.println(now.getDayOfWeek().getValue()); // 输出结果 2020-01-04T14:07:15.870 6 获取当前周的开始和结束时间LocalDateTime now = LocalDateTime.now(); System.out.println(\"当前时间:\" + now + \"\\n\"); //当前时间减去今天是周几() LocalDateTime startTime = now.minusDays(now.getDayOfWeek().getValue()); //当前时间加上（8-今天周几） LocalDateTime endTime = now.plusDays(8 - now.getDayOfWeek().getValue()); System.out.println(\"本周开始时间:\" + startTime); System.out.println(\"本周结束时间:\" + endTime); // 输出结果 当前时间:2020-01-04T14:14:56.110 本周开始时间:2019-12-29T14:14:56.110 本周结束时间:2020-01-06T14:14:56.110 但是发现一个问题，以上获取到的结果一周开始是从周天开始的，并不是我们日常的习惯从周一开始，那么要从周一开始可以使用WeekFields设置一周的开始是周几 LocalDateTime now = LocalDateTime.now(); System.out.println(\"当前时间:\" + now + \"\\n\"); // 使用WeekFields设置一周的开始为周一 TemporalField fieldISO = WeekFields.of(DayOfWeek.MONDAY, 1).dayOfWeek(); LocalDateTime startTime = now.with(fieldISO, 1); LocalDateTime endTime = now.with(fieldISO, 7); System.out.println(\"本周开始时间:\" + startTime); System.out.println(\"本周结束时间:\" + endTime); // 输出结果 当前时间:2020-01-04T14:17:13.176 本周开始时间:2019-12-30T14:17:13.176 本周结束时间:2020-01-05T14:17:13.176 以上两种方式可以获取到本周的开始和结束时间，但是如果我们需要一周从00点开始，到23:59:59秒结束，又该如何设置呢？ 其实也很简单，只需要在LocalDateTime对象的 LocalTime即可 LocalDateTime now = LocalDateTime.now(); System.out.println(\"当前时间:\" + now + \"\\n\"); // 使用WeekFields设置一周的开始为周一 TemporalField fieldISO = WeekFields.of(DayOfWeek.MONDAY, 1).dayOfWeek(); // 设置开始时间为LocalTime.MIN LocalDateTime startTime = now.with(fieldISO, 1).with(LocalTime.MIN); // 设置结束时间为LocalTime.MAX LocalDateTime endTime = now.with(fieldISO, 7).with(LocalTime.MAX); System.out.println(\"本周开始时间:\" + startTime); System.out.println(\"本周结束时间:\" + endTime); // 输出结果 当前时间:2020-01-04T14:22:01.291 本周开始时间:2019-12-30T00:00 本周结束时间:2020-01-05T23:59:59.999999999 获取本月的开始和结束时间如果不需要时间归到00点和23:59:59，则不设置LocalTime即可 LocalDateTime now = LocalDateTime.now(); System.out.println(\"当前时间:\" + now + \"\\n\"); LocalDateTime startTime = now.with(TemporalAdjusters.firstDayOfMonth()).with(LocalTime.MIN); LocalDateTime endTime = now.with(TemporalAdjusters.lastDayOfMonth()).with(LocalTime.MAX); System.out.println(\"本月开始时间:\" + startTime); System.out.println(\"本月结束时间:\" + endTime); // 输出结果 当前时间:2020-01-04T14:27:33.706 本月开始时间:2020-01-01T00:00 本月结束时间:2020-01-31T23:59:59.999999999 获取一个季度的开始和结果获取季度的开始和结束Java8并没有提供直接的api使用，但是我们可以使用TemporalQuery进行自定义查询获取，而且季度和月度以及周有些许不同，每年的季度开始和结束都是固定的 一季度的始终是每年的01.01-03.31 二季度的始终是每年的04.01-06.30 三季度的始终是每年的07.01-09.30 四季度的始终是每年的10.01-12.31 废话不多说，直接上代码，先定义了一个QuarterCycle类 getQuarterRange方法中使用了Tuple，主要是为了方便存储开始和结束时间，也可以使用LocalDateTime[]存储，并没有特殊意义 QuarterCycle import io.vavr.Tuple; import io.vavr.Tuple2; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.LocalTime; import java.time.Month; import java.time.temporal.TemporalAccessor; import java.time.temporal.TemporalQuery; /** * Created by tao.zeng on 2020-01-03. */ public class QuarterCycle { /** * 定义四个季度枚举值 */ enum QuarterEnum { FIRST, SECOND, THIRD, FOURTH } class QuarterOfYearQuery implements TemporalQuery&lt;QuarterEnum> { @Override public QuarterEnum queryFrom(TemporalAccessor temporal) { LocalDate now = LocalDate.from(temporal); if (now.isBefore(now.with(Month.APRIL).withDayOfMonth(1))) { return QuarterEnum.FIRST; } else if (now.isBefore(now.with(Month.JULY).withDayOfMonth(1))) { return QuarterEnum.SECOND; } else if (now.isBefore(now.with(Month.OCTOBER).withDayOfMonth(1))) { return QuarterEnum.THIRD; } else { return QuarterEnum.FOURTH; } } } /** * 根据 LocalDateTime 获取季度 * * @param dateTime * @return */ public int getQuarter(LocalDateTime dateTime) { return getQuarter(dateTime.toLocalDate()); } /** * 根据 LocalDate 获取季度 * * @param date * @return */ public int getQuarter(LocalDate date) { TemporalQuery&lt;QuarterEnum> quarterOfYearQuery = new QuarterOfYearQuery(); QuarterEnum quarter = date.query(quarterOfYearQuery); switch (quarter) { case FIRST: return 1; case SECOND: return 2; case THIRD: return 3; case FOURTH: return 4; } return 0; } public Tuple2&lt;LocalDateTime, LocalDateTime> getQuarterRange(LocalDateTime dateTime, int quarter) { return getQuarterRange(dateTime.getYear(), quarter); } public Tuple2&lt;LocalDateTime, LocalDateTime> getQuarterRange(LocalDate dateTime, int quarter) { return getQuarterRange(dateTime.getYear(), quarter); } /** * 获取某年某季度的第一天和最后一天 * * @param year 哪一年 * @param quarter 第几季度 */ public Tuple2&lt;LocalDateTime, LocalDateTime> getQuarterRange(int year, int quarter) { LocalDate startDate, endDate; switch (quarter) { case 1: // 01.01-03.31 startDate = LocalDate.of(year, 1, 1); endDate = LocalDate.of(year, 3, 31); break; case 2: // 04.01-06.30 startDate = LocalDate.of(year, 4, 1); endDate = LocalDate.of(year, 6, 30); break; case 3: // 07.01-09.30 startDate = LocalDate.of(year, 7, 1); endDate = LocalDate.of(year, 9, 30); break; case 4: // 10.01-12.31 startDate = LocalDate.of(year, 10, 1); endDate = LocalDate.of(year, 12, 31); break; default: throw new RuntimeException(\"quarter range [1-4]\"); } return Tuple.of(startDate.atTime(LocalTime.MIN), endDate.atTime(LocalTime.MAX)); } } 测试代码QuarterCycle quarterCycle = new QuarterCycle(); LocalDateTime now = LocalDateTime.now(); System.out.println(\"当前时间:\" + now + \"\\n\"); int quarter = quarterCycle.getQuarter(now); System.out.println(\"当前季度:\" + quarter + \"\\n\"); Tuple2&lt;LocalDateTime, LocalDateTime> tuple2 = quarterCycle.getQuarterRange(now, quarter); System.out.println(\"当前季度开始和结束时间:\" + tuple2 + \"\\n\"); // 输出结果 当前时间:2020-01-04T15:17:43.949 当前季度:1 当前季度开始和结束时间:(2020-01-01T00:00, 2020-03-31T23:59:59.999999999) 常用方法整理 方法 作用 adjustInto 调整指定的Temporal和当前LocalDateTime对 atOffset 结合LocalDateTime和ZoneOffset创建一个 atZone 结合LocalDateTime和指定时区创建一个ZonedD compareTo 比较两个LocalDateTime format 格式化LocalDateTime生成一个字符串 from 转换TemporalAccessor为LocalDateTime get 得到LocalDateTime的指定字段的值 getDayOfMonth 得到LocalDateTime是月的第几天 getDayOfWeek 得到LocalDateTime是星期几 getDayOfYear 得到LocalDateTime是年的第几天 getHour 得到LocalDateTime的小时 getLong 得到LocalDateTime指定字段的值 getMinute 得到LocalDateTime的分钟 getMonth 得到LocalDateTime的月份 getMonthValue 得到LocalDateTime的月份，从1到12 getNano 得到LocalDateTime的纳秒数 getSecond 得到LocalDateTime的秒数 getYear 得到LocalDateTime的年份 isAfter 判断LocalDateTime是否在指定LocalDateTime之后 isBefore 判断LocalDateTime是否在指定LocalDateTime之前 isEqual 判断两个LocalDateTime是否相等 isSupported 判断LocalDateTime是否支持指定时间字段或单元 minus 返回LocalDateTime减去指定数量的时间得到的值 minusDays 返回LocalDateTime减去指定天数得到的值 minusHours 返回LocalDateTime减去指定小时数得到的值 minusMinutes 返回LocalDateTime减去指定分钟数得到的值 minusMonths 返回LocalDateTime减去指定月数得到的值 minusNanos 返回LocalDateTime减去指定纳秒数得到的值 minusSeconds 返回LocalDateTime减去指定秒数得到的值 minusWeeks 返回LocalDateTime减去指定星期数得到的值 minusYears 返回LocalDateTime减去指定年数得到的值 now 返回指定时钟的当前LocalDateTime of 根据年、月、日、时、分、秒、纳秒等创建LocalDateTime ofEpochSecond 根据秒数(从1970-01-0100:00:00开始)创建LocalDateTime ofInstant 根据Instant和ZoneId创建LocalDateTime parse 解析字符串得到LocalDateTime plus 返回LocalDateTime加上指定数量的时间得到的值 plusDays 返回LocalDateTime加上指定天数得到的值 plusHours 返回LocalDateTime加上指定小时数得到的值 plusMinutes 返回LocalDateTime加上指定分钟数得到的值 plusMonths 返回LocalDateTime加上指定月数得到的值 plusNanos 返回LocalDateTime加上指定纳秒数得到的值 plusSeconds 返回LocalDateTime加上指定秒数得到的值 plusWeeks 返回LocalDateTime加上指定星期数得到的值 plusYears 返回LocalDateTime加上指定年数得到的值 query 查询LocalDateTime range 返回指定时间字段的范围 toLocalDate 返回LocalDateTime的LocalDate部分 toLocalTime 返回LocalDateTime的LocalTime部分 toString 返回LocalDateTime的字符串表示 truncatedTo 返回LocalDateTime截取到指定时间单位的拷贝 until 计算LocalDateTime和另一个LocalDateTime with 返回LocalDateTime指定字段更改为新值后的拷贝 withDayOfMonth 返回LocalDateTime月的第几天更改为新值后的拷贝 withDayOfYear 返回LocalDateTime年的第几天更改为新值后的拷贝 withHour 返回LocalDateTime的小时数更改为新值后的拷贝 withMinute 返回LocalDateTime的分钟数更改为新值后的拷贝 withMonth 返回LocalDateTime的月份更改为新值后的拷贝 withNano 返回LocalDateTime的纳秒数更改为新值后的拷贝 withSecond 返回LocalDateTime的秒数更改为新值后的拷贝 withYear 返回LocalDateTime年份更改为新值后的拷贝","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Swagger2 常用注解","slug":"swagger-annotation","date":"2020-01-03T12:15:43.000Z","updated":"2024-07-01T12:30:37.380Z","comments":true,"path":"2020/01/03/swagger-annotation/","link":"","permalink":"http://iogogogo.github.io/2020/01/03/swagger-annotation/","excerpt":"","text":"Spring Boot 开发restful接口时，往往会有很多RESTful API，一般会选择swagger对接口进行管理 Spring Boot添加swagger支持&lt;dependency> &lt;groupId>io.springfox&lt;/groupId> &lt;artifactId>springfox-swagger2&lt;/artifactId> &lt;version>2.9.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>io.springfox&lt;/groupId> &lt;artifactId>springfox-swagger-ui&lt;/artifactId> &lt;version>2.9.2&lt;/version> &lt;/dependency> 配置类 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.ParameterBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.schema.ModelRef; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Parameter; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.util.List; import java.util.stream.Collectors; import java.util.stream.Stream; @Configuration @EnableSwagger2 public class Swagger2Configuration { @Bean public Docket createRestApi() { // 构建一个header ParameterBuilder parameterBuilder = new ParameterBuilder() .parameterType(\"header\") .name(BaseConst.AUTH_TOKEN) .defaultValue(null) .description(\"token\") .modelRef(new ModelRef(\"string\")) .required(false); List&lt;Parameter> parameters = Stream.of(parameterBuilder.build()).collect(Collectors.toList()); return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()).globalOperationParameters(parameters).select() .apis(RequestHandlerSelectors.basePackage(\"com.iogogogo\")) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"RESTful APIs\") .description(\"描述\") .termsOfServiceUrl(\"\").contact(new Contact(\"name\", \"url\", \"email\")) .version(\"1.0\") .build(); } } 注解详细说明 属性 取值 作用 作用范围 @API 使用位置 对象属性 @ApiModelProperty 用在出入参数对象的字段上 协议集描述 @Api 用于controller类上 协议描述 @ApiOperation 用在controller的方法上 Response集 @ApiResponses 用在controller的方法上 Response @ApiResponse 用在 @ApiResponses里边 非对象参数集 @ApiImplicitParams 用在controller的方法上 非对象参数描述 @ApiImplicitParam 用在@ApiImplicitParams的方法里边 描述返回对象的意义 @ApiModel 用在返回对象类上 标记@RequestBody @ApiParam 用在方法参数 @ApiImplicitParam 属性 取值 作用 paramType 查询参数类型 path 以地址的形式提交数据 query 直接跟参数完成自动映射赋值 body 以流的形式提交 仅支持POST header 参数在request headers 里边提交 form 以form表单的形式提交 仅支持POST dataType 参数的数据类型 只作为标志说明 不会验证 Long String Integer name 接收参数名 value 接收参数的意义描述 required 参数是否必填 true 必填 false 非必填 defaultValue 默认值","categories":[{"name":"Swagger","slug":"Swagger","permalink":"http://iogogogo.github.io/categories/Swagger/"}],"tags":[{"name":"Swagger","slug":"Swagger","permalink":"http://iogogogo.github.io/tags/Swagger/"}]},{"title":"maven归档插件assembly介绍","slug":"maven-assembly","date":"2020-01-02T12:19:25.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2020/01/02/maven-assembly/","link":"","permalink":"http://iogogogo.github.io/2020/01/02/maven-assembly/","excerpt":"","text":"2020年的第一篇文章，祝大家新年快乐！ assembly插件主要用于对打包以后的文件进行归档处理，比如项目中的jar，配置文件，脚本…. 打包需要归档到一起时，就可以使用maven-assembly-plugin。assembly使用很简单，第一是需要添加对应的maven插件，第二就是添加assembly需要归档的描述文件 项目结构这里用之前的一个介绍的maven多模块项目配置来进行配置 ➜ life-multi-module git:(master) ✗ tree . ├── HELP.md ├── life-multi-module.iml ├── multi-api │ ├── multi-api.iml │ ├── pom.xml │ └── src │ ├── assembly │ │ └── assembly-descriptor.xml │ ├── main │ │ ├── java │ │ │ └── com │ │ │ └── iogogogo │ │ │ └── MainApplication.java │ │ ├── java-templates │ │ │ └── com │ │ │ └── iogogogo │ │ │ └── Version.java │ │ └── resources │ │ └── git.properties │ └── test │ └── java ├── multi-common │ ├── multi-common.iml │ ├── pom.xml │ └── src │ ├── main │ │ ├── java │ │ │ └── com │ │ │ └── iogogogo │ │ │ └── common │ │ │ ├── CommonApplication.java │ │ │ └── util │ │ │ └── IdHelper.java │ │ └── resources │ └── test │ └── java ├── mvnw ├── mvnw.cmd └── pom.xml 添加maven配置如果是在多模块项目下，该配置放在对应模块下，不要放在parent pom.xml中，示例放在./multi-api/pom.xml &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-assembly-plugin&lt;/artifactId> &lt;version>3.1.0&lt;/version> &lt;executions> &lt;execution> &lt;!-- 在package任务以后执行 --> &lt;phase>package&lt;/phase> &lt;goals> &lt;goal>single&lt;/goal> &lt;/goals> &lt;configuration> &lt;!-- 生产压缩包名称 --> &lt;finalName>${project.artifactId}-${project.version}-${timestamp}&lt;/finalName> &lt;appendAssemblyId>false&lt;/appendAssemblyId> &lt;!-- assembly配置描述文件 --> &lt;descriptors> &lt;descriptor>src/assembly/assembly-descriptor.xml&lt;/descriptor> &lt;/descriptors> &lt;/configuration> &lt;/execution> &lt;/executions> &lt;/plugin> assembly配置描述文件&lt;assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\"> &lt;id>release&lt;/id> &lt;formats> &lt;format>tar.gz&lt;/format> &lt;format>zip&lt;/format> &lt;/formats> &lt;includeBaseDirectory>false&lt;/includeBaseDirectory> &lt;fileSets> &lt;fileSet> &lt;directory>../docs/bin&lt;/directory> &lt;outputDirectory>multi-api&lt;/outputDirectory> &lt;fileMode>0755&lt;/fileMode> &lt;includes> &lt;include>*.sh&lt;/include> &lt;/includes> &lt;/fileSet> &lt;fileSet> &lt;directory>../docs&lt;/directory> &lt;outputDirectory>multi-api&lt;/outputDirectory> &lt;includes> &lt;include>db/*&lt;/include> &lt;include>db/*/*&lt;/include> &lt;/includes> &lt;/fileSet> &lt;fileSet> &lt;directory>target&lt;/directory> &lt;outputDirectory>multi-api&lt;/outputDirectory> &lt;includes> &lt;include>*.jar&lt;/include> &lt;include>lib/*&lt;/include> &lt;/includes> &lt;/fileSet> &lt;fileSet> &lt;directory>src/main/resources&lt;/directory> &lt;outputDirectory>multi-api&lt;/outputDirectory> &lt;includes> &lt;include>logback-spring.xml&lt;/include> &lt;include>application.properties&lt;/include> &lt;/includes> &lt;/fileSet> &lt;fileSet> &lt;directory>../&lt;/directory> &lt;outputDirectory>multi-api&lt;/outputDirectory> &lt;includes> &lt;include>*.MD&lt;/include> &lt;/includes> &lt;/fileSet> &lt;/fileSets> &lt;/assembly> 配置描述文件介绍 id id 标识符，添加到生成文件名称的后缀符。如果指定 id 的话，目标文件则是 ${artifactId}-${id}.tar.gz formats maven-assembly-plugin 支持的打包格式有zip、tar、tar.gz (or tgz)、tar.bz2 (or tbz2)、jar、dir、war，可以同时指定多个打包格式 includeBaseDirectory 解压时是否讲当前压缩包名称作为文件夹名称 fileSets 管理一组文件的存放位置，核心元素如下表所示。 元素 类型 作用 directory string 指定从哪个目录进行获取文件进行归档 outputDirectory string 指定文件集合的输出目录，该目录是相对于根目录 fileMode String 指定文件属性，使用八进制表达，分别为(User)(Group)(Other)所属属性，默认为 0644 includes/include* 包含文件 excludes/exclude* 排除文件 完整代码：https://github.com/iogogogo/life-multi-module","categories":[{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/tags/maven/"}]},{"title":"商业论证中的财务测量指标","slug":"pmp-note-01","date":"2019-12-31T16:00:00.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2020/01/01/pmp-note-01/","link":"","permalink":"http://iogogogo.github.io/2020/01/01/pmp-note-01/","excerpt":"","text":"商业论证中的财务测量指标商业论证中常见的财务指标测量方法 ROI 投资回报率 PBP 投资回报周期 NPV 净现值 IRR 内部收益率 BCR 效益成本比率 静态评价法适用于项目早期，不计较利息的情况。 600万买一个房子，出租，每个月租金收入1万。 请问投资回报率(ROI)是多少？ 一直租下去，投资回报期(PBP)几年？ 投资回报率(ROI)投资回报率(ROI) = 年均利润 ➗ 投资额 ROI = 12 ➗ 600 = 2% 投资回报期(PBP)投资回报期(PBP) = 1 ➗ ROI PBP = 1 ➗ (2%) = 50年 再问：600万买一个房子，出租，每个月租金收入1万，5年后房价翻了一番，问ROI是多少？PBP是多少年？ 年份 0 1 2 3 4 5 收入 12 12 12 12 1212 支出 -600 净现金流 -600 12 12 12 12 1212 累计现金流 -600 -588 -576 -564 -552 660 投资回报率(ROI) = 年均利润 ➗ 投资额 ROI= (600 ➗ 5 + 12) ➗ 600 = 22% 投资回报期(PBP) = 1 ➗ ROI PBP = 5 - 1 + (552 ➗ 1212) = 4.46年 简单解法，利用相似三角形原理 PBP = (x-4) ➗ (5-x) = (-552) ➗ 660 = 4.46年 动态分析法复利计算: 终值 = 现值 ✖️ (1+i)^n 折现计算: 现值 = 终值 ➗ (1+i)^n 名词解释: 现值=本金 终值=收益总额 i = 利率 n = 周期(单位年) 净现值 NPV (有利息的计算) 年份 0 1 2 3 4 5 收入 12 12 12 12 1212 支出 -600 净现金流 -600 12 12 12 12 1212 净现金流(折现) -600 10.9112/(1+10%) 9.9212/(1+10%)^2 9.02 8.20 752.561212/(1+10%)^5 累计现金流 -600 -598.09(600-10.91) -579.17(598.09-9.92) -570.16(579.17-9.02) -561.96 190.60 取基准折现率 i = 10% 静态：PBP (x-4) ➗ (5-x) = (-552) ➗ 660 x = 4.46年 - 计算方式参考图二 动态：PBP (x-4) ➗ (5-x) = (-561.96) ➗ 190.60 x = 4.75年 净现值：NPV = 190.60万元，该值表示最后的净利润 内部收益率 IRR该值越高，理论上表示可以承受的风险越高。 年份 0 1 2 3 4 5 i NPV 收入 12 12 12 12 1212 支出 -600 净现金流 -600 12 12 12 12 1212 净现金流(折现)1 -600 10.9112/(1+10%) 9.9212/(1+10%)^2 9.02 8.20 752.561212/(1+10%)^5 10% 190.60 净现金流(折现)2 -600 10.62 9.40 8.32 7.36 657.83 13% 93.52 净现金流(折现)3 -600 10.43 9.07 7.89 6.86 602.58 15% 36.84 净现金流(折现)4 -600 10.34 8.92 7.69 6.63 577.05 16% 10.63 净现金流(折现)5 -600 10.26 8.77 7.49 6.40 552.81 17% -14.27 采用 相似三角形定律 方式进行计算 线性插值 IRR = (IRR-16%) ➗ (17%-IRR) = 10.63 ➗ 14.27 IRR = 16.43% // 该值表示在这个利率下，不赚不赔 多个项目进行比较 项目 A B C NPV(万元) 1500 1000 1000 IRR 16% 16% 38% 正常情况下，比较IRR是需要NPV作为考量标准，在没有NPV的情况下，没有比较意义。 如果非要比较的话，个人认为可以从对待风险的态度方面来讲。 A、B ==&gt; IRR相同，表示内部收益率相同，抗风险能力更强，A项目的NPV(净现值)收益更高，所有选A B、C ==&gt; NPV(净现值)相同，表示赚的钱是一样的，但是C项目的IRR(内部收益率)高，所以选择C 效益成本比率 BCR (Benefit cost ratio) 汽油车 混合动力 纯电动 百公里能源成本 65￥ 39￥ 7.5￥ 购买成本 +10 万￥ +5 万￥ 节油效益 2.6 万￥ 5.75 万￥ 效益成本BCR 0.26 1.15 在C0这个点，成本和效益达到最佳点。△C 区间：成本增加，效益收益不明显。","categories":[{"name":"PMP实战","slug":"PMP实战","permalink":"http://iogogogo.github.io/categories/PMP实战/"}],"tags":[{"name":"PMP","slug":"PMP","permalink":"http://iogogogo.github.io/tags/PMP/"}]},{"title":"FTP 常用命令","slug":"ftp-command","date":"2019-12-12T02:13:15.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2019/12/12/ftp-command/","link":"","permalink":"http://iogogogo.github.io/2019/12/12/ftp-command/","excerpt":"","text":"FTP是可用于许多不同操作系统上的协议。如果 FTP 服务器端允许 PASV 被动模式，可以用浏览器访问 FTP ，也可以使用FTP命令，直接与远程计算机连接。 启动Linux 终端直接敲入 ftp 回车，或者按照下面模式，直接连入 FTP 服务器： *~&gt;ftp 服务器地址（IP或URL） … Name …:用户名 … Password:密码 … ftp&gt; 连接成功如果希望匿名登录，使用用户名密码全部是ftp，或者用户 Anonymous 密码为空。 常用命令目录命令 命令 作用 pwd 显示远程计算机上的当前目录 ls/dir 列出当前远程目录的内容，可以使用该命令在Linux下的任何合法的ls选项 cd 移动到cd 后的目录 cdup/cd .. 返回上一级目录 lcd 列出当前本地目录路径 需要权限的命令 命令 作用 mkdir 在远程系统中创建目录 rname 重命名一个文件或目录 redir 删除远程目录 delete 删除远程文件 mdelete 删除多个远程文件 文件上传下载 命令 作用 binary/bin 用于二进制文件传送（图像文件等） ascii 用于文本文件传送 get/mget 在当前远程目录下复制（一个/多个）文件到本地文件系统当前目录 put/mput 从当前目录把文件复制到当前远程目录 prompt 关闭二次确认时的提示 退出 命令 作用 ! 临时退出ftp模式，返回本地Linux Shell模式，键入exit返回 close 关闭当前连接 bye 关闭连接并退出ftp命令模式","categories":[{"name":"工具使用","slug":"工具使用","permalink":"http://iogogogo.github.io/categories/工具使用/"}],"tags":[{"name":"FTP","slug":"FTP","permalink":"http://iogogogo.github.io/tags/FTP/"}]},{"title":"javac编译java文件","slug":"javac-compiler","date":"2019-11-05T15:32:45.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2019/11/05/javac-compiler/","link":"","permalink":"http://iogogogo.github.io/2019/11/05/javac-compiler/","excerpt":"","text":"javac编译java文件最近做银行项目，生产上新给了一个csv文件，程序需要读取内容进行清洗，但是拿不出来看，也不可能为了这一个小测试专门打审批给生产上传一个程序包，就想到了使用javac写个简单的测试看下数据。下面先来复习一下javac这个命令 下面测试的所有java源文件统一保存在 /Users/xxx/Downloads/compiler 编译单文件现在写一段简单的Java代码 public class Test1 { public static void main(String... args){ System.out.println(\"hello world!!!\"); } } 使用javac编译 ➜ compiler pwd /Users/xxx/Downloads/compiler # 当前路径 ➜ compiler ls -lrt total 8 -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java # 这里是源文件 ➜ compiler javac Test1.java # 使用javac进行编译 ➜ compiler ls -lrt total 16 -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r-- 1 xxx staff 418 11 5 22:28 Test1.class # 编译以后的class文件 ➜ compiler java Test1 # 运行结果 hello world!!! 可以看到结果就是我们正常的一个输出 hello world 编译两个相互依赖的Java源文件 A.java public class A { public void sayHi() { System.out.println(\"我是 class A hello world!!!\"); } } B.java public class B { public static void main(String... args) { A a = new A(); a.sayHi(); } } 使用javac分别进行编译，这里注意先后顺序，先编译A.java，在编译B.java，当然，因为B中引用了A，A.java也可以不用编译，在编译B.java的时候，会自动编译A.java的，后面我们会看到 ➜ compiler ls -lrt total 24 -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 112 11 5 22:20 B.java -rw-r--r--@ 1 xxx staff 113 11 5 22:21 A.java ➜ compiler javac A.java ➜ compiler javac B.java ➜ compiler ls -lrt total 40 -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 112 11 5 22:20 B.java -rw-r--r--@ 1 xxx staff 113 11 5 22:21 A.java -rw-r--r-- 1 xxx staff 402 11 5 22:39 A.class -rw-r--r-- 1 xxx staff 297 11 5 22:39 B.class ➜ compiler java B # 运行B这个程序 我是 class A hello world!!! 编译带外部依赖的jar这里比如我们需要使用Google的guava-27.1-jre.jar，使用其中的api读取一个文本文件的内容。 为了方便，将guava-27.1-jre.jar复制到当前路径，当然也可以使用绝对路径，新建文件GuavaTest.java ➜ compiler ls -lrt total 5400 -rw-r--r-- 1 xxx staff 2746671 11 5 09:33 guava-27.1-jre.jar # 新复制的外部jar文件 -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 112 11 5 22:20 B.java -rw-r--r--@ 1 xxx staff 113 11 5 22:21 A.java -rw-r--r--@ 1 xxx staff 663 11 5 22:54 GuavaTest.java GuavaTest.java内容 import com.google.common.io.Files; import java.io.File; import java.io.IOException; import java.nio.charset.StandardCharsets; import java.util.List; /** * Created by xxx on 2019-11-05. */ public class GuavaTest { public static void main(String[] args) { String path = \"/Users/xxx/Downloads/compiler/A.java\"; try { // 按行读取文件内容 List&lt;String> list = Files.readLines(new File(path), StandardCharsets.UTF_8); list.forEach(System.out::println); } catch (IOException e) { e.printStackTrace(); } } } 然后使用javac进行编译，和预期的结果不一致，引用了guava-27.1-jre.jar中的class不存在 ➜ compiler javac GuavaTest.java GuavaTest.java:2: 错误: 程序包com.google.common.io不存在 import com.google.common.io.Files; ^ GuavaTest.java:19: 错误: 找不到符号 List list = Files.readLines(new File(path), StandardCharsets.UTF_8); ^ 符号: 变量 Files 位置: 类 GuavaTest 2 个错误 那么这个时候就不能单纯的使用javac GuavaTest.java 而是需要使用java -cp 指定外部依赖的jar路径，可以看到加了 -cp 参数指定外部依赖的jar以后编译成功了 ➜ compiler javac -cp guava-27.1-jre.jar GuavaTest.java ➜ compiler ls -lrt total 5408 -rw-r--r-- 1 xxx staff 2746671 11 5 09:33 guava-27.1-jre.jar -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 112 11 5 22:20 B.java -rw-r--r--@ 1 xxx staff 113 11 5 22:21 A.java -rw-r--r--@ 1 xxx staff 663 11 5 22:54 GuavaTest.java -rw-r--r-- 1 xxx staff 1548 11 5 22:59 GuavaTest.class 这个时候使用java GuavaTest去运行程序是否可行呢？ ➜ compiler java GuavaTest Exception in thread \"main\" java.lang.NoClassDefFoundError: com/google/common/io/Files at GuavaTest.main(GuavaTest.java:19) Caused by: java.lang.ClassNotFoundException: com.google.common.io.Files at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 1 more 答案当然是no 这里运行的时候，我们也需要使用 -cp 参数指定外部依赖的jar文件，但是我们发现依然报错，实际上当我们使用cp参数以后指定外部依赖jar以后，而并没有包含当前目录，就算编译成功，也是找不到主类的。 ➜ compiler java -cp guava-27.1-jre.jar GuavaTest 错误: 找不到或无法加载主类 GuavaTest 接下来我们可以把当前路径也加进去，这里特别注意的就是，和上一次的命令相比，添加了:.，: 作为分隔，. 表示当前路径。当然也有博客指出，在Linux下面使用:分隔，但是在Windows下面使用;分隔，因为我是Mac，没有Windows去验证，这里如果有需要就自己验证一下即可。就可以看到当前读取除了A.java文件中的内容 ➜ compiler java -cp guava-27.1-jre.jar:. GuavaTest public class A { public void sayHi() { System.out.println(\"我是 class A hello world!!!\"); } } 编译源文件中带有package的文件上面我们描述了编译单个文件，两个相互依赖的文件以及依赖外部文件的处理方式，如果在我们的源文件中包含package又该如何处理呢？接下来我们继续来看，首先我们给A.java和B.java分别添加上package A.java package compiler; public class A { public void sayHi() { System.out.println(\"我是 class A hello world!!!\"); } } B.java package compiler; public class B { public static void main(String... args) { A a = new A(); a.sayHi(); } } 接下来我们使用javac进行编译，可以看到A.java可以正常编译，但是B.java编译就出错了。这是因为，添加了package语句后，编译器需要找的是compiler.A类，编译器会首先找到compiler目录，然后再从compiler目录中找到A，此时当前目录中(compiler目录内)不存在compiler子目录，因此，编译器找不到A类，编译失败。这说明我们包含的类路径需要包括类所在的包，这里需要包含compiler目录的上一级子目录。 ➜ compiler javac A.java ➜ compiler javac B.java B.java:5: 错误: 找不到符号 A a = new A(); ^ 符号: 类 A 位置: 类 B B.java:5: 错误: 找不到符号 A a = new A(); ^ 符号: 类 A 位置: 类 B 2 个错误 接下来我们编译的时候就需要指定compiler的上一级子目录 ➜ compiler ls -lrt total 5400 -rw-r--r-- 1 xxx staff 2746671 11 5 09:33 guava-27.1-jre.jar -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 663 11 5 22:54 GuavaTest.java -rw-r--r--@ 1 xxx staff 131 11 5 23:19 B.java -rw-r--r--@ 1 xxx staff 131 11 5 23:19 A.java # 注意这里使用了两个.. 表示上一级目录，因为B里面依赖了A，所有也会把A.java自动编译，A.java可以不管 ➜ compiler javac -cp .. B.java ➜ compiler ls -lrt total 5416 -rw-r--r-- 1 xxx staff 2746671 11 5 09:33 guava-27.1-jre.jar -rw-r--r--@ 1 xxx staff 119 11 5 22:11 Test1.java -rw-r--r--@ 1 xxx staff 663 11 5 22:54 GuavaTest.java -rw-r--r--@ 1 xxx staff 131 11 5 23:19 B.java -rw-r--r--@ 1 xxx staff 131 11 5 23:19 A.java -rw-r--r-- 1 xxx staff 315 11 5 23:28 B.class -rw-r--r-- 1 xxx staff 411 11 5 23:28 A.class # 运行是也一样，需要.. 指定到上一级目录，并且要使用compiler.B ➜ compiler java -cp .. compiler.B 我是 class A hello world!!! # A.java中的输出语句 小结以上内容虽然平时很少用到，应用场景虽然不多，但是也是知识点的一次巩固复习，有不足的地方，欢迎指正。","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"使用webpack构建vue项目","slug":"web-vue-starter","date":"2019-10-20T06:53:43.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"2019/10/20/web-vue-starter/","link":"","permalink":"http://iogogogo.github.io/2019/10/20/web-vue-starter/","excerpt":"","text":"安装nodejsNodejs 官网下载地址 推荐下载LTS长期支持版本，然后下一步安装即可 查看 node版本node -v # 结果 ➜ ~ node -v v10.16.3 ➜ ~ 查看 npm 版本npm -v # 结果 ➜ ~ npm -v 6.11.3 ➜ ~ 安装vue组件以及webpack安装 @vue/clinpm install -g @vue/cli 安装 @vue/cli-initnpm install -g @vue/cli-init 安装 webpacknpm install webpack webpack-cli -g 创建vue项目vue create vue-template 输入vue create vue-template以后，按照提示选择对应的选型，即可创建一个vue脚手架项目 常用学习网站 Vue官网：https://cn.vuejs.org/index.html Vue路由：https://router.vuejs.org/ Vuex：https://vuex.vuejs.org/zh/guide/ ES6语法：http://es6.ruanyifeng.com/ JS工具库：https://www.lodashjs.com/docs/latest 日期处理：http://momentjs.cn/docs/ 网络请求：http://www.axios-js.com/zh-cn/docs/ CSS预编译：https://www.sass.hk/docs/ Babel：http://www.ruanyifeng.com/blog/2016/01/babel.html Flex布局：http://www.ruanyifeng.com/blog/2015/07/flex-grammar.html?utm_source=tuicool HTML教程：https://www.w3school.com.cn/html/index.asp","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://iogogogo.github.io/categories/Web开发/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://iogogogo.github.io/tags/Vue/"}]},{"title":"Maven构建Spring-Boot多模块项目","slug":"spring-boot-multi-module-project","date":"2019-07-27T03:18:17.000Z","updated":"2024-07-01T12:30:37.378Z","comments":true,"path":"2019/07/27/spring-boot-multi-module-project/","link":"","permalink":"http://iogogogo.github.io/2019/07/27/spring-boot-multi-module-project/","excerpt":"","text":"日常开发过程中肯定会用到maven构建项目，用来管理依赖的jar文件，对于使用maven构建多module项目很多时候还是不怎么熟悉，这篇文章将带着大家从头开始搭建一个使用maven构建的多module项目，并集成常用的项目插件。 使用Spring Initializr创建项目这一步很简单，直接使用idea自带的功能，创建一个spring-boot项目 一个初始化的项目目录结构如下 添加新的module一个项目中可能需要用到多个子模块，但是又有一些公共的工具类，model之类的，但是又不想传到nexus私服上面去，那么就可以添加子module，然后install以后，提供给当前project来使用了。比如我们需要一个common和一个提供api服务的module，那么可以新建两个module，parent下面的src目录也就没有存在的意义，可以直接删除。在project上面邮件新建module，步骤和新建一个maven project是一样的，这里就不做截图展示了。多module的一个完整目录结构如下： module间相互依赖多module就是为了方便公共部分被其他module引用，其实引用也就很简单了，就类似于一个正常的maven dep就可以，比如在multi-api这个module中引用multi-common，这样一来，multi-common中的类就能被multi-api正常访问使用了 &lt;dependency> &lt;groupId>com.iogogogo&lt;/groupId> &lt;artifactId>multi-common&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;/dependency> 在multi-common写了一个类叫 com.iogogogo.common.util.IdHelper 里面有一个获取UUID的方法，早其他已经引用multi-common的这个module中，只需要直接调用即可 package com.iogogogo; import com.iogogogo.common.util.IdHelper; import lombok.extern.slf4j.Slf4j; /** * Created by tao.zeng on 2019-07-27. */ @Slf4j public class MainApplicatiom { public static void main(String[] args) { // 这里的IdHelper 类，来自于multi-common module log.info(\"uuid [{}]\", IdHelper.uuid()); } } 打包多module项目关于多module项目打包，spring boot升级到2.0以后，打包插件有一些小变化，比如只在multi-common加一个工具类，使用maven自带的打包工具打包，会报错误，但是不影响项目正常运行。日志如下 [INFO] Scanning for projects... [INFO] ------------------------------------------------------------------------ [INFO] Reactor Build Order: [INFO] [INFO] life-multi-module [INFO] multi-common [INFO] multi-api [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building life-multi-module 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ life-multi-module --- [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building multi-common 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ multi-common --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 0 resource [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ multi-common --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 2 source files to /Users/tao.zeng/tmp/life-multi-module/multi-common/target/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ multi-common --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /Users/tao.zeng/tmp/life-multi-module/multi-common/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ multi-common --- [INFO] Changes detected - recompiling the module! [INFO] [INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ multi-common --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.1.2:jar (default-jar) @ multi-common --- [INFO] Building jar: /Users/tao.zeng/tmp/life-multi-module/multi-common/target/multi-common-0.0.1-SNAPSHOT.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ multi-common --- [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO] [INFO] life-multi-module .................................. SUCCESS [ 1.037 s] [INFO] multi-common ....................................... FAILURE [ 2.536 s] [INFO] multi-api .......................................... SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 4.037 s [INFO] Finished at: 2019-07-27T10:50:18+08:00 [INFO] Final Memory: 35M/293M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) on project multi-common: Execution repackage of goal org.springframework.boot:spring-boot-maven-plugin:2.1.6.RELEASE:repackage failed: Unable to find main class -> [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn &lt;goals> -rf :multi-common 意思就是说我们在multi-common这个module中缺少了main class，那么我们加上在multi-common中添加一个类，只有一个main方法，然后再来打包，依旧报错，日志如下 /Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home/bin/java -Dvisualvm.id=375540266385044 -Dmaven.multiModuleProjectDirectory=/Users/tao.zeng/tmp/life-multi-module \"-Dmaven.home=/Applications/IntelliJ IDEA.app/Contents/plugins/maven/lib/maven3\" \"-Dclassworlds.conf=/Applications/IntelliJ IDEA.app/Contents/plugins/maven/lib/maven3/bin/m2.conf\" \"-javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=56994:/Applications/IntelliJ IDEA.app/Contents/bin\" -Dfile.encoding=UTF-8 -classpath \"/Applications/IntelliJ IDEA.app/Contents/plugins/maven/lib/maven3/boot/plexus-classworlds-2.5.2.jar\" org.codehaus.classworlds.Launcher -Didea.version=2018.3.5 -DskipTests=true package [INFO] Scanning for projects... [INFO] ------------------------------------------------------------------------ [INFO] Reactor Build Order: [INFO] [INFO] life-multi-module [INFO] multi-common [INFO] multi-api [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building life-multi-module 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ life-multi-module --- [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building multi-common 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ multi-common --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 0 resource [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ multi-common --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 2 source files to /Users/tao.zeng/tmp/life-multi-module/multi-common/target/classes [INFO] [INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ multi-common --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /Users/tao.zeng/tmp/life-multi-module/multi-common/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ multi-common --- [INFO] Changes detected - recompiling the module! [INFO] [INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ multi-common --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.1.2:jar (default-jar) @ multi-common --- [INFO] Building jar: /Users/tao.zeng/tmp/life-multi-module/multi-common/target/multi-common-0.0.1-SNAPSHOT.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.1.6.RELEASE:repackage (repackage) @ multi-common --- [INFO] Replacing main artifact with repackaged archive [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building multi-api 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ multi-api --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 0 resource [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ multi-api --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 1 source file to /Users/tao.zeng/tmp/life-multi-module/multi-api/target/classes [INFO] ------------------------------------------------------------- [ERROR] COMPILATION ERROR : [INFO] ------------------------------------------------------------- [ERROR] /Users/tao.zeng/tmp/life-multi-module/multi-api/src/main/java/com/iogogogo/MainApplicatiom.java:[3,32] 程序包com.iogogogo.common.util不存在 [INFO] 1 error [INFO] ------------------------------------------------------------- [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO] [INFO] life-multi-module .................................. SUCCESS [ 1.499 s] [INFO] multi-common ....................................... SUCCESS [ 2.279 s] [INFO] multi-api .......................................... FAILURE [ 0.540 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 4.828 s [INFO] Finished at: 2019-07-27T10:52:45+08:00 [INFO] Final Memory: 38M/302M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile (default-compile) on project multi-api: Compilation failure [ERROR] /Users/tao.zeng/tmp/life-multi-module/multi-api/src/main/java/com/iogogogo/MainApplicatiom.java:[3,32] 程序包com.iogogogo.common.util不存在 [ERROR] -> [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn &lt;goals> -rf :multi-api Process finished with exit code 1 这个配置，在spring boot2.0版本之前，其实是完全可以的，在分析错误之前，我们先看一下整个项目的目录结构 可以看到在multi-common下面有两个class，在multi-api下面有一个class，那里面的内容就是引用了multi-common中的com.iogogogo.common.util.IdHelper，但是现在错误日志却说com.iogogogo.common.util不存在，这里就很纳闷了吧，接下来，介绍一下spring boot的打包插件，还得回到parent pom.xml中，使用Spring Initializr创建项目后，默认有一个 spring-boot-maven-plugin 这个maven插件，主要原因就在这里，sprint boot2.0升级以后，对插件也做了相应的升级，如果要解决这个问题，需要在此基础上做一些配置 &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> plugin修改以后，关于configuration的配置介绍，可以看spring boot官方的文档 maven-plugin &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;configuration> &lt;classifier>bootJar&lt;/classifier> &lt;outputDirectory>${project.build.directory}/boot&lt;/outputDirectory> &lt;/configuration> &lt;/plugin> 修改插件以后，在此执行打包命令就可以正常打包，我们再看一下打包以后 target目录的结果，感兴趣的同学可以去相应的目录看一下文件的大小，这里我就不在扩展了，核心日志我也有做标记 好了，到这里，一个完整的spring boot多module构建的项目骨架基本完成了，下面介绍一些实用的maven插件，配合spring boot食用更佳。 github 常用插件使用介绍spring-boot-maven-plugin该插件主要用于spring boot项目构建和打包，上面有简单的介绍和官网链接，主要就是配置 templating-maven-plugin该插件主要生成一个模板类，可以直接读取maven pom中的artifactId、groupId、version等信息，上面的项目源码中我会做出示例，用了该插件以后，第一次checkout project以后 需要使用maven的 compile构建一下 buildnumber-maven-plugin该插件主要解决maven打包以后的时间本地化问题，不然一直会有8小时的时差，一般配合maven-assembly-plugin使用更好 maven-assembly-plugin该插件主要用于项目打包以后的文件归档成指定的压缩包，通过配置文件自定义需要归档的文件 maven-compiler-plugin该插件主要规范maven project的compiler的jdk版本 git-commit-id-plugin该插件用于生产项目的git信息，方便程序读取 maven-jar-plugin、maven-dependency-pluginspring boot打包的jar默认是all in one，既一个jar包含所有依赖，可以使用这两个插件，将打出的jar做一个lib的分离","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Spring Cloud 配置中⼼","slug":"spring-cloud-config","date":"2019-04-06T03:32:30.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2019/04/06/spring-cloud-config/","link":"","permalink":"http://iogogogo.github.io/2019/04/06/spring-cloud-config/","excerpt":"","text":"在系统架构中，和安全、⽇日志、监控等⾮非功能需求⼀一样，配置管理理也是⼀一种⾮非功能需求。配置中⼼心是整个微服务基础架构体系中的⼀一个组件，它的功能看上去并不不起眼，⽆无⾮非就是简单配置的管理理和存取，但它是整个微服务架构中不不可或缺的⼀一环。另外，配置中⼼心如果真得⽤用好了了，它还能推动技术组织持续交付和DevOps⽂文化转型。 常用配置中心 阿⾥里里巴巴中间件部⻔门很早就⾃自研了了配置中⼼心Diamond，并且是开源的。Diamond对阿⾥里里系统的灵 活稳定性发挥了了⾄至关重要的作⽤用。开源版本的Diamond由于研发时间⽐比较早，使⽤用的技术⽐比较 ⽼老老，功能也不不够完善，⽬目前社区不不热已经不不维护了了。 Facebook内部也有⼀一整套完善的配置管理理体系，其中⼀一个产品叫Gatekeeper，⽬目前没有开源。 Netflix内部有⼤大量量的微服务，它的服务的稳定灵活性也重度依赖于配置中⼼心。Netflix开源了了它的配 置中⼼心的客户端，叫变⾊色⻰龙Archaius，⽐比较可惜的是，Netflix没有开源它的配置中⼼心的服务器器端。 Apollo是携程框架部研发并开源的⼀一款配置中⼼心产品，企业级治理理功能完善，⽬目前社区⽐比较⽕火，在 github上有超过10k星，在国内众多互联⽹网公司有落地案例例。⽬目前ITOA也是采⽤用的Apollo配置中 ⼼心。 百度之前也开源过⼀一个叫Disconf的配置中⼼心产品，作者是前百度资深⼯工程师廖绮绮。在Apollo没 有出来之前，Disconf在社区是⽐比较⽕火的，但是⾃自从廖琦琦离开百度之后，他好像没有⾜足够精⼒力力投 ⼊入维护这个项⽬目，⽬目前社区活跃度已经⼤大不不如前。 以及 Spring Cloud Config，和spring cloud⽣生态是天然⽀支持，当然，我个⼈人觉得作为⼀一个⽣生产级 别的配置中⼼心，spring cloud config还是存在⼀一定的缺陷的，⽐比如⼀一个可视化的管理理界⾯面，没有 spring cloud bus等⽀支持，⽆无法做到热发布等等，但是我们还是简单介绍⼀一下spring cloud config。个⼈人推荐⽣生产使⽤用携程Apollo。 Spring Cloud ConfigSpring Cloud Config项目是一个解决分布式系统的配置管理方案。它包含了Client和Server两个部分，server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，client通过接口获取数据、并依据此数据初始化自己的应用。Spring cloud使用git或svn存放配置文件，默认情况下使用git。 我们还是以之前的service-producer为基础，并且在项目根目录创建一个cloud-conf-repo文件夹用来存放配置，并且准备三个文件 # 开发环境 life-example-producer-dev.properties # 测试环境 life-example-producer-test.properties # 生产环境 life-example-producer-pro.properties 文件内容为分别为sharplook.instance=sharplook-[dev/test/pro] Server 端配置pom 配置&lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-config-server&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> 属性文件配置spring.application.name=life-cloud-config server.port=8899 eureka.instance.prefer-ip-address=true eureka.client.service-url.defaultZone=http://localhost:8761/eureka/ # git仓库地址 spring.cloud.config.server.git.uri= # git仓库地址下的相对地址 可以配置多个 用,分割。 spring.cloud.config.server.git.search-paths= # git 仓库用户名 spring.cloud.config.server.git.username= # git 仓库密码 spring.cloud.config.server.git.password= # 如果有分支 可以在这里配置分支名称 spring.cloud.config.server.git.default-label= 启动类配置package com.iogogogo.config; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.config.server.EnableConfigServer; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; /** * Created by tao.zeng on 2019-03-16. */ @EnableConfigServer @EnableEurekaClient @SpringBootApplication public class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); } } 测试浏览器访问 http://localhost:8899/life-example-producer/dev http://localhost:8899/life-example-producer/test http://localhost:8899/life-example-producer/pro 分别会按照我们的配置返回相应的数据，格式如下 // 20190317102625 // http://localhost:8899/life-example-producer/dev { \"name\": \"life-example-producer\", \"profiles\": [ \"dev\" ], \"label\": null, \"version\": \"131d288174b48601af4461dfde809913c87b91ca\", \"state\": null, \"propertySources\": [ { \"name\": \"https://gitlab.eoitek.net/zengtao/life-cloud-example.git/cloud-conf-repo/life-example-producer-dev.properties\", \"source\": { \"sharplook.instance\": \"sharplook-dev\" } } ] } 仓库中的配置文件会被转换成web接口，访问可以参照以下的规则： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties Client配置client 主要是其他服务怎么去获取config中的配置信息，还是以service-producer为例 pom 配置&lt;!-- 添加config客户端依赖 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-config&lt;/artifactId> &lt;/dependency> 属性文件配置application.properties无需修改，新建bootstrap.properties文件，用于配置spring cloud config的服务器信息 # 配置中心地址 spring.cloud.config.uri=http://localhost:8899/ # 使用哪个环境的配置 spring.cloud.config.profile=dev # 当前服务的名称 和 spring.application.name对应即可 spring.cloud.config.name=${spring.application.name} # 读取指定分支配置 spring.cloud.config.label=master 上面这些与spring-cloud相关的属性必须配置在bootstrap.properties中，config部分内容才能被正确加载。因为config的相关配置会先于application.properties，而bootstrap.properties的加载也是先于application.properties。 启动类 无需变更 Controller为了方便测试，还是使用接口访问形式，新建ConfigApi package com.iogogogo.producer.api; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * Created by tao.zeng on 2019-03-17. */ @RestController @RequestMapping(\"/api/config\") public class ConfigApi { /** * 这里key 就是自定义在配置中心中的key */ @Value(\"${sharplook.instance}\") private String instance; @GetMapping(\"/\") public String config() { return instance; } } 测试启动service-producer服务，访问 http://localhost:8080/api/config/ 返回 sharplook-dev 修改spring.cloud.config.profile=pro配置，重启服务后，访问接口，返现返回结果就是我们在config中的配置 修改配置中心的git中的配置，推送到git以后，再次请求服务，就能看到新的变更配置。 小结 配置中心是微服务基础架构中不可或缺的核心组件，现代微服务架构和云原生环境，对应用配置管理提出了更高的要求。 配置中心有众多的应用场景，配置中心+功能开关是DevOps最佳实践。用好配置中心，它能帮助技术组织实现持续交付和DevOps文化转型。 Spring Cloud Config相对来说还是达不到生产级别，目前来看携程开源的Apollo配置中心，企业级功能完善，经过大规模生产验证，社区活跃度高，是开源配置中心产品的首选。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/tags/Spring-Cloud/"}]},{"title":"服务网关 Zuul","slug":"spring-cloud-gateway-zuul","date":"2019-04-04T15:01:45.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2019/04/04/spring-cloud-gateway-zuul/","link":"","permalink":"http://iogogogo.github.io/2019/04/04/spring-cloud-gateway-zuul/","excerpt":"","text":"服务网关 ZuulEureka用于服务的注册于发现，Feign支持服务的调用以及均衡负载，Hystrix处理服务的熔断防止故障扩散。 但是外部的应用如何来访问内部各种各样的微服务呢？在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个API网关根据请求的url，路由到相应的服务。当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。 Spring Cloud Zuul添加依赖&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>life-cloud-example&lt;/artifactId> &lt;groupId>com.iogogogo&lt;/groupId> &lt;version>0.0.1&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>cloud-zuul&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-zuul&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;/project> 配置文件spring.application.name=life-cloud-zuul server.port=8888 eureka.instance.prefer-ip-address=true eureka.client.service-url.defaultZone=http://localhost:8761/eureka/ # 表示访问iogogogo 都会跳转到 https://iogogogo.github.io/ zuul.routes.iogogogo.path=/iogogogo/* zuul.routes.iogogogo.url=https://iogogogo.github.io/ 启动类package com.iogogogo.zuul; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.zuul.EnableZuulProxy; import org.springframework.cloud.netflix.zuul.EnableZuulServer; /** * &lt;p> * Created by tao.zeng on 2019-03-16. */ @EnableZuulProxy @EnableEurekaClient @SpringBootApplication public class ZuulApplication { public static void main(String[] args) { SpringApplication.run(ZuulApplication.class, args); } } 依次启动cloud-eureka、cloud-zuul 微服务整合通过url映射的方式来实现zuul的转发有局限性，比如每增加一个服务就需要配置一条内容，另外后端的服务如果是动态来提供，就不能采用这种方案来配置了。实际上在实现微服务架构时，服务名与服务实例地址的关系在eureka server中已经存在了，所以只需要将Zuul注册到eureka server上去发现其他服务，就可以实现对serviceId的映射。 配置文件spring.application.name=life-cloud-zuul server.port=8888 eureka.instance.prefer-ip-address=true eureka.client.service-url.defaultZone=http://localhost:8761/eureka/ # 表示访问iogogogo 都会跳转到 https://iogogogo.github.io/ zuul.routes.iogogogo.path=/iogogogo/** zuul.routes.iogogogo.url=https://iogogogo.github.io/ # 添加微服务路由地址 zuul.routes.producer.path=/producer/** zuul.routes.producer.service-id=life-example-producer 启动服务提供者java -jar service-producer-0.0.1.jar --server.port=8080 --service.instance.name=这是服务器1 java -jar service-producer-0.0.1.jar --server.port=8081 --service.instance.name=这是服务器2 java -jar service-producer-0.0.1.jar --server.port=8082 --service.instance.name=这是服务器3 访问 http://localhost:8888/producer/api/index?name=阿牛 会发现自动负载均衡，将每个请求分发到不同的服务，至此，整个zuul和微服务整合也就完成了。 spring cloud gateway猿天地spring cloud gateway系列教程","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/tags/Spring-Cloud/"}]},{"title":"服务提供调用与熔断","slug":"spring-cloud-feign","date":"2019-04-01T11:34:40.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2019/04/01/spring-cloud-feign/","link":"","permalink":"http://iogogogo.github.io/2019/04/01/spring-cloud-feign/","excerpt":"","text":"服务提供调用与熔断之前我们介绍了eureka服务注册中心的搭建，这篇文章介绍一下如何使用eureka服务注册中心，搭建一个简单的服务端注册服务，客户端去调用服务使用的案例。 需要有三个角色：服务注册中心、服务提供者、服务消费者，其中服务注册中心就是我们上一篇的eureka单机版启动既可，流程是首先启动注册中心，服务提供者生产服务并注册到服务中心中，消费者从服务中心中获取服务并执行。 服务提供我们假设服务提供者有一个hello方法，可以根据传入的参数，提供输出“hello xxx”的服务 pom配置创建一个springboot项目，pom.xml中添加如下配置，注:旧版的spring cloud和最新版的artifactId不太一样 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> 配置文件application.properties配置如下： spring.application.name=life-example-producer server.port=8080 eureka.instance.prefer-ip-address=true eureka.client.service-url.defaultZone=http://localhost:8761/eureka/ # 这个配置是为了后面测试负载均衡 service.instance.name=这是服务器1 启动类package com.iogogogo.producer; import feign.Retryer; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.hystrix.EnableHystrix; import org.springframework.context.annotation.Bean; /** * Created by tao.zeng on 2019-03-16. */ @EnableHystrix @EnableEurekaClient @SpringBootApplication public class ProducerApplication { public static void main(String[] args) { SpringApplication.run(ProducerApplication.class, args); } @Bean public Retryer feignRetryer() { // new Retryer.Default(100,TimeUnit.SECONDS.toMillis(1),5);//默认是5次 return Retryer.NEVER_RETRY; } } Controllerpackage com.iogogogo.producer.api; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; /** * Created by tao.zeng on 2019-03-16. */ @RestController @RequestMapping(\"/api\") public class IndexApi { @Value(\"${service.instance.name}\") private String instanceName; @GetMapping(\"/index\") public String index(String name) { return String.format(\"%s hello %s - %s\", instanceName, name, UUID.randomUUID().toString()); } } 添加@EnableEurekaClient注解后，项目就具有了服务注册的功能。启动工程后，就可以在注册中心的页面看到service-producer服务。 到此服务提供者配置就完成了。 服务调用pom配置和服务提供者一致 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> 配置文件application.properties配置如下： spring.application.name=life-example-consumer server.port=8081 eureka.instance.prefer-ip-address=true eureka.client.service-url.defaultZone=http://localhost:8761/eureka/ # 开启熔断 feign.hystrix.enabled=true 启动类package com.iogogogo.consumer; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.hystrix.EnableHystrix; import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard; import org.springframework.cloud.openfeign.EnableFeignClients; /** * Created by tao.zeng on 2019-03-16. */ @EnableHystrix @EnableFeignClients @EnableEurekaClient @SpringBootApplication @EnableHystrixDashboard public class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); } } Feign是一个声明式Web Service客户端。使用Feign能让编写Web Service客户端更加简单, 它的使用方法是定义一个接口，然后在上面添加注解，同时也支持JAX-RS标准的注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。 feign调用实现package com.iogogogo.consumer.feign; import com.iogogogo.consumer.configure.FeignConfig; import com.iogogogo.consumer.feign.fallback.ProducerFallback; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; /** * value = 服务提供者的 spring.application.name * fallback = 熔断降级处理类 * configuration = 熔断降级配置 * &lt;p> * Created by tao.zeng on 2019-03-16. */ @Component @FeignClient(value = \"life-example-producer\", fallback = ProducerFallback.class, configuration = FeignConfig.class) public interface ProducerService { /** * 调用的远程方法路由地址需要和服务提供者的一致，并且不要使用GetMapping之类的简化方法 * * @param name * @return */ @RequestMapping(value = \"/api/index\", method = RequestMethod.GET) String index(@RequestParam(\"name\") String name); } 消费者调用远程服务package com.iogogogo.consumer.api; import com.iogogogo.consumer.feign.ProducerService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * Created by tao.zeng on 2019-03-16. */ @RestController @RequestMapping(\"/api/consumer\") public class IndexApi { @Autowired private ProducerService producerService; @RequestMapping(\"/index\") public String index(String name) { return producerService.index(name); } } 到此，最简单的一个服务注册与调用的例子就完成了。 测试启动服务依次启动cloud-eureka、service-producer、service-consumer三个项目，并且查看eureka注册情况 测试服务提供者浏览器输入服务提供者路由地址查看是否正常 http://localhost:8080/api/index?name=sharplook 返回结果 hello sharplook - 7359bd06-8471-4a5d-aa04-7b25b7c13ddb 说明service-producer正常启动，提供的服务也正常。 测试服务调用者浏览器输入调用者路由地址，并传递相应的参数 http://localhost:8081/api/consumer/index?name=阿牛 返回结果 hello 阿牛 - f012cf85-9a04-4ae0-b879-42fa860d5015 说明客户端已经成功的通过feign调用了远程服务，并且将结果返回到了浏览器。 负载均衡前面在服务提供者的application.properties文件中配置了一个service.instance.name属性，现在讲程序打包，然后输入不同的instance名称，用来模拟多个服务器 依次启动多个service-producer实例，使用不同的端口以及自定义的service.instance.name java -jar service-producer-0.0.1.jar --server.port=8080 --service.instance.name=这是服务器1 java -jar service-producer-0.0.1.jar --server.port=8081 --service.instance.name=这是服务器2 java -jar service-producer-0.0.1.jar --server.port=8082 --service.instance.name=这是服务器3 启动完成后，会看到eureka中有多个服务提供者 然后次使用服务消费者去调用 http://localhost:8081/api/consumer/index?name=阿牛 第一次返回结果： 这是服务器1 hello 阿牛 - c280ad85-8475-464e-9856-151c70b8970d 第二次返回结果： 这是服务器2 hello 阿牛 - 4e798f0a-7fda-4063-bb33-bbaaad106f05 第三次返回结果： 这是服务器3 hello 阿牛 - a318c789-9765-4119-a991-b77c72a19ba3 不断的进行测试下去会发现两种结果交替出现，说明两个服务中心自动提供了服务均衡负载的功能。如果我们将服务提供者的数量在提高为N个，测试结果一样，请求会自动轮询到每个服务端来处理。 服务熔断熔断器雪崩效应在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。 熔断器（CircuitBreaker）熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。 熔断器模式就像是那些容易导致错误的操作的一种代理。这种代理能够记录最近调用发生错误的次数，然后决定使用允许操作继续，或者立即返回错误。 熔断器开关相互转换的逻辑如下图： 熔断器就是保护服务高可用的最后一道防线。 Hystrix特性1.断路器机制 断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力. 2.Fallback Fallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存. 3.资源隔离 在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池. 例如调用产品服务的Command放入A线程池, 调用账户服务的Command放入B线程池. 这样做的主要优点是运行环境被隔离开了. 这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时, 不会对系统的其他服务造成影响. 但是带来的代价就是维护多个线程池会对系统带来额外的性能开销. 如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话, 可以使用Hystrix的信号模式(Semaphores)来隔离资源. Feign Hystrix因为熔断只是作用在服务调用这一端，因此我们根据上一篇的示例代码只需要改动service-consumer项目相关代码就可以。因为，Feign中已经依赖了Hystrix所以在maven配置上不用做任何改动。 配置文件feign.hystrix.enabled=true 熔断降级处理类package com.iogogogo.consumer.feign.fallback; import com.iogogogo.consumer.feign.ProducerService; import org.springframework.stereotype.Component; /** * Created by tao.zeng on 2019-03-16. */ @Component public class ProducerFallback implements ProducerService { @Override public String index(String name) { return String.format(\"life-example-producer 服务不可用 param:%s\", name); } } fallback属性package com.iogogogo.consumer.feign; import com.iogogogo.consumer.configure.FeignConfig; import com.iogogogo.consumer.feign.fallback.ProducerFallback; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; /** * value = 服务提供者的 spring.application.name * fallback = 熔断降级处理类 * configuration = 熔断降级配置 * &lt;p> * Created by tao.zeng on 2019-03-16. */ @Component @FeignClient(value = \"life-example-producer\", fallback = ProducerFallback.class, configuration = FeignConfig.class) public interface ProducerService { /** * 调用的远程方法路由地址需要和服务提供者的一致，并且不要使用GetMapping之类的简化方法 * * @param name * @return */ @RequestMapping(value = \"/api/index\", method = RequestMethod.GET) String index(@RequestParam(\"name\") String name); } 测试依次启动cloud-eureka、service-producer、service-consumer三个项目，手动停掉服务查看熔断结果","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/tags/Spring-Cloud/"}]},{"title":"MySQL 导出表结构和表数据 mysqldump用法","slug":"mysql-note-mysqldump","date":"2019-03-22T14:51:12.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2019/03/22/mysql-note-mysqldump/","link":"","permalink":"http://iogogogo.github.io/2019/03/22/mysql-note-mysqldump/","excerpt":"","text":"命令行下具体用法如下： mysqldump -u用戶名 -p密码 -d 数据库名 表名 &gt; 脚本名; 导出整个数据库结构和数据mysqldump -h localhost -uroot -p123456 database > dump.sql 导出单个数据表结构和数据mysqldump -h localhost -uroot -p123456 database table > dump.sql 导出整个数据库结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database > dump.sql 导出单个数据表结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database table > dump.sql","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"Spring Boot 整合MyBatis-Plus使用多数据源","slug":"spring-boot-mybatisplus-multiple-datasource","date":"2019-03-19T14:34:14.000Z","updated":"2024-07-01T12:30:37.378Z","comments":true,"path":"2019/03/19/spring-boot-mybatisplus-multiple-datasource/","link":"","permalink":"http://iogogogo.github.io/2019/03/19/spring-boot-mybatisplus-multiple-datasource/","excerpt":"","text":"项目中使用到了MySQL数据库存储配置数据，Vertica中存储指标数据，这样就有两个基于jdbc的数据源，所以需要做到动态配置与切换，并且项目采用了mybatis-plus作为orm框架，所以使用mybatis-plus配置多数据源，并且配置hikari连接池，这也是Spring Boot-2.x自带的连接池，这里提供一个配置思路与方案，仅供参考。通过查看mybatis-plus的源码发现，该框架目前连接Vertica时会提示一个警告⚠️ 表示不支持该数据库，实际使用时可以直接使用mybatis执行sql的功能即可。 2019-03-19 17:36:20.877 WARN 14103 --- [ restartedMain] c.b.m.extension.toolkit.JdbcUtils : The jdbcUrl is jdbc:vertica://192.168.21.188:5433/vertica20190122001, Mybatis Plus Cannot Read Database type or The Database&#39;s Not Supported! 关于MySQL和Vertica的建库建表这边就不放了，直接贴上核心代码。 pom 配置&lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;version>${mybatisplus.spring.version}&lt;/version> &lt;/dependency> &lt;!-- jdbc driver 这是是官网下载，自己传到内网服务器的jdbc驱动 --> &lt;dependency> &lt;groupId>com.iogogogo.vertica&lt;/groupId> &lt;artifactId>vertica-jdbc&lt;/artifactId> &lt;version>9.2.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 配置文件spring: application: name: example-dynamic-datasource datasource: mysql: driver-class-name: com.mysql.cj.jdbc.Driver hikari: auto-commit: true connection-test-query: SELECT 1 connection-timeout: 30000 idle-timeout: 30000 max-lifetime: 1800000 maximum-pool-size: 15 minimum-idle: 5 pool-name: MySQLHikariCP password: Root@123 type: com.zaxxer.hikari.HikariDataSource jdbc-url: jdbc:mysql://192.168.21.111:3306/life-test?characterEncoding=utf8&amp;useSSL=false username: root vertica: driver-class-name: com.vertica.jdbc.Driver hikari: auto-commit: true connection-test-query: SELECT 1 connection-timeout: 30000 idle-timeout: 30000 max-lifetime: 1800000 maximum-pool-size: 15 minimum-idle: 5 pool-name: VerticaHikariCP password: 123456 type: com.zaxxer.hikari.HikariDataSource jdbc-url: jdbc:vertica://192.168.21.188:5433/vertica20190122001 username: dbadmin logging: home: ${user.dir}/logs mybatis-plus: configuration: map-underscore-to-camel-case: true type-aliases-package: com.iogogogo.entity HikariCP 配置package com.iogogogo.datasource.config; import lombok.Data; /** * Created by tao.zeng on 2019-03-20. */ @Data public class HikariConfig { private String poolName; private boolean autoCommit; private long connectionTimeout; private long idleTimeout; private long maxLifetime; private int maximumPoolSize; private int minimumIdle; private String connectionTestQuery; } MySQL数据源配置连接池配置package com.iogogogo.datasource.config; import lombok.Data; import lombok.EqualsAndHashCode; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; /** * Created by tao.zeng on 2019-03-20. */ @Data @Configuration @EqualsAndHashCode(callSuper = true) @ConfigurationProperties(prefix = \"spring.datasource.mysql.hikari\") public class HikariMySQLConfig extends HikariConfig { } DataSource配置package com.iogogogo.datasource; import com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean; import com.iogogogo.datasource.configure.HikariMySQLConfig; import com.zaxxer.hikari.HikariDataSource; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionTemplate; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import javax.sql.DataSource; /** * Created by tao.zeng on 2019-03-19. */ @Configuration @MapperScan(basePackages = \"com.iogogogo.mapper.mysql\", sqlSessionTemplateRef = \"mysqlSqlSessionTemplate\") public class MySQLDataSourceConfigure { private HikariMySQLConfig mysqlConfig; public MySQLDataSourceConfigure(HikariMySQLConfig mysqlConfig) { this.mysqlConfig = mysqlConfig; } @Bean(name = \"mysqlDataSource\") @ConfigurationProperties(\"spring.datasource.mysql\") public DataSource mysql() { DataSource dataSource = DataSourceBuilder.create().build(); HikariDataSource hikariDataSource = null; if (dataSource instanceof HikariDataSource) { // 连接池配置 hikariDataSource = (HikariDataSource) dataSource; hikariDataSource.setPoolName(mysqlConfig.getPoolName()); hikariDataSource.setAutoCommit(mysqlConfig.isAutoCommit()); hikariDataSource.setConnectionTestQuery(mysqlConfig.getConnectionTestQuery()); hikariDataSource.setIdleTimeout(mysqlConfig.getIdleTimeout()); hikariDataSource.setConnectionTimeout(mysqlConfig.getConnectionTimeout()); hikariDataSource.setMaximumPoolSize(mysqlConfig.getMaximumPoolSize()); hikariDataSource.setMaxLifetime(mysqlConfig.getMaxLifetime()); hikariDataSource.setMinimumIdle(mysqlConfig.getMinimumIdle()); } return hikariDataSource == null ? dataSource : hikariDataSource; } @Bean(name = \"mysqlSqlSessionFactory\") public SqlSessionFactory mysqlSqlSessionFactory(@Qualifier(\"mysqlDataSource\") DataSource dataSource) throws Exception { // MyBatis-Plus使用MybatisSqlSessionFactoryBean MyBatis直接使用SqlSessionFactoryBean MybatisSqlSessionFactoryBean bean = new MybatisSqlSessionFactoryBean(); // 给MyBatis-Plus注入数据源 bean.setDataSource(dataSource); return bean.getObject(); } @Bean(name = \"mysqlTransactionManager\") public DataSourceTransactionManager mysqlTransactionManager(@Qualifier(\"mysqlDataSource\") DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } @Bean(name = \"mysqlSqlSessionTemplate\") public SqlSessionTemplate mysqlSqlSessionTemplate(@Qualifier(\"mysqlSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) { return new SqlSessionTemplate(sqlSessionFactory); } } Vertica数据源配置连接池配置package com.iogogogo.datasource.config; import lombok.Data; import lombok.EqualsAndHashCode; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; /** * Created by tao.zeng on 2019-03-20. */ @Data @Configuration @EqualsAndHashCode(callSuper = true) @ConfigurationProperties(prefix = \"spring.datasource.vertica.hikari\") public class HikariVerticaConfig extends HikariConfig { } DataSource配置package com.iogogogo.datasource; import com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean; import com.iogogogo.datasource.configure.HikariVerticaConfig; import com.zaxxer.hikari.HikariDataSource; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionTemplate; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import javax.sql.DataSource; /** * Created by tao.zeng on 2019-03-19. */ @Configuration @MapperScan(basePackages = \"com.iogogogo.mapper.vertica\", sqlSessionTemplateRef = \"verticaSqlSessionTemplate\") public class VerticaDataSourceConfigure { private HikariVerticaConfig verticaConfig; public VerticaDataSourceConfigure(HikariVerticaConfig verticaConfig) { this.verticaConfig = verticaConfig; } @Bean(name = \"verticaDataSource\") @ConfigurationProperties(\"spring.datasource.vertica\") public DataSource vertica() { DataSource dataSource = DataSourceBuilder.create().build(); HikariDataSource hikariDataSource = null; if (dataSource instanceof HikariDataSource) { // 连接池配置 hikariDataSource = (HikariDataSource) dataSource; hikariDataSource.setPoolName(verticaConfig.getPoolName()); hikariDataSource.setAutoCommit(verticaConfig.isAutoCommit()); hikariDataSource.setConnectionTestQuery(verticaConfig.getConnectionTestQuery()); hikariDataSource.setIdleTimeout(verticaConfig.getIdleTimeout()); hikariDataSource.setConnectionTimeout(verticaConfig.getConnectionTimeout()); hikariDataSource.setMaximumPoolSize(verticaConfig.getMaximumPoolSize()); hikariDataSource.setMaxLifetime(verticaConfig.getMaxLifetime()); hikariDataSource.setMinimumIdle(verticaConfig.getMinimumIdle()); } return hikariDataSource == null ? dataSource : hikariDataSource; } @Bean(name = \"verticaSqlSessionFactory\") public SqlSessionFactory verticaSqlSessionFactory(@Qualifier(\"verticaDataSource\") DataSource dataSource) throws Exception { // MyBatis-Plus使用MybatisSqlSessionFactoryBean MyBatis直接使用SqlSessionFactoryBean MybatisSqlSessionFactoryBean bean = new MybatisSqlSessionFactoryBean(); // 给MyBatis-Plus注入数据源 bean.setDataSource(dataSource); return bean.getObject(); } @Bean(name = \"verticaTransactionManager\") public DataSourceTransactionManager verticaTransactionManager(@Qualifier(\"verticaDataSource\") DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } @Bean(name = \"verticaSqlSessionTemplate\") public SqlSessionTemplate verticaSqlSessionTemplate(@Qualifier(\"verticaSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) { return new SqlSessionTemplate(sqlSessionFactory); } } MapperMySQLpackage com.iogogogo.mapper.mysql; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.iogogogo.entity.SysUser; import org.apache.ibatis.annotations.Insert; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import org.springframework.stereotype.Repository; import java.util.List; /** * Created by tao.zeng on 2019-03-19. */ @Repository public interface SysUserMapper extends BaseMapper&lt;SysUser> { @Insert(\"insert into sys_user values(#{x.id},#{x.name},#{x.birthday})\") boolean save(@Param(\"x\") SysUser user); @Select(\"select * from sys_user\") List&lt;SysUser> list(); } Verticapackage com.iogogogo.mapper.vertica; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.iogogogo.entity.User; import org.apache.ibatis.annotations.Select; import org.springframework.stereotype.Repository; import java.util.List; /** * Created by tao.zeng on 2019-03-15. */ @Repository public interface UserMapper extends BaseMapper&lt;User> { @Select(\"select * from public.user\") List&lt;User> list(); } 可以发现只要数据源配置成功以后，两者已经没有任何区别了，就可以像正常写代码一样，需要注意的就是不同数据库的mapper需要放在指定的包下面，否则spring容器无法扫描。 测试为了方便，直接就在项目启动以后查询两个数据库的数据就好了 package com.iogogogo; import com.iogogogo.entity.SysUser; import com.iogogogo.entity.User; import com.iogogogo.mapper.mysql.SysUserMapper; import com.iogogogo.mapper.vertica.UserMapper; import com.iogogogo.util.IdHelper; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import java.time.LocalDateTime; import java.util.List; /** * Created by tao.zeng on 2019-03-15. */ @Slf4j @SpringBootApplication public class DynamicDataSourceApplication implements CommandLineRunner { @Autowired private UserMapper userMapper; @Autowired private SysUserMapper sysUserMapper; public static void main(String[] args) { SpringApplication.run(DynamicDataSourceApplication.class, args); } @Override public void run(String... args) { int i = userMapper.insert(new User(IdHelper.id(), \"阿牛-\" + IdHelper.uuid(), \"description-\" + IdHelper.uuid())); // 使用自定义的查询方法 List&lt;User> list = userMapper.list(); log.info(\"insert result:{} list.size:{}\", i, list.size()); boolean b = sysUserMapper.save(new SysUser(IdHelper.id(), \"阿牛-\" + IdHelper.uuid(), LocalDateTime.now())); // 使用MyBatis-Plus提供的查询方法 List&lt;SysUser> users = sysUserMapper.selectList(null); log.info(\"insert result:{} list.size:{}\", b, users.size()); users.forEach(x -> log.info(x.toString())); } } 项目启动以后，可以看到控制台初始化了多个数据源的日志 . ____ _ __ _ _ /\\\\ / ___&#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | &#39;_ | &#39;_| | &#39;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#39; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.3.RELEASE) 2019-03-20 10:33:18.233 INFO 21123 --- [ restartedMain] c.iogogogo.DynamicDataSourceApplication : Starting DynamicDataSourceApplication on iogogogo.local with PID 21123 (/Users/tao.zeng/share/life-example/example-dynamic-datasource/target/classes started by tao.zeng in /Users/tao.zeng/share/life-example) 2019-03-20 10:33:18.237 INFO 21123 --- [ restartedMain] c.iogogogo.DynamicDataSourceApplication : No active profile set, falling back to default profiles: default 2019-03-20 10:33:18.360 INFO 21123 --- [ restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set &#39;spring.devtools.add-properties&#39; to &#39;false&#39; to disable 2019-03-20 10:33:18.360 INFO 21123 --- [ restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the &#39;logging.level.web&#39; property to &#39;DEBUG&#39; 2019-03-20 10:33:20.341 INFO 21123 --- [ restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2019-03-20 10:33:20.374 INFO 21123 --- [ restartedMain] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2019-03-20 10:33:20.375 INFO 21123 --- [ restartedMain] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.16] 2019-03-20 10:33:20.391 INFO 21123 --- [ restartedMain] o.a.catalina.core.AprLifecycleListener : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/Users/tao.zeng/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.] 2019-03-20 10:33:20.497 INFO 21123 --- [ restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2019-03-20 10:33:20.497 INFO 21123 --- [ restartedMain] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2136 ms _ _ |_ _ _|_. ___ _ | _ | | |\\/|_)(_| | |_\\ |_)||_|_\\ / | 3.0.6 2019-03-20 10:33:20.751 INFO 21123 --- [ restartedMain] com.zaxxer.hikari.HikariDataSource : VerticaHikariCP - Starting... 2019-03-20 10:33:21.449 INFO 21123 --- [ restartedMain] com.zaxxer.hikari.pool.PoolBase : VerticaHikariCP - Driver does not support get/set network timeout for connections. (com.vertica.jdbc.VerticaJdbc4ConnectionImpl.getNetworkTimeout()I) 2019-03-20 10:33:21.672 INFO 21123 --- [ restartedMain] com.zaxxer.hikari.HikariDataSource : VerticaHikariCP - Start completed. 2019-03-20 10:33:21.683 WARN 21123 --- [ restartedMain] c.b.m.extension.toolkit.JdbcUtils : The jdbcUrl is jdbc:vertica://192.168.21.188:5433/vertica20190122001, Mybatis Plus Cannot Read Database type or The Database&#39;s Not Supported! _ _ |_ _ _|_. ___ _ | _ | | |\\/|_)(_| | |_\\ |_)||_|_\\ / | 3.0.6 2019-03-20 10:33:21.865 INFO 21123 --- [ restartedMain] com.zaxxer.hikari.HikariDataSource : MySQLHikariCP - Starting... 2019-03-20 10:33:23.201 INFO 21123 --- [ restartedMain] com.zaxxer.hikari.HikariDataSource : MySQLHikariCP - Start completed. 2019-03-20 10:33:23.516 INFO 21123 --- [ restartedMain] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService &#39;applicationTaskExecutor&#39; 2019-03-20 10:33:23.804 INFO 21123 --- [ restartedMain] o.s.b.d.a.OptionalLiveReloadServer : LiveReload server is running on port 35729 2019-03-20 10:33:23.887 INFO 21123 --- [ restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#39;&#39; 2019-03-20 10:33:23.892 INFO 21123 --- [ restartedMain] c.iogogogo.DynamicDataSourceApplication : Started DynamicDataSourceApplication in 6.41 seconds (JVM running for 7.001) 以上完整代码","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Spring Cloud Eureka 注册中心","slug":"spring-cloud-eureka","date":"2019-03-17T08:41:17.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2019/03/17/spring-cloud-eureka/","link":"","permalink":"http://iogogogo.github.io/2019/03/17/spring-cloud-eureka/","excerpt":"","text":"什么是Spring CloudSpring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 下图是一个基本的Spring Cloud组件架构，核心组件有Eureka、Zuul、Ribbon、Fegin、Hystrix等等。接下来将介绍第一个Eureka组件 Eureka注册中心注册中心，管理各种服务功能包括服务的注册、发现、熔断、负载、降级等，比如dubbo admin后台的各种功能。有了服务中心之后，任何一个服务都不能直接去掉用，都需要通过服务中心来调用。通过服务中心来获取服务你不需要关注你调用的项目IP地址，由几台服务器组成，每次直接去服务中心获取可以使用的服务去调用既可。 Eureka是Netflix开源的一款提供服务注册和发现的产品，它提供了完整的Service Registry和Service Discovery实现。也是Spring Cloud体系中最重要最核心的组件之一。 官方介绍: Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers. Eureka 是一个基于 REST 的服务，主要在 AWS 云中使用, 定位服务来进行中间层服务器的负载均衡和故障转移。 用一张图简单说明: 上图简要描述了Eureka的基本架构，由3个角色组成： 1、Eureka Server 提供服务注册和发现 2、Service Provider 服务提供方 将自身服务注册到Eureka，从而使服务消费方能够找到 3、Service Consumer 服务消费方 从Eureka获取注册服务列表，从而能够消费服务 Eureka Server我们可以用Spring initialize 构建一个基本的maven项目，基于Spring Cloud Greenwich.SR1 然后自己添加相应的依赖 pom依赖&lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-server&lt;/artifactId> &lt;/dependency> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;executions> &lt;execution> &lt;goals> &lt;!-- 默认goal。在mvn package之后，再次打包可执行的jar/war，同时保留mvn package生成的jar/war为.origin --> &lt;!-- https://docs.spring.io/spring-boot/docs/current/maven-plugin/repackage-mojo.html --> &lt;goal>repackage&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;/plugin> &lt;/plugins> &lt;/build> 启动类package com.iogogogo.eureka; import lombok.extern.slf4j.Slf4j; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; /** * 添加启动代码中添加@EnableEurekaServer注解 * Created by tao.zeng on 2019-03-15. */ @Slf4j @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } application.properties 配置eureka使用8761端口 spring.application.name=life-cloud-eureka server.port=8761 eureka.instance.hostname=localhost # 实例名称显示IP eureka.instance.prefer-ip-address=true # 健康检查 eureka.server.enable-self-preservation=false # 清理间隔 eureka.server.eviction-interval-timer-in-ms=6000 # 表示是否将自己注册到Eureka Server，默认为true。 eureka.client.register-with-eureka=false # 表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.fetch-registry=false # eureka服务地址 多个地址可使用 , 分隔。 eureka.client.service-url.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/ 然后启动项目，访问 http://localhost:8761/ Eureka 高可用注册中心这么关键的服务，如果是单点话，遇到故障就是毁灭性的。在生产中我们可能需要三台或者大于三台的注册中心来保证服务的稳定性，在一个分布式系统中，服务注册中心是最重要的基础部分，理应随时处于可以提供服务的状态。为了维持其可用性，使用集群是很好的解决方案。Eureka通过互相注册的方式来实现高可用的部署，所以我们只需要将Eureke Server配置其他可用的serviceUrl就能实现高可用部署。 修改hosts文件hosts文件中添加以下内容vim /etc/hosts 127.0.0.1 peer1 127.0.0.1 peer2 127.0.0.1 peer3 修改properties文件 创建 application-peer1.properties 将serviceUrl指向peer2、peer3 spring.application.name=life-cloud-eureka server.port=8761 eureka.instance.hostname=peer1 # 实例名称显示IP eureka.instance.prefer-ip-address=true # 健康检查 eureka.server.enable-self-preservation=false # 清理间隔 eureka.server.eviction-interval-timer-in-ms=6000 # 表示是否将自己注册到Eureka Server，默认为true。 eureka.client.register-with-eureka=false # 表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.fetch-registry=false # eureka服务地址 多个地址可使用 , 分隔。 eureka.client.service-url.defaultZone=http://peer2:8762/eureka/,http://peer3:8763/eureka/ 创建 application-peer2.properties 将serviceUrl指向peer1、peer3 spring.application.name=life-cloud-eureka server.port=8762 eureka.instance.hostname=peer2 # 实例名称显示IP eureka.instance.prefer-ip-address=true # 健康检查 eureka.server.enable-self-preservation=false # 清理间隔 eureka.server.eviction-interval-timer-in-ms=6000 # 表示是否将自己注册到Eureka Server，默认为true。 eureka.client.register-with-eureka=false # 表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.fetch-registry=false # eureka服务地址 多个地址可使用 , 分隔。 eureka.client.service-url.defaultZone=http://peer1:8761/eureka/,http://peer3:8763/eureka/ 创建 application-peer3.properties 将serviceUrl指向peer1、peer2 spring.application.name=life-cloud-eureka server.port=8763 eureka.instance.hostname=peer3 # 实例名称显示IP eureka.instance.prefer-ip-address=true # 健康检查 eureka.server.enable-self-preservation=false # 清理间隔 eureka.server.eviction-interval-timer-in-ms=6000 # 表示是否将自己注册到Eureka Server，默认为true。 eureka.client.register-with-eureka=false # 表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.fetch-registry=false # eureka服务地址 多个地址可使用 , 分隔。 eureka.client.service-url.defaultZone=http://peer1:8761/eureka/,http://peer2:8762/eureka/ 打包依次启动mvn clean package 依次启动 java -jar cloud-eureka-0.0.1.jar --spring.profiles.active=peer1 java -jar cloud-eureka-0.0.1.jar --spring.profiles.active=peer2 java -jar cloud-eureka-0.0.1.jar --spring.profiles.active=peer3 启动完成后，浏览器输入：http://localhost:8762/ 效果图如下： 可以在peer2中看到了peer1、peer3的相关的副本信息。至此eureka集群也已经完成了。 以上完整代码github","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/tags/Spring-Cloud/"}]},{"title":"MySQL 常用语句","slug":"mysql-note-01","date":"2019-03-14T08:21:43.000Z","updated":"2024-07-01T12:30:37.376Z","comments":true,"path":"2019/03/14/mysql-note-01/","link":"","permalink":"http://iogogogo.github.io/2019/03/14/mysql-note-01/","excerpt":"","text":"MySQL 常用语句sql-joinmysql常用sql语句总结 修改替换字段中的某一个值update dictionary set content=REPLACE(content, '谭', '谈'); update recipes set item_image=REPLACE(item_image,'http://app-file.botu.com:9000','http://app-file.botu.com:9000/BOTU') where id in (select rec.id from (select id from recipes r where binary r.item_image not like '%BOTU%') rec); 清空表数据truncate table dictionary; -- 清空自增主键 delete from dictionary; -- 不清空自增主键 NULL查询select * from tmp where name is not null; select * from tmp where name is null; 根据表结构生成实体对应字段SELECT CONCAT_WS( '', '/** *', COLUMN_COMMENT, ' */ @TableField(\"',column_name,'\") @JSONField(name = \"',column_name,'\") private ', CASE DATA_TYPE WHEN 'varchar' THEN 'String ' WHEN 'bigint' THEN 'Long ' WHEN 'longtext' THEN 'String ' WHEN 'datetime' THEN 'Date ' WHEN 'int' THEN 'Integer ' WHEN 'decimal' THEN 'BigDecimal ' WHEN 'double' THEN 'Double ' WHEN 'timestamp' THEN 'Timestamp ' WHEN 'longblob' THEN 'Byte[] ' WHEN 'tinyint' THEN 'Integer ' WHEN 'text' THEN 'String ' WHEN 'char' THEN 'Char ' WHEN 'date' THEN 'Date ' WHEN 'float' THEN 'Float ' WHEN 'varbinary' THEN 'Byte[] ' WHEN 'mediumtext' THEN 'String ' WHEN 'enum' THEN 'String ' WHEN 'blob' THEN 'Byte[] ' WHEN 'set' THEN 'String ' WHEN 'time' THEN 'Time ' WHEN 'smallint' THEN 'Integer ' WHEN 'tinytext' THEN 'String ' WHEN 'binary' THEN 'Byte[] ' WHEN 'bit' THEN 'Boolean ' END, column_name, ';' ) FROM information_schema.`COLUMNS` WHERE TABLE_SCHEMA = 'life_health' AND TABLE_NAME = 'health_exp'; 表操作增加与修改列Alter table 表名 add 列名称 列类型 列参数; [加的列在表的最后] 例: alter table m1 add birth date not null default '0000-00-00'; Alter table 表名 add 列名称 列类型 列参数 after 某列; [把新列加在某列后] 例: alter table m1 add gender char(1) not null default '' after username; Alter table 表名 add 列名称 列类型 列参数 first; [把新列加在最前面] 例: alter table m1 add pid int not null default 0 first; 删除列Alter table 表名 drop 列名; 修改列类型Alter table 表名 modify 列名 新类型 新参数; (不能修改列名); 例:alter table m1 modify gender char(4) not null default ''; 修改列名及列类型Alter table 表名 change 旧列名 新列名 新类型 新参数; 例:alter table m1 change id uid int unsigned; 改表名rename table regist3 to reg3; 删除表DROP TABLE IF EXISTS `dictionary`; 常用查询SELECT * FROM sensitive_word_condition a WHERE a.count &lt; 11 ORDER BY a.count DESC LIMIT 1; MySQL 5.7查询一段时间内最后一条数据mysql 升级到5.7之后，存储引擎做了一些优化，之前我们使用的 先order by 再 group by 的方式取最后一条数据的查询，会出现取的不是最后一条记录的问题 为了实现原有查询逻辑，请在子查询后面，加上limit 9223372036854775807其中，9223372036854775807为bigint的最大值 SELECT * FROM ( SELECT e.*, DATE_FORMAT(`update_date`, '%Y-%m-%d') AS edt FROM health_exp e WHERE update_date BETWEEN '2018-02-01' AND '2018-02-06 23:23:59' AND user_id = '2baef230bad144e89296c2c51fa2b680' ORDER BY update_date DESC LIMIT 9223372036854775807 ) t GROUP BY t.edt;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"Vertica 分析函数","slug":"vertica-03","date":"2019-03-14T03:33:07.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"2019/03/14/vertica-03/","link":"","permalink":"http://iogogogo.github.io/2019/03/14/vertica-03/","excerpt":"","text":"分析函数作为 SQL 言语的一种扩展已经被纳入了美国国家标准化组织SQL 委员会的SQL 规范说明书中。所以不同数据库厂商支持的分析函数其语法结构和函数名称也基本一致。这里仅介绍Vertica的的分析函数语法和函数作用，应用函数相关例子略。 分析函数语法ANALYTIC_FUNCTION（argument-1，...，argument-n） OVER（[window_partition_clause] [window_order_clause] [window_frame_clause） 常见函数用途和描述 和 该函数计算组中表达式的累积和 MIN 在一个组中的数据窗口中查找表达式的最小值 MAX 在一个组中的数据窗口中查找表达式的最大值 AVG 用于计算一个组和数据窗口内表达式的平均值。 计数 对一组内发生的事情进行累积计数 秩 根据ORDER BY子句中表达式的值，从查询返回的每一行，计算它们与其它行的相对位置 DENSE_RANK 根据ORDER BY子句中表达式的值，从查询返回的每一行，计算它们与其它行的相对位置 FIRST_VALUE 返回组中数据窗口的第一个值 LAST_VALUE 返回组中数据窗口的最后一个值。 落后 可以访问结果集中的其它行而不用进行自连接 铅 LEAD与LAG相反，LEAD可以访问组中当前行之后的行 ROW_NUMBER 返回有序组中一行的偏移量，从而可用于按特定标准排序的行号 STDDEV 计算当前行关于组的标准偏离 STDDEV_POP 该函数计算总体标准偏离，并返回总体变量的平方根 STDDEV_SAMP 该函数计算累积样本标准偏离，并返回总体变量的平方根 VAR_POP 该函数返回非空集合的总体变量（忽略null） VAR_SAMP 该函数返回非空集合的样本变量（忽略null） 方差 如果表达式中行数为1，则返回0，如果表达式中行数大于1，则返回VAR_SAMP CUME_DIST 计算一行在组中的相对位置 NTILE 将一个组分为“表达式”的散列表示 PERCENT_RANK 和CUME_DIST（累积分配）函数类似 PERCENTILE_DISC 返回一个与输入的分布百分比值相对应的数据值 PERCENTILE_CONT 返回一个与输入的分布百分比值相对应的数据值 MEDIAN 在一个组中的数据窗口中查找最小值与最大值的平均值 参数-1，…，参数-n分析函数的参数 window_partition_clause根据划分表达式设置的规则， PARTITION BY （按… 划分）将一个结果逻辑分成Ñ 个分组划分表达式。在此“ 划分” 和“ 分组” 用作同义词。分析函数独立应用于各个分组，并在应用时重置。 OVER（PARTITION BY expression [，...]） window_order_clauseORDER BY （按… 排序）语句规定了每个分组（划分）的数据如何排序。这些必然影响分析函数的结果。 OVER（ORDER BY expression [{ASC | DESC}] ... [NULLS {FIRST | LAST | AUTO}] [，expression ...]） window_frame_clause窗口生成语句用以定义滑动或固定数据窗口，分析函数在分组内进行分析。该语句能够对分组中任意定义的滑动或固定窗口进行计算。","categories":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/categories/Vertica/"}],"tags":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/tags/Vertica/"}]},{"title":"Vertica 基本操作语句","slug":"vertica-02","date":"2019-03-14T02:51:43.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"2019/03/14/vertica-02/","link":"","permalink":"http://iogogogo.github.io/2019/03/14/vertica-02/","excerpt":"","text":"基本介绍基于列存储的数据库，相对于传统的基于行的数据库，它更适合在数据仓库存储方面发挥特长。基于列存储的数据库的优点： 对于聚集操作，比如求sum，明显基于列存储的要比基于行存储的快； 对于update操作，不须接触其他列值； 基于行存储的数据库在查询每行记录的多个列值更高效的条件是，row-size比较小，这样一次磁盘读取就可以获取整行； 基于行存储的数据库在insert一行的时候相对更高效，毕竟可一次写入一个连续空间，即一次single disk seek。 从实际情况上来看，基于行存储的数据库更适合OLTP（联机事务处理系统），基于列存储的数据库更适合OLAP（联机分析处理系统），比如数据仓库。除此之外，同一列必定是同一类型大小，基于列存储的数据库更容易使用高效的存储方式，与之相对，基于行存储的数据库则只能采用随机方式处理列值了。 Vertica数据库的设计特点是： 它是基于列的存储结构，提高了连续的record处理的性能，但是在一般事务中增加了对单独record进行update和delete的开销； “单独”更新（out-of-place updates）和混合存储结构，提高了查询、插入的性能，但增加了update和delete的开销； 压缩，减少存储开销和IO带宽开销； 完全无共享架构，降低对共享资源的系统竞争。 Vertica数据库运行在基于Linux的网格服务器上，目前应用于Amazon Elastic Compute Cloud的数据库管理系统。 基本操作进入 vsql 环境vsql -U dbadmin -w 123456 查看帮助dbadmin=> \\h 切换vertica用户，用于创建database# 切换用户 su - dbadmin # 进入vertica管理工具 /opt/vertica/bin/admintools 创建数据库 用户与schema查询查询用户select * from v_catalog.users; 查询schemaselect * from schemata; 某个schema必须附属于某个用户（user），查询用户和schema信息SELECT u.user_name, s.schema_name FROM users u LEFT OUTER JOIN schemata s ON u.user_name = s.schema_owner; 创建用户和schema创建一个用户# username:dev_test password:test create user dev_test identified by 'test'; 基于某个用户创建schemacreate schema if not exists test authorization dev_test; 重命名(备份)dataname数据库为 dataname_bak alter schema dataname rename to dataname_bak; 删除 schema(dataname)drop schema dataname cascade; 创建表CREATE TABLE test.\"user\" ( id Integer NOT NULL, name Varchar(100), description Varchar(1024) ); 赋权一个schema上的权限赋给另一个用户GRANT USAGE ON SCHEMA dbname_dw TO dev_test; 把对某个表的操作的权限赋给另一个用户GRANT ALL ON TABLE tw_re_pm_cell_all_cell_h to dev_test; 从某个用户收回对某个schema的使用权限revoke all on SCHEMA dbname_dw from dev_test; 从某个用户收回对某个表的使用权限revoke all on table fct_flux_se_flux_flow_whole_ana_d from dev_test; 序列查询系统中的序列select * from sequences; 创建序列# 简单语法： CREATE SEQUENCE my_seq MAXVALUE 5000 START 1; # 标准语法： CREATE SEQUENCE [[db-name.]schema.]sequence_name ... [ INCREMENT [ BY ] positive_or_negative ] ... [ MINVALUE minvalue | NO MINVALUE ] ... [ MAXVALUE maxvalue | NO MAXVALUE ] ... [ START [ WITH ] start ] ... [ CACHE cache ] ... [ CYCLE | NO CYCLE ] 使用序列# 一个新创建还没有使用过的序列，必须首先执行NEXTVAL，然后才能执行CURRVAL。 SELECT NEXTVAL('my_seq'); SELECT CURRVAL('my_seq'); 在INSERT语句里使用序列 INSERT INTO customer VALUES ('Hawkins' ,'John', 072753, NEXTVAL('my_seq')); 在INSERT语句里把序列作为默认值： CREATE TABLE customer2(ID INTEGER DEFAULT NEXTVAL('my_seq'), lname VARCHAR(25), fname VARCHAR(25), membership_card INTEGER ); => INSERT INTO customer2 VALUES (default,'Carr', 'Mary', 87432); 删除序列 DROP SEQUENCE seq_name; Vertica创建外部表CREATE EXTERNAL TABLE ext1 (x integer) AS COPY FROM '/tmp/ext1.dat' DELIMITER ','; CREATE EXTERNAL TABLE ext1 (x integer) AS COPY FROM '/tmp/ext1.dat.bz2' BZIP DELIMITER ','; CREATE EXTERNAL TABLE ext1 (x integer, y integer) AS COPY (x as '5', y) FROM '/tmp/ext1.dat.bz2' BZIP DELIMITER ','; copy执行错误后的Vertica的错误日志/database/dbname/dbname/v_dbname_node0002_catalog/CopyErrorLogs 从vertica数据的表中导出数据到数据文件echo `vsql -d dbname -U dbadmin -Atq -w Zongfen_12 -c \"select * from test.dim_flow_direction order by flow_type_code\"> /database/datastage/export/dim_all/test` 通过数据文件向vertica数据库里加载数据copy test.fct_flux_se_bus_res_ana_d from '/database/imp_file/fct_flux_se_bus_res_ana_d' on v_dbname_node0002 delimiter '|'; 修改字段修改字段为非空alter table test.fct_fournet_wlanap_equp_ana_d alter column day_id set not null; 更改字段数据类型对于数值类型：types–INTEGER, INT, BIGINT, TINYINT, INT8, SMALLINT, and all NUMERIC values of scale &lt;=18 and precision 0 之间是可以互相转化的。此外，numeric类型的精度（precision）是无法更改的，但是长度(scale)是可以修改的，（0-18）之间可以互修改，（19-37）之间可以互修改。 alter table test.dim_micro_area_gsm alter column cell_id set data type numeric(15,0); 给表增加字段 alter table test.DIM_DETAIL_SVCTYPE add column if_app numeric(10,0); 删除表字段alter table test.DIM_DETAIL_SVCTYPE drop column if_app; 数据库表之间导数据CONNECT TO VERTICA dbname USER dbadmin PASSWORD 'dbname' ON '192.168.1.1',5433; export TO VERTICA dbname.test.FCT_TNES_GN_NET_M FROM test.FCT_TNES_GN_NET_M; 修改普通表为分区表alter table test.fct_fournet_wlanap_equp_ana_d partition by day_id; 修改表名alter table test.fct_fournet_wlanap_equp_ana_d_x rename to fct_fournet_wlanap_equp_ana_d; 修改表所属的用户alter table test.fct_fournet_wlanap_equp_ana_d owner to dev_test 查询表tables projectionsprojections # 查询表对应的projection SELECT owner_name, anchor_table_name, projection_name FROM projections WHERE projection_basename = 'DIM_CFG_LEVEL'; 查询列columns 查询注释comments # 查询表的列对应的注释 SELECT t3.anchor_table_name AS Table_name, SUBSTR (t1.object_name, INSTR (t1.object_name, '.', 1) + 1) AS Column_name, t1.comment AS comment FROM comments t1, projections t3 WHERE SUBSTR (t1.object_name, 1, INSTR (t1.object_name, '.', 1) - 1) = t3.projection_name AND t1.object_type = 'COLUMN' ORDER BY t3.anchor_table_name; 其他操作四舍五入、并且保留两位小数SELECT TRIM (TO_CHAR (ROUND (3.456, 2.0), '999999999999999999.00')), TRIM (TO_CHAR (ROUND (3, 2.0), '999999999999999999.00')), TRIM (TO_CHAR (ROUND (3.00, 2.0), '999999999999999999.00')), TRIM (TO_CHAR (ROUND (323542.101, 2.0), '999999999999999999.00')), TRIM (TO_CHAR (ROUND (3.1067, 2.0), '999999999999999999.00')) 产生随机数 RANDOM() SELECT RANDOM(); RANDOMINT RANDOMINT ( N )","categories":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/categories/Vertica/"}],"tags":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/tags/Vertica/"}]},{"title":"Vertica 简介","slug":"vertica-01","date":"2019-03-14T02:51:39.000Z","updated":"2024-07-01T12:30:37.380Z","comments":true,"path":"2019/03/14/vertica-01/","link":"","permalink":"http://iogogogo.github.io/2019/03/14/vertica-01/","excerpt":"","text":"Vertica是一款基于列存储的MPP （massively parallel processing）架构的数据库。它可以支持存放多至PB（Petabyte）级别的结构化数据。Vertica是由关系数据库大师Michael Stonebraker(2014 年图灵奖获得者)所创建，于2011年被惠普收购并成为其核心大数据平台软件。 简介Vertica是一款基于列存储的MPP（massively parallel processing）架构的数据库。 它可以支持存放多至PB（Petabyte）级别的结构化数据。Vertica是由关系数据库大师Michael Stonebraker(2014 年图灵奖获得者)所创建，于2011年被惠普收购并成为其核心大数据平台软件。 Vertica 采用无共享的MPP 架构，基于工业标准的x86 服务器，拥有高可扩展性。Vertica 集群中的所有节点100%对等，集群中没有主节点或其他共享资源。通过增加节点，就可以线性地扩展集群的计算能力和数据处理容量。 Vertica 是真正的纯列式数据库，优化器和执行引擎可以忽略表中与查询无关的列。Vertica 不仅仅按列式存储数据，还主动地根据列数据的特点和查询的要求选用最佳的算法对数据进行排序和编码压缩，这就极大地降低磁盘I/O 消耗。同时，Vertica 的执行引擎和优化器也是基于列式数据库设计的，编码压缩过的列数据在Vertica 的执行引擎中进行过滤、关联、分组等操作时不需要解反编码，从而大大降低了CPU 和内存消耗。 Vertica 充分利用列式存储的优点，在保持对前端应用透明的前提下，把数据在集群中的所有节点进行均匀分布的同时，还在多个节点上对同一份数据维护了多个拷贝，确保任意一个扩几个节点出现故障或进入维修状态都不会影响集群的健康状态。这使得Vertica 拥有类似磁盘RAID 一样高可靠性。 无共享的MPP 架构和真正的列式数据库特性，使Vertica 拥有高性能、高扩展性、高压缩率、高健壮性的特点。与传统的解决方案相比，Vertica 可以以30%的成本，实现50 倍-1000 倍的性能提高。 软件优势作为全新架构的实时分析平台，Vertica 有很多的创新，特点包括： 列式存储和计算 通过列式计算和强大的主动数据压缩，大幅降低成本高昂的磁盘 I/O（主要是传统的以行为存储单位的SQL 数据库使用），执行查询的速度可提升 50 到 1000倍，存储成本最高削减 90%。 “横向扩展式”大规模并行处理 (MPP) 基于无共享的MPP 架构，支持在线添加数量不限的X86 工业标准服务器，可根据需求任意扩展解决方案。 实时分析 通过内存与磁盘混合存储架构，以及原生支持kafka 消息系统的连接，支持数据实时装载和秒级分析。 数据库内部分析库 开箱即用的数据库内时序插值和关联、事件窗口和会话处理、模式匹配、空间地理分析、文本情感分析等高级分析，以及广义线性回归、逻辑回归、K-Means聚类、朴素贝叶斯分类等常用机器学习和预测分析功能。您也可以获取开源分析库，包括源自 CRAN（综合 R 存档网络）的众多分析功能包。 完整的关系数据库和SQL 标准支持 Vertica 支持关系数据库事务处理和ACID 规范，支持SQL-92/SQL-99/SQL-2003 标准，提供ODBC、JDBC、ADO.NET 接口规范驱动，完全兼容传统关系数据库的开发、使用和管理习惯，可以轻松与现有的ETL 和报表工具集成，保护客户已有的投资。 可扩展的数据库内部分析框架 采用面向用户定义的过程式分析的强大开发框架，实现了对于数据库内部处理的开放式访问。除了使用内置的 SQL 分析和聚合函数外，还可借助 C++/Java/R语言软件开发人员套件 (SDK) 定义自己的定制函数。SDK 功能可保证沙盒安全，并使函数能够并行运行以加快运行速度。 原生支持Hadoop Vertica 可以作为SQL 分析引擎直接部署到Hadoop 集群中，直接存取HDFS上的数据；也可以通过标准SQL 直接访问Hive 等管理的数据，并与Vertica 管理的数据进行关联分析；另外Vertica 还提供应用编程接口 (API)支持与MapReduce、Pig 等框架构建结构化、半结构化和非结构化深度融合的大数据分析应用。 自动实现高可用性 不间断运行，并具有数据复制、故障转移和恢复功能；Vertica 进行了性能优化，并且对业务和运营团队完全透明。 自动优化和性能管理 通过强大的 API 集合来监控系统的资源、后台进程、工作负载及性能，通过工作负载分析和数据库设计器自动优化数据库，简化系统管理。 以上摘自百度百科。","categories":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/categories/Vertica/"}],"tags":[{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/tags/Vertica/"}]},{"title":"Mac 修改MySQL编码集","slug":"mac-change-character-set","date":"2019-03-09T14:05:06.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2019/03/09/mac-change-character-set/","link":"","permalink":"http://iogogogo.github.io/2019/03/09/mac-change-character-set/","excerpt":"","text":"前两天因为Cisco的VPN坏了，一直用不了，所以重新还原了Mac，重新安装了所有的软件，其中就有MySQL-5.7.25。之前安装以后也是第一时间设置了MySQL的编码为utf8，这次新安装也再次记录一下修改步骤 查看Mac 安装MySQL以后的默认编码SHOW VARIABLES LIKE 'character_set_%'; # 结果 character_set_client utf8mb4 character_set_connection utf8mb4 character_set_database latin1 ## 这里是默认编码 character_set_filesystem binary character_set_results utf8mb4 character_set_server latin1 ## 这里是默认编码 character_set_system utf8 character_sets_dir /usr/local/mysql-5.7.25-macos10.14-x86_64/share/charsets/ 新建my.cnf文件[client] default-character-set=utf8 [mysqld] collation-server = utf8_unicode_ci init-connect='SET NAMES utf8' character-set-server = utf8 [mysql] default-character-set=utf8 移动到 /etc 目录移动my.cnf文件到/etc目录，需要root权限 sudo mv my.cnf /etc/ 重启MySQL，再次查看编码SHOW VARIABLES LIKE 'character_set_%'; # 结果 character_set_client utf8mb4 character_set_connection utf8mb4 character_set_database utf8 ## 这里是修改以后的 character_set_filesystem binary character_set_results utf8mb4 character_set_server utf8 ## 这里是修改以后的 character_set_system utf8 character_sets_dir /usr/local/mysql-5.7.25-macos10.14-x86_64/share/charsets/","categories":[{"name":"MacBook","slug":"MacBook","permalink":"http://iogogogo.github.io/categories/MacBook/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://iogogogo.github.io/tags/Mac/"}]},{"title":"Elasticsearch 快速上手","slug":"elasticsearch-rest-api","date":"2019-03-09T05:29:36.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2019/03/09/elasticsearch-rest-api/","link":"","permalink":"http://iogogogo.github.io/2019/03/09/elasticsearch-rest-api/","excerpt":"","text":"Elasticsearch 快速上手 注：本文档中除无特别说明，请求方式均为GET。所有的请求均在Sense中测试通过 遵循的格式为 curl -X&lt;REST Verb&gt; &lt;Node&gt;:&lt;Port&gt;/&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt; 集群健康查看 http://127.0.0.1:9200/_cat/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks 1441940569 11:02:49 elasticsearch yellow 1 1 7 7 0 0 7 0 http://127.0.0.1:9200/_cat/nodes?v host ip heap.percent ram.percent load node.role master name acer 169.254.9.202 32 52 d * Mys-Tech 列出所有的indices http://127.0.0.1:9200/_cat/indices?v health status index pri rep docs.count docs.deleted store.size pri.store.size yellow open .marvel-2015.09.11 1 1 3233 0 10.5mb 10.5mb yellow open .marvel-2015.09.10 1 1 1996 0 3.9mb 3.9mb yellow open news 5 1 3455 0 17.8mb 17.8mb 创建索引使用PUT请求创建一个countries的索引 curl -XPUT http://127.0.0.1:9200/countries?pretty 输出: { &quot;acknowledged&quot;: true } 查看索引列表 curl -XGET http://127.0.0.1:9200/_cat/indices?v 输出: health status index pri rep docs.count docs.deleted store.size pri.store.size yellow open countries 5 1 0 0 575b 575b yellow open .marvel-2015.09.11 1 1 3436 0 11.4mb 11.4mb yellow open .marvel-2015.09.10 1 1 1996 0 3.9mb 3.9mb yellow open news 5 1 3455 0 17.8mb 17.8mb 索引文档 使用自定义id索引文档 使用PUT请求创建一个索引为countries类型为country的文档。其文档编号为1，文档内容包含name和capital curl -XPUT http://127.0.0.1:9200/countries/country/1?pretty -d &#39; { &quot;name&quot;: &quot;中国&quot;, &quot;capital&quot;: &quot;北京&quot; }&#39; 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;created&quot;: true } 使用系统分配的id索引文档 curl -XPOST http://127.0.0.1:9200/countries/country?pretty -d &#39; { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; }&#39; 注意：使用系统分配的id时使用POST方式提交文档，且在索引\\类型url格式中不再有id 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;AU-6awteDgxJZYVN-E5I&quot;, &quot;_version&quot;: 1, &quot;created&quot;: true } 查询文档使用自定义id查询文档 curl -XGET http://127.0.0.1:9200/countries/country/1?pretty 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: { &quot;name&quot;: &quot;中国&quot;, &quot;capital&quot;: &quot;北京&quot; } } 使用系统分配的id查询 GET http://127.0.0.1:9200/countries/country/AU-6awteDgxJZYVN-E5I?pretty 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;AU-6awteDgxJZYVN-E5I&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } } 查看索引信息GET http://127.0.0.1:9200/countries/ 输出: { &quot;countries&quot;: { &quot;aliases&quot;: {}, &quot;mappings&quot;: { &quot;country&quot;: { &quot;properties&quot;: { &quot;capital&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;name&quot;: { &quot;type&quot;: &quot;string&quot; } } } }, &quot;settings&quot;: { &quot;index&quot;: { &quot;creation_date&quot;: &quot;1441941497754&quot;, &quot;uuid&quot;: &quot;UaoQ_WCATaiy5w736cjw2A&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;number_of_shards&quot;: &quot;5&quot;, &quot;version&quot;: { &quot;created&quot;: &quot;1070199&quot; } } }, &quot;warmers&quot;: {} } } 删除索引删除myindex索引 DELETE http://127.0.0.1:9200/myindex/?pretty 输出: { &quot;acknowledged&quot;: true } 索引或替换一个文档根据文档id索引或替换文档，若存在则修改替换，否则索引该文档。 使用已存在的id 修改文档id为1的国家信息。 PUT &#39;http://127.0.0.1:9200/countries/country/1?pretty&#39; { &quot;name&quot;: &quot;日本&quot;, &quot;capital&quot;: &quot;东京&quot; } 查询其是否已修改 GET http://127.0.0.1:9200/countries/country/1?pretty 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: { &quot;name&quot;: &quot;日本&quot;, &quot;capital&quot;: &quot;东京&quot; } } 可见国家信息已由中国变为日本，其首都信息也发生了变化 使用不存在的id则是索引文档 PUT http://127.0.0.1:9200/countries/country/2?pretty { &quot;name&quot;: &quot;澳大利亚&quot;, &quot;capital&quot;: &quot;悉尼&quot; } 输出: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 1, &quot;created&quot;: true } 修改文档 按doc方式更新文档 以doc方式修改文档id为1的文档 POST http://127.0.0.1:9200/countries/country/1/_update?pretty { &quot;doc&quot;: { &quot;name&quot;: &quot;美国&quot;,&quot;capital&quot;: &quot;华盛顿&quot;} } 其中doc是固定写法,其内容为要修改的文档内容 按script方式更新文档 以script方式修改文档id为1的文档 POST http://127.0.0.1:9200/countries/country/1/_update?pretty { &quot;script&quot;: &quot;ctx._source.name=\\&quot;加拿大\\&quot;;ctx._source.capital=\\&quot;渥太华\\&quot;&quot; } 删除文档 按文档id删除 DELETE http://127.0.0.1:9200/countries/country/1?pretty 输出： { &quot;found&quot;: true, &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 6 } 根据查询结果删除 DELETE http://127.0.0.1:9200/countries/country/_query?pretty { &quot;query&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;美国&quot; } } } 输出： { &quot;_indices&quot;: { &quot;countries&quot;: { &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 } } } } 查询是否还有name为美国的文档 GET http://127.0.0.1:9200/countries/country/_query { &quot;query&quot;: { &quot;match_all&quot;: { &quot;name&quot;: &quot;美国&quot; } } } 批量处理_bulk api https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html 遵循格式 /_bulk, /{index}/_bulk, {index}/{type}/_bulk action_and_meta_data\\n optional_source\\n action_and_meta_data\\n optional_source\\n 支持的action有index, create, delete, update index和create在下一行跟上要索引的docdelete则不需要update在下一行跟上doc或script 批量索引文档 POST http://127.0.0.1:9200/countries/country/_bulk?pretty {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;name&quot;: &quot;中国&quot;,&quot;capital&quot;: &quot;北京&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;name&quot;: &quot;美国&quot;,&quot;capital&quot;: &quot;华盛顿&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;name&quot;: &quot;日本&quot;,&quot;capital&quot;: &quot;东京&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;4&quot;}} {&quot;name&quot;: &quot;澳大利亚&quot;,&quot;capital&quot;: &quot;悉尼&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;name&quot;: &quot;印度&quot;,&quot;capital&quot;: &quot;新德里&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;6&quot;}} {&quot;name&quot;: &quot;韩国&quot;,&quot;capital&quot;: &quot;首尔&quot;} 以上请求将会批量索引6个文档。 输出： { &quot;took&quot;: 4, &quot;errors&quot;: false, &quot;items&quot;: [ { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 2, &quot;status&quot;: 200 } }, { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;6&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } } ] } 批量执行，含index、create、delete、update POST http://127.0.0.1:9200/countries/country/_bulk?pretty {&quot;index&quot;:{&quot;_id&quot;:&quot;7&quot;}} {&quot;name&quot;: &quot;新加坡&quot;,&quot;capital&quot;: &quot;渥太华&quot;} {&quot;create&quot;:{&quot;_id&quot;:&quot;8&quot;}} {&quot;name&quot;: &quot;德国&quot;,&quot;capital&quot;: &quot;柏林&quot;} {&quot;update&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;doc&quot;: {&quot;name&quot;: &quot;法国&quot;,&quot;capital&quot;: &quot;巴黎&quot; }} {&quot;update&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;script&quot;: &quot;ctx._source.name = \\&quot;法国\\&quot;;ctx._source.capital = \\&quot;巴黎\\&quot;&quot;} {&quot;delete&quot;:{&quot;_id&quot;:&quot;2&quot;}} 输出： { &quot;took&quot;: 40, &quot;errors&quot;: false, &quot;items&quot;: [ { &quot;index&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;create&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;8&quot;, &quot;_version&quot;: 1, &quot;status&quot;: 201 } }, { &quot;update&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;status&quot;: 200 } }, { &quot;update&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_version&quot;: 2, &quot;status&quot;: 200 } }, { &quot;delete&quot;: { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 3, &quot;status&quot;: 200, &quot;found&quot;: true } } ] } 导入数据 countries.json {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;name&quot;: &quot;新加坡&quot;,&quot;capital&quot;: &quot;渥太华&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;name&quot;: &quot;韩国&quot;,&quot;capital&quot;: &quot;首尔&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;name&quot;: &quot;朝鲜&quot;,&quot;capital&quot;: &quot;平壤&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;4&quot;}} {&quot;name&quot;: &quot;日本&quot;,&quot;capital&quot;: &quot;东京&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;name&quot;: &quot;马来西亚&quot;,&quot;capital&quot;: &quot;吉隆坡&quot;} 使用curl的--data-binary参数导入数据 curl XPOST http://127.0.0.1:9200/countries/country/_bulk?pretty --data-binary @countries.json 或者使用postman导入 http://127.0.0.1:9200/countries/country/_bulk?pretty {&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}} {&quot;name&quot;: &quot;新加坡&quot;,&quot;capital&quot;: &quot;渥太华&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}} {&quot;name&quot;: &quot;韩国&quot;,&quot;capital&quot;: &quot;首尔&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;3&quot;}} {&quot;name&quot;: &quot;朝鲜&quot;,&quot;capital&quot;: &quot;平壤&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;4&quot;}} {&quot;name&quot;: &quot;日本&quot;,&quot;capital&quot;: &quot;东京&quot;} {&quot;index&quot;:{&quot;_id&quot;:&quot;5&quot;}} {&quot;name&quot;: &quot;马来西亚&quot;,&quot;capital&quot;: &quot;吉隆坡&quot;} search api GET方式搜索(queryString) GET http://127.0.0.1:9200/countries/_search?q=*&amp;pretty 注:q=*将匹配索引中的所有文档 输出: { &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 10, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;日本&quot;, &quot;capital&quot;: &quot;东京&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;_query&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;query&quot;: { &quot;match_all&quot;: { &quot;name&quot;: &quot;美国&quot; } } } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;印度&quot;, &quot;capital&quot;: &quot;新德里&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;6&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;新加坡&quot;, &quot;capital&quot;: &quot;渥太华&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;新加坡&quot;, &quot;capital&quot;: &quot;渥太华&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;AU-6awteDgxJZYVN-E5I&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;8&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;德国&quot;, &quot;capital&quot;: &quot;柏林&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;朝鲜&quot;, &quot;capital&quot;: &quot;平壤&quot; } } ] } } POST方式搜索(含请求体query) POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} } } 输出: { &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 10, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;日本&quot;, &quot;capital&quot;: &quot;东京&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;_query&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;query&quot;: { &quot;match_all&quot;: { &quot;name&quot;: &quot;美国&quot; } } } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;5&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;印度&quot;, &quot;capital&quot;: &quot;新德里&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;6&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;新加坡&quot;, &quot;capital&quot;: &quot;渥太华&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;7&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;新加坡&quot;, &quot;capital&quot;: &quot;渥太华&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;AU-6awteDgxJZYVN-E5I&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;韩国&quot;, &quot;capital&quot;: &quot;首尔&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;8&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;德国&quot;, &quot;capital&quot;: &quot;柏林&quot; } }, { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;朝鲜&quot;, &quot;capital&quot;: &quot;平壤&quot; } } ] } } 限定返回条目 POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;size&quot;: 1 } size控制返回条目，默认为10 输出: { &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 10, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;countries&quot;, &quot;_type&quot;: &quot;country&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;name&quot;: &quot;日本&quot;, &quot;capital&quot;: &quot;东京&quot; } } ] } } 分页(form,size) POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 2, &quot;size&quot;: 2 } 使用from和size来翻页。其中form默认为0,size默认为10 排序(sort) POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;name&quot;: { &quot;order&quot;: &quot;desc&quot; } } ] } 其中name为排序字段 限定返回字段POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;name&quot;] } 使用_source来限定返回的字段。这里只返回name 高级查询 match_phrase POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;name&quot;: &quot;韩国&quot; } } } must POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match&quot;: { &quot;name&quot;: &quot;日本&quot; }}, {&quot;match&quot;: { &quot;capital&quot;: &quot;东京&quot; }} ] } } } should POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ {&quot;match&quot;: { &quot;name&quot;: &quot;日本&quot; }}, {&quot;match&quot;: { &quot;name&quot;: &quot;韩国&quot; }} ] } } } must_not POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;bool&quot;: { &quot;must_not&quot;: [ {&quot;match&quot;: { &quot;name&quot;: &quot;日本&quot; }}, {&quot;match&quot;: { &quot;name&quot;: &quot;韩国&quot; }} ] } } } filter POST http://127.0.0.1:9200/countries/_search?pretty { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;filter&quot;: { &quot;term&quot;: { &quot;capital&quot;: &quot;东京&quot; } } } 聚合(aggs) POST http://127.0.0.1:9200/countries/_search?pretty { &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;group_by_name&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;name&quot; } } } } 按name统计分组文档数 输出: { &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 10, &quot;max_score&quot;: 0, &quot;hits&quot;: [] }, &quot;aggregations&quot;: { &quot;group_by_name&quot;: { &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ { &quot;key&quot;: &quot;韩国&quot;, &quot;doc_count&quot;: 3 }, { &quot;key&quot;: &quot;新加坡&quot;, &quot;doc_count&quot;: 2 }, { &quot;key&quot;: &quot;印度&quot;, &quot;doc_count&quot;: 1 }, { &quot;key&quot;: &quot;德国&quot;, &quot;doc_count&quot;: 1 }, { &quot;key&quot;: &quot;日本&quot;, &quot;doc_count&quot;: 1 }, { &quot;key&quot;: &quot;朝鲜&quot;, &quot;doc_count&quot;: 1 } ] } } } 高亮查询(highlight)POST http://127.0.0.1:9200/news/_search?q=李克强 { &quot;query&quot; : { match_all:{} }, &quot;highlight&quot; : { &quot;pre_tags&quot; : [&quot;&lt;font color=&#39;red&#39;&gt;&quot;, &quot;&lt;b&gt;&quot;, &quot;&lt;em&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/font&gt;&quot;, &quot;&lt;b&gt;&quot;, &quot;&lt;/em&gt;&quot;], &quot;fields&quot; : [ {&quot;title&quot; : {}}, {&quot;content&quot; : { &quot;fragment_size&quot; : 350, &quot;number_of_fragments&quot; : 3, &quot;no_match_size&quot;: 150 }} ] } } POST http://127.0.0.1:9200/news/_search?q=李克强 { &quot;query&quot; : { match_all:{} }, &quot;highlight&quot; : { &quot;pre_tags&quot; : [&quot;&lt;font color=&#39;red&#39;&gt;&lt;b&gt;&lt;em&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/font&gt;&lt;b&gt;&lt;/em&gt;&quot;], &quot;fields&quot; : [ {&quot;title&quot; : {}}, {&quot;content&quot; : { &quot;fragment_size&quot; : 350, &quot;number_of_fragments&quot; : 3, &quot;no_match_size&quot;: 150 }} ] } } 删除索引https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-delete-index.html DELETE http://127.0.0.1:9200/news 创建索引https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html PUT http://127.0.0.1:9200/news 创建或修改mappinghttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-put-mapping.html PUT /{index}/_mapping/{type} PUT http://127.0.0.1:9200/news/_mapping/article { &quot;article&quot;: { &quot;properties&quot;: { &quot;pubdate&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;dateOptionalTime&quot; }, &quot;author&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;content&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;id&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;source&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;url&quot;: { &quot;type&quot;: &quot;string&quot; } } } } 查看mappinghttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-mapping.html GET http://127.0.0.1:9200/_all/_mapping GET http://127.0.0.1:9200/_mapping GET http://127.0.0.1:9200/news/_mapping/article 输出: { &quot;news&quot;: { &quot;mappings&quot;: { &quot;article&quot;: { &quot;properties&quot;: { &quot;author&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;content&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;id&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;pubdate&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;store&quot;: true, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot; }, &quot;source&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;url&quot;: { &quot;type&quot;: &quot;string&quot; } } } } } } 删除mappinghttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-delete-mapping.html [DELETE] /{index}/{type} [DELETE] /{index}/{type}/_mapping [DELETE] /{index}/_mapping/{type} DELETE http://127.0.0.1:9200/news/_mapping/article 文章转自:elasticsearch快速上手.md","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://iogogogo.github.io/categories/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://iogogogo.github.io/tags/elasticsearch/"}]},{"title":"Java8 stream-实战","slug":"java8-stream-drill","date":"2019-03-06T09:03:21.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2019/03/06/java8-stream-drill/","link":"","permalink":"http://iogogogo.github.io/2019/03/06/java8-stream-drill/","excerpt":"","text":"Java8在日常编码中感触最深的无非就是steam和lambda表达式以及新的时间api，在此之前，集合处理一直是不太方便且性能较低，第二个是时间api不好用，一般配合joda-time这个库配合使用，下面介绍一些在Java8中常用的stream处理 List转换成Map/** * toMap 如果集合中重复的key 可能会抛出异常 Duplicate key... * apply1、apply2的ID都为1 既m1,m2的ID都为1 * 可以用(m1,m2)->m1 来设置 如果有重复的key 保留m1 舍弃m2 */ Map&lt;String, Model> modelMap = modelList .parallelStream() .collect(Collectors.toMap(Model::getId, x -> x, (m1, m2) -> m1)); groupBy以后求最大值或者最小值http://www.java2s.com/Tutorials/Java_Streams/Example/Group/Get_max_value_in_each_group.htm @Data @NoArgsConstructor @AllArgsConstructor class Model { String hostname; String ip; int num; } @Test public void test() { List&lt;Model> models = new ArrayList&lt;>(); models.add(new Model(\"vm_11_11\", \"192.168.1.0\", 1)); models.add(new Model(\"vm_11_11\", \"192.168.1.1\", 2)); models.add(new Model(\"vm_11_11\", \"192.168.1.2\", 3)); models.add(new Model(\"vm_11_11\", \"192.168.1.3\", 4)); models.add(new Model(\"vm_11_11\", \"192.168.1.2\", 5)); models.add(new Model(\"vm_11_12\", \"192.168.1.3\", 6)); models.add(new Model(\"vm_11_12\", \"192.168.1.6\", 7)); models.add(new Model(\"vm_11_12\", \"192.168.1.7\", 8)); models.add(new Model(\"vm_11_12\", \"192.168.1.8\", 9)); models.add(new Model(\"vm_11_12\", \"192.168.1.9\", 10)); models.add(new Model(\"vm_11_13\", \"192.168.1.10\", 11)); models.add(new Model(\"vm_11_13\", \"192.168.1.11\", 12)); models.add(new Model(\"vm_11_13\", \"192.168.1.11\", 13)); models.add(new Model(\"vm_11_13\", \"192.168.1.12\", 14)); models.add(new Model(\"vm_11_13\", \"192.168.1.11\", 15)); models.add(new Model(\"vm_11_13\", \"192.168.1.15\", 16)); models.add(new Model(\"vm_11_16\", \"192.168.1.16\", 17)); models.add(new Model(\"vm_11_16\", \"192.168.1.17\", 18)); models.add(new Model(\"vm_11_16\", \"192.168.1.18\", 19)); models.add(new Model(\"vm_11_16\", \"192.168.1.19\", 20)); models.add(new Model(\"vm_11_16\", \"192.168.1.20\", 21)); models.add(new Model(\"vm_11_16\", \"192.168.1.21\", 22)); models.add(new Model(\"vm_11_16\", \"192.168.1.22\", 23)); Map&lt;String, Model> map = models .parallelStream() .collect(Collectors.toMap(model -> model.getHostname() + \"_\" + model.getIp(), Function.identity(), (Model d1, Model d2) -> d1.getOrder() &lt; d2.getOrder() ? d1 : d2)); log.info(\"map:{}\", map); } Scala中使用group求出最大值或者最小值object CollectionApp { def main(args: Array[String]): Unit = { val log = LoggerFactory.getLogger(getClass) import scala.collection.JavaConverters._ val models: util.List[Model] = new util.ArrayList[Model]() models.add(Model(\"vm_11_11\", \"192.168.1.0\", 1)) models.add(Model(\"vm_11_11\", \"192.168.1.1\", 2)) models.add(Model(\"vm_11_11\", \"192.168.1.2\", 3)) models.add(Model(\"vm_11_11\", \"192.168.1.3\", 4)) models.add(Model(\"vm_11_11\", \"192.168.1.2\", 5)) models.add(Model(\"vm_11_12\", \"192.168.1.3\", 6)) models.add(Model(\"vm_11_12\", \"192.168.1.6\", 7)) models.add(Model(\"vm_11_12\", \"192.168.1.7\", 8)) models.add(Model(\"vm_11_12\", \"192.168.1.8\", 9)) models.add(Model(\"vm_11_12\", \"192.168.1.9\", 10)) models.add(Model(\"vm_11_13\", \"192.168.1.10\", 11)) models.add(Model(\"vm_11_13\", \"192.168.1.11\", 12)) models.add(Model(\"vm_11_13\", \"192.168.1.11\", 13)) models.add(Model(\"vm_11_13\", \"192.168.1.12\", 14)) models.add(Model(\"vm_11_13\", \"192.168.1.11\", 15)) models.add(Model(\"vm_11_13\", \"192.168.1.15\", 16)) models.add(Model(\"vm_11_16\", \"192.168.1.16\", 17)) models.add(Model(\"vm_11_16\", \"192.168.1.17\", 18)) models.add(Model(\"vm_11_16\", \"192.168.1.18\", 19)) models.add(Model(\"vm_11_16\", \"192.168.1.19\", 20)) models.add(Model(\"vm_11_16\", \"192.168.1.20\", 21)) models.add(Model(\"vm_11_16\", \"192.168.1.21\", 22)) models.add(Model(\"vm_11_16\", \"192.168.1.22\", 23)) val list = models.asScala val res = list.groupBy(x => x.hostname + x.ip).map { case (k, v) => (k, v.map(_.order).min) } log.info(s\"$res\") } } case class Model(hostname: String, ip: String, order: Int) 批处理package com.iogogog.util; import lombok.extern.slf4j.Slf4j; import org.apache.commons.collections4.CollectionUtils; import java.util.ArrayList; import java.util.Collection; import java.util.Iterator; import java.util.List; /** * Created by tao.zeng on 2019-03-09. */ @Slf4j public class BatchProcess { public static void process(Collection&lt;?> totalList, int batchSize, BatchProcessListener batchProcessListener) throws Exception { if (CollectionUtils.isEmpty(totalList)) return; if (batchProcessListener == null) { throw new RuntimeException(\"没有批处理监听器!\"); } Iterator&lt;?> iterator = totalList.parallelStream().iterator(); int i = 0; List&lt;Object> list = new ArrayList&lt;>(1024); while (iterator.hasNext()) { Object next = iterator.next(); list.add(next); if ((i + 1) % batchSize == 0 || i == (totalList.size() - 1)) { // process batchProcessListener.onProcess(list); log.debug(\"batchSize:{} processSize:{} \", batchSize, list.size()); list.clear(); } i++; } } public interface BatchProcessListener { void onProcess(List&lt;?> list) throws Exception; } }","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Spring Boot 使用logback管理日志","slug":"spring-boot-logback","date":"2019-03-02T13:09:11.000Z","updated":"2024-07-01T12:30:37.378Z","comments":true,"path":"2019/03/02/spring-boot-logback/","link":"","permalink":"http://iogogogo.github.io/2019/03/02/spring-boot-logback/","excerpt":"","text":"Spring Boot在所有内部日志中使用Commons Logging，但是默认配置也提供了对常用日志的支持，如：Java Util Logging，Log4J, Log4J2和Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。 下面记录一下spring boot中如何按照日志等级拆分，输出到不同文件并做归档处理 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;configuration scan=\"true\" scanPeriod=\"2000\" debug=\"false\"> &lt;!-- scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。（这个功能可以在不重启运行环境下，调整打印日志的细节，方便定位问题） scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 Logger 可以被分配级别。级别包括：TRACE、DEBUG、INFO、WARN 和 ERROR 级别排序为： TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR --> &lt;!-- springProperty 可以读取application.properties文件中的属性值，只有当logback文件名为logback-spring时，该配置才会生效 --> &lt;springProperty scope=\"context\" name=\"app.name\" source=\"spring.application.name\"/> &lt;springProperty scope=\"context\" name=\"log.home\" source=\"logging.home\"/> &lt;!-- 配置是logback默认的 --> &lt;!--&lt;property name=\"log.home\" value=\"${user.dir}/logs\"/>--> &lt;!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,%i索引【从数字0开始递增】,,, --> &lt;!-- appender是configuration的子节点，是负责写日志的组件。 --> &lt;!-- ConsoleAppender：把日志输出到控制台 --> &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> &lt;encoder> &lt;pattern>%date{ISO8601} [%thread] %-5level [${app.name}] [%logger{50}] [%file:%line] - %msg%n&lt;/pattern> &lt;!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 --> &lt;charset>UTF-8&lt;/charset> &lt;/encoder> &lt;/appender> &lt;!-- info level --> &lt;appender name=\"file_info\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;file>${log.home}/${app.name}.log&lt;/file> &lt;encoder> &lt;pattern>%date{ISO8601} [%thread] %-5level [${app.name}] [%logger{50}] [%file:%line] - %msg%n&lt;/pattern> &lt;/encoder> &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"> &lt;level>INFO&lt;/level> &lt;onMatch>ACCEPT&lt;/onMatch> &lt;onMismatch>DENY&lt;/onMismatch> &lt;/filter> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;fileNamePattern>${log.home}/${app.name}.info.%d{yyyy-MM-dd}.%i.zip&lt;/fileNamePattern> &lt;!-- 如果按天来回滚，则最大保存时间为10天，10天之前的都将被清理掉 --> &lt;maxHistory>10&lt;/maxHistory> &lt;!-- 日志总保存量为500MB --> &lt;totalSizeCap>500MB&lt;/totalSizeCap> &lt;!--文件达到最大50MB时会被压缩和切割 --> &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"> &lt;!--文件达到 最大50MB时会被压缩和切割 --> &lt;maxFileSize>50MB&lt;/maxFileSize> &lt;/timeBasedFileNamingAndTriggeringPolicy> &lt;!--&lt;maxFileSize>50MB&lt;/maxFileSize>--> &lt;/rollingPolicy> &lt;/appender> &lt;!-- debug level --> &lt;appender name=\"file_debug\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;file>${log.home}/${app.name}.debug.log&lt;/file> &lt;encoder> &lt;pattern>%date{ISO8601} [%thread] %-5level [${app.name}] [%logger{50}] [%file:%line] - %msg%n&lt;/pattern> &lt;/encoder> &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"> &lt;level>DEBUG&lt;/level> &lt;onMatch>ACCEPT&lt;/onMatch> &lt;onMismatch>DENY&lt;/onMismatch> &lt;/filter> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;fileNamePattern>${log.home}/${app.name}.debug.%d{yyyy-MM-dd}.%i.zip&lt;/fileNamePattern> &lt;!-- 如果按天来回滚，则最大保存时间为10天，10天之前的都将被清理掉 --> &lt;maxHistory>10&lt;/maxHistory> &lt;!-- 日志总保存量为500MB --> &lt;totalSizeCap>500MB&lt;/totalSizeCap> &lt;!--文件达到最大50MB时会被压缩和切割 --> &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"> &lt;!--文件达到 最大50MB时会被压缩和切割 --> &lt;maxFileSize>50MB&lt;/maxFileSize> &lt;/timeBasedFileNamingAndTriggeringPolicy> &lt;!--&lt;maxFileSize>50MB&lt;/maxFileSize>--> &lt;/rollingPolicy> &lt;/appender> &lt;!-- warn level --> &lt;appender name=\"file_warn\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;file>${log.home}/${app.name}.warn.log&lt;/file> &lt;encoder> &lt;pattern>%date{ISO8601} [%thread] %-5level [${app.name}] [%logger{100}] [%file:%line] - %msg%n&lt;/pattern> &lt;/encoder> &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"> &lt;level>WARN&lt;/level> &lt;onMatch>ACCEPT&lt;/onMatch> &lt;onMismatch>DENY&lt;/onMismatch> &lt;/filter> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;fileNamePattern>${log.home}/${app.name}.warn.%d{yyyy-MM-dd}.%i.zip&lt;/fileNamePattern> &lt;!-- 如果按天来回滚，则最大保存时间为10天，10天之前的都将被清理掉 --> &lt;maxHistory>10&lt;/maxHistory> &lt;!-- 日志总保存量为500MB --> &lt;totalSizeCap>500MB&lt;/totalSizeCap> &lt;!--文件达到最大50MB时会被压缩和切割 --> &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"> &lt;!--文件达到 最大50MB时会被压缩和切割 --> &lt;maxFileSize>50MB&lt;/maxFileSize> &lt;/timeBasedFileNamingAndTriggeringPolicy> &lt;!--&lt;maxFileSize>50MB&lt;/maxFileSize>--> &lt;/rollingPolicy> &lt;/appender> &lt;!-- error level --> &lt;appender name=\"file_error\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;file>${log.home}/${app.name}.error.log&lt;/file> &lt;encoder> &lt;pattern>%date{ISO8601} [%thread] %-5level [${app.name}] [%logger{100}] [%file:%line] - %msg%n&lt;/pattern> &lt;/encoder> &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"> &lt;level>ERROR&lt;/level> &lt;onMatch>ACCEPT&lt;/onMatch> &lt;onMismatch>DENY&lt;/onMismatch> &lt;/filter> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;fileNamePattern>${log.home}/${app.name}.error.%d{yyyy-MM-dd}.%i.zip&lt;/fileNamePattern> &lt;!-- 如果按天来回滚，则最大保存时间为10天，10天之前的都将被清理掉 --> &lt;maxHistory>10&lt;/maxHistory> &lt;!-- 日志总保存量为500MB --> &lt;totalSizeCap>500MB&lt;/totalSizeCap> &lt;!--文件达到最大50MB时会被压缩和切割 --> &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"> &lt;!--文件达到 最大50MB时会被压缩和切割 --> &lt;maxFileSize>50MB&lt;/maxFileSize> &lt;/timeBasedFileNamingAndTriggeringPolicy> &lt;!--&lt;maxFileSize>50MB&lt;/maxFileSize>--> &lt;/rollingPolicy> &lt;/appender> &lt;!-- level Options: ERROR, WARN, INFO, DEBUG --> &lt;!-- logger：日志所处的包或者具体的类 level：日志打印级别 --> &lt;logger name=\"com.zaxxer.hikari\" level=\"WARN\"/> &lt;logger name=\"com.example.LogbackApplication\" level=\"INFO\"/> &lt;root level=\"INFO\"> &lt;!-- Options: ERROR, WARN, INFO, DEBUG --> &lt;appender-ref ref=\"STDOUT\"/> &lt;appender-ref ref=\"file_debug\"/> &lt;appender-ref ref=\"file_info\"/> &lt;appender-ref ref=\"file_warn\"/> &lt;appender-ref ref=\"file_error\"/> &lt;/root> &lt;/configuration>","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Apache CollectionUtils 常用方法总结","slug":"apache-common-collection-utils","date":"2019-03-01T02:09:21.000Z","updated":"2024-07-01T12:30:37.346Z","comments":true,"path":"2019/03/01/apache-common-collection-utils/","link":"","permalink":"http://iogogogo.github.io/2019/03/01/apache-common-collection-utils/","excerpt":"","text":"CollectionUtils在真实项目中，是一个非常好用的工具类，使用非常频繁。它可以使代码更加简洁和安全。 依赖 maven &lt;!-- https://mvnrepository.com/artifact/commons-collections/commons-collections --> &lt;dependency> &lt;groupId>commons-collections&lt;/groupId> &lt;artifactId>commons-collections&lt;/artifactId> &lt;version>3.2.1&lt;/version> &lt;/dependency> gradle // https://mvnrepository.com/artifact/commons-collections/commons-collections compile group: 'commons-collections', name: 'commons-collections', version: '3.2.1' 常用方法非空判断// 判断集合是否为空: CollectionUtils.isEmpty(null): true CollectionUtils.isEmpty(new ArrayList()): true CollectionUtils.isEmpty({a,b}): false // 判断集合是否不为空: CollectionUtils.isNotEmpty(null): false CollectionUtils.isNotEmpty(new ArrayList()): false CollectionUtils.isNotEmpty({a,b}): true 并集、交集、交集的补集、差集@Test public void test() { List&lt;String> list1 = Stream.of(\"a\", \"b\", \"c\", \"d\", \"e\").parallel().collect(Collectors.toList()); List&lt;String> list2 = Stream.of(\"a\", \"f\", \"C\", \"e\", \"g\",\"z\").parallel().collect(Collectors.toList()); // 并集 Collection union = CollectionUtils.union(list1, list2); log.info(\"union:{}\", union); // 交集 Collection intersection = CollectionUtils.intersection(list1, list2); log.info(\"intersection:{}\", intersection); // 交集的补集（析取） Collection disjunction = CollectionUtils.disjunction(list1, list2); log.info(\"disjunction:{}\", disjunction); // 差集（扣除）list1扣除list2 Collection subtract = CollectionUtils.subtract(list1, list2); log.info(\"subtract:{}\", subtract); } // 结果 union:[a, b, c, C, d, e, f, g, z] intersection:[a, e] disjunction:[b, c, C, d, f, g, z] subtract:[b, c, d] 判断相等@Test public void testEqual() { List&lt;String> list1 = Stream.of(\"a\", \"b\", \"c\", \"d\", \"e\").parallel().collect(Collectors.toList()); List&lt;String> list2 = Stream.of(\"a\", \"f\", \"C\", \"e\", \"g\", \"z\").parallel().collect(Collectors.toList()); // 比较值 false log.info(\"isEqualCollection:{}\", CollectionUtils.isEqualCollection(list1, list2)); List&lt;Integer> list3 = Stream.of(1, 2, 3, 4).parallel().collect(Collectors.toList()); List&lt;Integer> list4 = Stream.of(1, 2, 3, 4).parallel().collect(Collectors.toList()); // 比较值 true log.info(\"isEqualCollection:{}\", CollectionUtils.isEqualCollection(list3, list4)); class Person { } @Data @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = true) class Boy extends Person { String name; } List&lt;Person> boy1 = new ArrayList&lt;>(); boy1.add(new Boy(\"阿牛\")); List&lt;Person> boy2 = new ArrayList&lt;>(); boy2.add(new Boy(\"阿牛\")); // 比较集合中不同对象 false log.info(\"isEqualCollection:{}\", CollectionUtils.isEqualCollection(boy1, boy2)); Boy boy = new Boy(); List&lt;Boy> boy3 = new ArrayList&lt;>(); boy3.add(boy); List&lt;Boy> boy4 = new ArrayList&lt;>(); boy4.add(boy); // 比较集合中相同对象 true log.info(\"isEqualCollection:{}\", CollectionUtils.isEqualCollection(boy3, boy4)); } 不可变集合@Test public void testUnmodifiable() { Collection&lt;String> list = new ArrayList&lt;>(); // 抓换为不可变集合，添加数据会报错 Collection&lt;String> collection = CollectionUtils.unmodifiableCollection(list); collection.add(\"a\"); collection.add(\"b\"); collection.add(\"c\"); log.info(\"collection:{}\", collection); } // Collections.unmodifiableCollection可以得到一个集合的镜像，它的返回结果是不可直接被改变，否则会提示错误 java.lang.UnsupportedOperationException at org.apache.commons.collections.collection.UnmodifiableCollection.add(UnmodifiableCollection.java:75)","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"Comparable和Comparator的区别","slug":"chinese-sort","date":"2019-02-17T03:27:48.000Z","updated":"2024-07-01T12:30:37.369Z","comments":true,"path":"2019/02/17/chinese-sort/","link":"","permalink":"http://iogogogo.github.io/2019/02/17/chinese-sort/","excerpt":"","text":"ComparableComparable可以认为是一个内比较器，实现了Comparable接口的类有一个特点，就是这些类是可以和自己比较的，至于具体和另一个实现了Comparable接口的类如何比较，则依赖compareTo方法的实现，compareTo方法也被称为自然比较方法。如果开发者add进入一个Collection的对象想要Collections的sort方法帮你自动进行排序的话，那么这个对象必须实现Comparable接口。compareTo方法的返回值是int，有三种情况： 1、比较者大于被比较者（也就是compareTo方法里面的对象），那么返回正整数 2、比较者等于被比较者，那么返回0 3、比较者小于被比较者，那么返回负整数 public class Domain implements Comparable&lt;Domain> { private String str; public Domain(String str) { this.str = str; } public int compareTo(Domain domain) { if (this.str.compareTo(domain.str) > 0) return 1; else if (this.str.compareTo(domain.str) == 0) return 0; else return -1; } public String getStr() { return str; } } public static void main(String[] args) { Domain d1 = new Domain(\"c\"); Domain d2 = new Domain(\"c\"); Domain d3 = new Domain(\"b\"); Domain d4 = new Domain(\"d\"); System.out.println(d1.compareTo(d2)); System.out.println(d1.compareTo(d3)); System.out.println(d1.compareTo(d4)); } // 输出结果 0 1 -1 ComparatorComparator可以认为是是一个外比较器，个人认为有两种情况可以使用实现Comparator接口的方式： 1、一个对象不支持自己和自己比较（没有实现Comparable接口），但是又想对两个对象进行比较 2、一个对象实现了Comparable接口，但是开发者认为compareTo方法中的比较方式并不是自己想要的那种比较方式 Comparator接口里面有一个compare方法，方法有两个参数T o1和T o2，是泛型的表示方式，分别表示待比较的两个对象，方法返回值和Comparable接口一样是int，有三种情况： 1、o1大于o2，返回正整数 2、o1等于o2，返回0 3、o1小于o3，返回负整数 public class DomainComparator implements Comparator&lt;Domain> { public int compare(Domain domain1, Domain domain2) { if (domain1.getStr().compareTo(domain2.getStr()) > 0) return 1; else if (domain1.getStr().compareTo(domain2.getStr()) == 0) return 0; else return -1; } } public static void main(String[] args) { Domain d1 = new Domain(\"c\"); Domain d2 = new Domain(\"c\"); Domain d3 = new Domain(\"b\"); Domain d4 = new Domain(\"d\"); DomainComparator dc = new DomainComparator(); System.out.println(dc.compare(d1, d2)); System.out.println(dc.compare(d1, d3)); System.out.println(dc.compare(d1, d4)); } // 输出结果 0 1 -1 因为泛型指定死了，所以实现Comparator接口的实现类只能是两个相同的对象（不能一个Domain、一个String）进行比较了，因此实现Comparator接口的实现类一般都会以”待比较的实体类+Comparator”来命名 总结1、如果实现类没有实现Comparable接口，又想对两个类进行比较（或者实现类实现了Comparable接口，但是对compareTo方法内的比较算法不满意），那么可以实现Comparator接口，自定义一个比较器，写比较算法 2、实现Comparable接口的方式比实现Comparator接口的耦合性 要强一些，如果要修改比较算法，要修改Comparable接口的实现类，而实现Comparator的类是在外部进行比较的，不需要对实现类有任何修 改。从这个角度说，其实有些不太好，尤其在我们将实现类的.class文件打成一个.jar文件提供给开发者使用的时候。实际上实现Comparator 接口的方式后面会写到就是一种典型的策略模式。 中文实现排序treeMap 方式 @org.junit.Test public void test() { CollatorComparator comparator = new CollatorComparator(); TreeMap&lt;String, Object> sortMap = new TreeMap&lt;>(comparator); sortMap.put(\"广州\", \"500\"); sortMap.put(\"安徽\", \"100000000000\"); sortMap.put(\"中山\", \"9000\"); sortMap.put(\"潮州\", \"8000\"); //注意：每次对TreeMap进行put()时，TreeMap都会自动调用它的compare(key,Entry.key) //按照key进行排序 System.out.println(sortMap); } class CollatorComparator implements Comparator&lt;Object> { Collator collator = Collator.getInstance(); @Override public int compare(Object element1, Object element2) { CollationKey key1 = collator.getCollationKey(element1.toString()); CollationKey key2 = collator.getCollationKey(element2.toString()); return key1.compareTo(key2); } } Comparator 方式@org.junit.Test public void test() { Comparator&lt;Object> com = Collator.getInstance(java.util.Locale.CHINA); String[] newArray = {\"中山\", \"汕头\", \"广州\", \"$\", \"安庆\", \"1\", \"阳江\", \"z\", \"南京\", \"武汉\", \"北京\", \"安阳\", \"北方\"}; List&lt;String> list = Arrays.asList(newArray); list.sort(com); for (String i : list) { System.out.print(i + \" \"); } }","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"Java8 新特性-Optional类","slug":"java8-optional","date":"2019-02-13T03:15:36.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2019/02/13/java8-optional/","link":"","permalink":"http://iogogogo.github.io/2019/02/13/java8-optional/","excerpt":"","text":"在Stream流式数据处理的文章中提到了Optional类，这是Java 8新增的一个类，用以解决程序中常见的NullPointerException异常问题。本篇文章将详细介绍Optional类，以及如何用它消除代码中的null检查。 避免使用null检查作为Java开发人员，几乎所有人都遇到过NullPointerException异常，大多数人遇到NullPointerException异常时都会在异常出现的地方加上if代码块来判断值不为空，比如下面的代码： public void bindUserToRole(User user) { if (user != null) { String roleId = user.getRoleId(); if (roleId != null) { Role role = roleDao.findOne(roleId); if (role != null) { role.setUserId(user.getUserId()); roleDao.save(role); } } } } 这是比较普遍的做法，为了避免出现NullPointerException异常，手动对可能为null值进行了处理，不过代码看起来非常糟糕，业务逻辑被淹没在if逻辑判断中，也许下面的代码看起来可读性稍好一些： public String bindUserToRole(User user) { if (user == null) { return; } String roleId = user.getRoleId(); if (roleId == null) { return; } Role = roleDao.findOne(roleId); if (role != null) { role.setUserId(user.getUserId()); roleDao.save(role); } } 上面的代码避免了深层的if语句嵌套，但本质上是一样的，方法内有三个不同的返回点，出错后调试也不容易，因为你不知道是那个值导致了NullPointerException异常。 基于上面的原因，Java 8中引入了一个新的类Optional，用以避免使用null值引发的种种问题。 Optional类java.util.Optional&lt;T&gt;类是一个封装了Optional值的容器对象，Optional值可以为null，如果值存在，调用isPresent()方法返回true，调用get()方法可以获取值。 创建Optional对象Optional类提供类三个方法用于实例化一个Optional对象，它们分别为empty()、of()、ofNullable()，这三个方法都是静态方法，可以直接调用。 empty()方法用于创建一个没有值的Optional对象： Optional&lt;String> emptyOpt = Optional.empty(); empty()方法创建的对象没有值，如果对emptyOpt变量调用isPresent()方法会返回false，调用get()方法抛出NullPointerException异常。 of()方法使用一个非空的值创建Optional对象： String str = \"Hello World\"; Optional&lt;String> notNullOpt = Optional.of(str); ofNullable()方法接收一个可以为null的值： Optional&lt;String> nullableOpt = Optional.ofNullable(str); 如果str的值为null，得到的nullableOpt是一个没有值的Optional对象。 提取Optional对象中的值如果我们要获取User对象中的roleId属性值，常见的方式是直接获取： String roleId = null; if (user != null) { roleId = user.getRoleId(); } 使用Optional中提供的map()方法可以以更简单的方式实现： Optional&lt;User> userOpt = Optional.ofNullable(user); Optional&lt;String> roleIdOpt = userOpt.map(User::getRoleId); 使用orElse()方法获取值Optional类还包含其他方法用于获取值，这些方法分别为： orElse()：如果有值就返回，否则返回一个给定的值作为默认值； orElseGet()：与orElse()方法作用类似，区别在于生成默认值的方式不同。该方法接受一个Supplier&lt;? extends T&gt;函数式接口参数，用于生成默认值； orElseThrow()：与前面介绍的get()方法类似，当值为null时调用这两个方法都会抛出NullPointerException异常，区别在于该方法可以指定抛出的异常类型。 下面来看看这三个方法的具体用法： String str = \"Hello World\"; Optional&lt;String> strOpt = Optional.of(str); String orElseResult = strOpt.orElse(\"Hello Shanghai\"); String orElseGet = strOpt.orElseGet(() -> \"Hello Shanghai\"); String orElseThrow = strOpt.orElseThrow( () -> new IllegalArgumentException(\"Argument 'str' cannot be null or blank.\")); 此外，Optional类还提供了一个ifPresent()方法，该方法接收一个Consumer&lt;? super T&gt;函数式接口，一般用于将信息打印到控制台： Optional&lt;String> strOpt = Optional.of(\"Hello World\"); strOpt.ifPresent(System.out::println); 使用filter()方法过滤filter()方法可用于判断Optional对象是否满足给定条件，一般用于条件过滤： Optional&lt;String> optional = Optional.of(\"lw900925@163.com\"); optional = optional.filter(str -> str.contains(\"164\")); 在上面的代码中，如果filter()方法中的Lambda表达式成立，filter()方法会返回当前Optional对象值，否则，返回一个值为空的Optional对象。 如何正确使用Optional通过上面的例子可以看出，Optional类可以优雅的避免NullPointerException带来的各种问题，不过，你是否真正掌握了Optional的用法？假设你试图使用Optional来避免可能出现的NullPointerException异常，编写了如下代码： Optional&lt;User> userOpt = Optional.ofNullable(user); if (userOpt.isPresent()) { User user = userOpt.get(); // do something... } else { // do something... } 坦白说，上面的代码与我们之前的使用if语句判断空值没有任何区别，没有起到Optional的正真作用： if (user != null) { // do something... } else { // do something... } 当我们从之前版本切换到Java 8的时候，不应该还按照之前的思维方式处理null值，Java 8提倡函数式编程，新增的许多API都可以用函数式编程表示，Optional类也是其中之一。这里有几条关于Optional使用的建议： 尽量避免在程序中直接调用Optional对象的get()和isPresent()方法； 避免使用Optional类型声明实体类的属性； 第一条建议中直接调用get()方法是很危险的做法，如果Optional的值为空，那么毫无疑问会抛出NullPointerException异常，而为了调用get()方法而使用isPresent()方法作为空值检查，这种做法与传统的用if语句块做空值检查没有任何区别。 第二条建议避免使用Optional作为实体类的属性，它在设计的时候就没有考虑过用来作为类的属性，如果你查看Optional的源代码，你会发现它没有实现java.io.Serializable接口，这在某些情况下是很重要的（比如你的项目中使用了某些序列化框架），使用了Optional作为实体类的属性，意味着他们不能被序列化。 下面我们通过一些例子讲解Optional的正确用法： 正确创建Optional对象上面提到创建Optional对象有三个方法，empty()方法比较简单，没什么特别要说明的。主要是of()和ofNullable()方法。当你很确定一个对象不可能为null的时候，应该使用of()方法，否则，尽可能使用ofNullable()方法，比如： public static void method(Role role) { // 当Optional的值通过常量获得或者通过关键字new初始化，可以直接使用of()方法 Optional&lt;String> strOpt = Optional.of(\"Hello World\"); Optional&lt;User> userOpt = Optional.of(new User()); // 方法参数中role值不确定是否为null，使用ofNullable()方法创建 Optional&lt;Role> roleOpt = Optional.ofNullable(role); } orElse()方法的使用return str != null ? str : \"Hello World\" 上面的代码表示判断字符串str是否为空，不为空就返回，否则，返回一个常量。使用Optional类可以表示为： return strOpt.orElse(\"Hello World\") 简化if-elseUser user = ... if (user != null) { String userName = user.getUserName(); if (userName != null) { return userName.toUpperCase(); } else { return null; } } else { return null; } 上面的代码可以简化成： User user = ... Optional&lt;User> userOpt = Optional.ofNullable(user); return user.map(User::getUserName) .map(String::toUpperCase) .orElse(null); 总结一下，新的Optional类让我们可以以函数式编程的方式处理null值，抛弃了Java 8之前需要嵌套大量if-else代码块，使代码可读性有了很大的提高。","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Java8 新特性-lambda表达式","slug":"java8-lambda-expression","date":"2019-02-13T03:10:25.000Z","updated":"2024-07-01T12:30:37.373Z","comments":true,"path":"2019/02/13/java8-lambda-expression/","link":"","permalink":"http://iogogogo.github.io/2019/02/13/java8-lambda-expression/","excerpt":"","text":"2014年3月发布的Java 8，有可能是Java版本更新中变化最大的一次。新的Java 8为开发者带来了许多重量级的新特性，包括Lambda表达式，流式数据处理，新的Optional类，新的日期和时间API等。这些新特性给Java开发者带来了福音，特别是Lambda表达式的支持，使程序设计更加简化。本篇文章将讨论行为参数化，Lambda表达式，函数式接口等特性。 行为参数化在软件开发的过程中，开发人员可能会遇到频繁的需求变更，使他们不断地修改程序以应对这些变化的需求，导致项目进度缓慢甚至项目延期。行为参数化就是一种可以帮助你应对频繁需求变更的开发模式，简单的说，就是预先定义一个代码块而不去执行它，把它当做参数传递给另一个方法，这样，这个方法的行为就被这段代码块参数化了。 为了方便理解，我们通过一个例子来讲解行为参数化的使用。假设我们正在开发一个图书管理系统，需求是要对图书的作者进行过滤，筛选出指定作者的书籍。比较常见的做法就是编写一个方法，把作者当成方法的参数： public List&lt;Book> filterByAuthor(List&lt;Book> books, String author) { List&lt;Book> result = new ArrayList&lt;>(); for (Book book : books) { if (author.equals(book.getAuthor())) { result.add(book); } } return result; } 现在客户需要变更需求，添加过滤条件，按照出版社过滤，于是我们不得不再次编写一个方法： public List&lt;Book> filterByPublisher(List&lt;Book> books, String publisher) { List&lt;Book> result = new ArrayList&lt;>(); for (Book book : books) { if (publisher.equals(book.getPublisher())) { result.add(book); } } return result; } 两个方法除了名称之外，内部的实现逻辑几乎一模一样，唯一的区别就是if判断条件，前者判断的是作者，后者判断的是出版社。如果现在客户又要增加需求，需要按照图书的售价过滤，是不是需要再次将上面的方法复制一遍，将if判断条件改为售价？ No! 这种做法违背了DRY（Don’t Repeat Yourself，不要重复自己）原则，而且不利于后期维护，如果需要改变方法内部遍历方式来提高性能，意味着每个filterByXxx()方法都需要修改，工作量太大。 一种可行的办法是对过滤的条件做更高层的抽象，过滤的条件无非就是图书的某些属性（比如价格、出版社、出版日期、作者等），可以声明一个接口用于对过滤条件建模： public interface BookPredicate { public boolean test(Book book); } BookPredicate接口只有一个抽象方法test()，该方法接受一个Book类型参数，返回一个boolean值，可以用它来表示图书的不同过滤条件。 接下来我们对之前的过滤方法进行重构，将filterByXxx()方法的第二个参数换成上面定义的接口： public List&lt;Book> filter(List&lt;Book> books, BookPredicate bookPredicate) { List&lt;Book> result = new ArrayList&lt;>(); for (Book book : books) { if (bookPredicate.test(book)) { result.add(book); } } return result; } 将过滤的条件换成BookPredicate的实现类，这里采用了内部类： // 根据作者过滤 final String author = \"张三\"; List&lt;Book> result = filter(books, new BookPredicate() { @Override public boolean test(Book book) { return author.equals(book.getAuthor()); } }); // 根据图书价格过滤 final double price = 100.00D; List&lt;Book> result = filter(books, new BookPredicate() { @Override public boolean test(Book book) { return price > book.getPrice(); } }); 重构前后有什么区别？我们将方法中的if判断条件换成了BookPredicate接口定义的test()方法，用于判断是否满足过滤条件，将图书过滤的逻辑交给了BookPredicate接口的实现类，而不是在filter()方法内部实现过滤，而BookPredicate接口又是filter()方法的参数。以上的步骤，就是将行为参数化，也就是将图书过滤的行为（BookPredicate接口的实现类）当做filter()方法的参数。现在，可以删掉所有filterByXxx()的方法，只保留filter()方法，就算后期数据规模很庞大，需要改变集合的遍历方式来提高性能，只需要在filter()方法内部做出相应的修改，而不用去修改其他业务代码。 不过，BookPredicate接口只是针对图书的过滤，如果需要对其他对象集合排序（如：用户），又得重新申明一个接口。有一个办法就是可以用Java的泛型对它做进一步的抽象： public interface Predicate&lt;T> { public boolean test(T t); } 现在你可以把filter()方法用在任何对象的过滤中。 Lambda表达式虽然我们对filter()方法进行重构，并抽象了Predicate接口作为过滤的条件，但实际上还需要编写很多内部类来实现Predicate接口。使用内部类的方式实现Predicate接口有很多缺点：首先是代码显得臃肿不堪，可读性差；其次，如果某个局部变量被内部类使用，这个变量必须使用final关键字修饰。在Java 8中，使用Lambda表达式可以对内部类进一步简化： // 根据作者过滤 List&lt;Book> result = filter(books, book -> \"张三\".equals(book.getAuthor())); // 根据图书价格过滤 List&lt;Book> result = filter(books, book -> 100 > book.getPrice()); 使用Lambda仅仅用一行代码就对内部类进行了转化，而且代码变得更加清晰可读。其中book -&gt; &quot;张三&quot;.equals(book.getAuthor())和book -&gt; 100 &gt; book.getPrice()就是我们接下来要研究的Lambda表达式。 Lambda表达式是什么Lambda表达式（lambda expression）是一个匿名函数，由数学中的λ演算而得名。在Java 8中可以把Lambda表达式理解为匿名函数，它没有名称，但是有参数列表、函数主体、返回类型等。 Lambda表达式的语法如下： (parameters) -> { statements; } 为什么要使用Lambda表达式？前面你也看到了，在Java中使用内部类显得十分冗长，要编写很多样板代码，Lambda表达式正是为了简化这些步骤出现的，它使代码变得清晰易懂。 如何使用Lambda表达式Lambda表达式是为了简化内部类的，你可以把它当成是内部类的一种简写方式，只要是有内部类的代码块，都可以转化成Lambda表达式： // Comparator排序 List&lt;Integer> list = Arrays.asList(3, 1, 4, 5, 2); list.sort(new Comparator&lt;Integer>() { @Override public int compare(Integer o1, Integer o2) { return o1.compareTo(o2); } }); // 使用Lambda表达式简化 list.sort((o1, o2) -> o1.compareTo(o2)); // Runnable代码块 Thread thread = new Thread(new Runnable() { @Override public void run() { System.out.println(\"Hello Man!\"); } }); // 使用Lambda表达式简化 Thread thread = new Thread(() -> System.out.println(\"Hello Man!\")); 可以看出，只要是内部类的代码块，就可以使用Lambda表达式简化，并且简化后的代码清晰易懂。甚至，Comparator排序的Lambda表达式还可以进一步简化： list.sort(Integer::compareTo); 这种写法被称为 方法引用，方法引用是Lambda表达式的简便写法。如果你的Lambda表达式只是调用这个方法，最好使用名称调用，而不是描述如何调用，这样可以提高代码的可读性。 方法引用使用::分隔符，分隔符的前半部分表示引用类型，后面半部分表示引用的方法名称。例如：Integer::compareTo表示引用类型为Integer，引用名称为compareTo的方法。 类似使用方法引用的例子还有打印集合中的元素到控制台中： list.forEach(System.out::println); 函数式接口如果你的好奇心使你翻看Runnable接口源代码，你会发现该接口被一个@FunctionalInterface的注解修饰，这是Java 8中添加的新注解，用于表示 函数式接口。 函数式接口又是什么鬼？在Java 8中，把那些仅有一个抽象方法的接口称为函数式接口。如果一个接口被@FunctionalInterface注解标注，表示这个接口被设计成函数式接口，只能有一个抽象方法，如果你添加多个抽象方法，编译时会提示“Multiple non-overriding abstract methods found in interface XXX”之类的错误。 函数式方法又能做什么？Java8允许你以Lambda表达式的方式为函数式接口提供实现，通俗的说，你可以将整个Lambda表达式作为接口的实现类。 除了Runnable之外，Java 8中内置了许多函数式接口供开发者使用，这些接口位于java.util.function包中，我们之前使用的Predicate接口，已经被包含在这个包内，他们分别为Predicate、Consumer和Function，由于我们已经在之前的图书过滤的例子中介绍了Predicate的用法，所以接下来主要介绍Consumer和Function的用法。 Consumerjava.util.function.Consumer&lt;T&gt;定义了一个名叫accept()的抽象方法，它接受泛型T的对象，没有返回（void）。如果你需要访问类型T的对象，并对其执行某些操作，就可以使用这个接口。比如，你可以用它来创建一个forEach()方法，接受一个集合，并对集合中每个元素执行操作： @FunctionalInterface public interface Consumer&lt;T> { void accept(T t); } public static &lt;T> void forEach(List&lt;T> list, Consumer&lt;T> consumer) { for(T t: list){ consumer.accept(t); } } public static void main(String[] args) { List&lt;String> list = Arrays.asList(\"A\", \"B\", \"C\", \"D\"); forEach(list, str -> System.out.println(str)); // 也可以写成 forEach(list, System.out::println); } Functionjava.util.function.Function&lt;T, R&gt;接口定义了一个叫作apply()的方法，它接受一个泛型T的对象，并返回一个泛型R的对象。如果你需要定义一个Lambda，将输入对象的信息映射到输出，就可以使用这个接口。比如，我们需要计算一个图书集合中每本书的作者名称有几个汉字（假设这些书的作者都是中国人）： @FunctionalInterface public interface Function&lt;T, R> { R apply(T t); } public static &lt;T, R> List&lt;R> map(List&lt;T> list, Function&lt;T, R> f) { List&lt;R> result = new ArrayList&lt;>(); for(T s: list){ result.add(f.apply(s)); } return result; } public static void main(String[] args) { List&lt;Book> books = Arrays.asList( new Book(\"张三\", 99.00D), new Book(\"李四\", 59.00D), new Book(\"王老五\", 59.00D) ); List&lt;Integer> results = map(books, book -> book.getAuthor().length()); } 现在，应该对Lambda表达式有一个初步的了解了，并且，你可以使用Lambda表达式来重构你的代码，提高代码可读性；使用行为参数化来设计你的程序，让程序更灵活。","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Java8 新特性-流处理","slug":"java8-stream-api","date":"2019-02-13T02:32:16.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2019/02/13/java8-stream-api/","link":"","permalink":"http://iogogogo.github.io/2019/02/13/java8-stream-api/","excerpt":"","text":"Java 8的另一个新特性——Stream API。新增的Stream API与InputStream和OutputStream是完全不同的概念，Stream API是对Java中集合操作的增强，可以利用它进行各种过滤、排序、分组、聚合等操作。Stream API配合Lambda表达式可以加大的提高代码可读性和编码效率，Stream API也支持并行操作，我们不用再花费很多精力来编写容易出错的多线程代码了，Stream API已经替我们做好了，并且充分利用多核CPU的优势。借助Stream API和Lambda，开发人员可以很容易的编写出高性能的并发处理程序。 Stream API简介Stream API是Java 8中加入的一套新的API，主要用于处理集合操作，不过它的处理方式与传统的方式不同，称为“数据流处理”。流（Stream）类似于关系数据库的查询操作，是一种声明式操作。比如要从数据库中获取所有年龄大于20岁的用户的名称，并按照用户的创建时间进行排序，用一条SQL语句就可以搞定，不过使用Java程序实现就会显得有些繁琐，这时候可以使用流： List&lt;String> userNames = users.stream() .filter(user -> user.getAge() > 20) .sorted(comparing(User::getCreationDate)) .map(User::getUserName) .collect(toList()); 可以把流跟集合做一个比较。在Java中，集合是一种数据结构，或者说是一种容器，用于存放数据，流不是容器，它不关心数据的存放，只关注如何处理。可以把流当做是Java中的Iterator，不过它比Iterator强大多了。 流与集合另一个区别在于他们的遍历方式，遍历集合通常使用for-each方式，这种方式称为外部迭代，而流使用内部迭代方式，也就是说它帮你把迭代的工作做了，你只需要给出一个函数来告诉它接下来要干什么： // 外部迭代 List&lt;String> list = Arrays.asList(\"A\", \"B\", \"C\", \"D\"); for (String str : list) { System.out.println(str); } // 内部迭代 list.stream().forEach(System.out::println); 在这个大数据的时代，数据变得越来越多样化，很多时候我们会面对海量数据，并对其做一些复杂的操作（比如统计，分组），依照传统的遍历方式（for-each），每次只能处理集合中的一个元素，并且是按顺序处理，这种方法是极其低效的。你也许会想到并行处理，但是编写多线程代码并非易事，很容易出错并且维护困难。不过在Java 8之后，你可以使用Stream API来解决这一问题。 Stream API将迭代操作封装到了内部，它会自动的选择最优的迭代方式，并且使用并行方式处理时，将集合分成多段，每一段分别使用不同的线程处理，最后将处理结果合并输出。 需要注意的是，流只能遍历一次，遍历结束后，这个流就被关闭掉了。如果要重新遍历，可以从数据源（集合）中重新获取一个流。如果你对一个流遍历两次，就会抛出java.lang.IllegalStateException异常： List&lt;String> list = Arrays.asList(\"A\", \"B\", \"C\", \"D\"); Stream&lt;String> stream = list.stream(); stream.forEach(System.out::println); stream.forEach(System.out::println); // 这里会抛出java.lang.IllegalStateException异常，因为流已经被关闭 流通常由三部分构成： 数据源：数据源一般用于流的获取，比如本文开头那个过滤用户的例子中users.stream()方法。 中间处理：中间处理包括对流中元素的一系列处理，如：过滤（filter()），映射（map()），排序（sorted()）。 终端处理：终端处理会生成结果，结果可以是任何不是流值，如List&lt;String&gt;；也可以不返回结果，如stream.forEach(System.out::println)就是将结果打印到控制台中，并没有返回。 创建流创建流的方式有很多，具体可以划分为以下几种： 由值创建流使用静态方法Stream.of()创建流，该方法接收一个变长参数： Stream&lt;Stream> stream = Stream.of(\"A\", \"B\", \"C\", \"D\"); 也可以使用静态方法Stream.empty()创建一个空的流： Stream&lt;Stream> stream = Stream.empty(); 由数组创建流使用静态方法Arrays.stream()从数组创建一个流，该方法接收一个数组参数： String[] strs = {\"A\", \"B\", \"C\", \"D\"}; Stream&lt;Stream> stream = Arrays.stream(strs); 通过文件生成流使用java.nio.file.Files类中的很多静态方法都可以获取流，比如Files.lines()方法，该方法接收一个java.nio.file.Path对象，返回一个由文件行构成的字符串流： Stream&lt;String> stream = Files.lines(Paths.get(\"text.txt\"), Charset.defaultCharset()); 通过函数创建流java.util.stream.Stream中有两个静态方法用于从函数生成流，他们分别是Stream.generate()和Stream.iterate()： // iteartor Stream.iterate(0, n -> n + 2).limit(51).forEach(System.out::println); // generate Stream.generate(() -> \"Hello Man!\").limit(10).forEach(System.out::println); 第一个方法会打印100以内的所有偶数，第二个方法打印10个Hello Man!。值得注意的是，这两个方法生成的流都是无限流，没有固定大小，可以无穷的计算下去，在上面的代码中我们使用了limit()来避免打印无穷个值。 一般来说，iterate()用于生成一系列值，比如生成以当前时间开始之后的10天的日期： Stream.iterate(LocalDate.now(), date -> date.plusDays(1)).limit(10).forEach(System.out::println); generate()方法用于生成一些随机数，比如生成10个UUID： Stream.generate(() -> UUID.randomUUID().toString()).limit(10).forEach(System.out::println); 使用流Stream接口中包含许多对流操作的方法，这些方法分别为： filter()：对流的元素过滤 map()：将流的元素映射成另一个类型 distinct()：去除流中重复的元素 sorted()：对流的元素排序 forEach()：对流中的每个元素执行某个操作 peek()：与forEach()方法效果类似，不同的是，该方法会返回一个新的流，而forEach()无返回 limit()：截取流中前面几个元素 skip()：跳过流中前面几个元素 toArray()：将流转换为数组 reduce()：对流中的元素归约操作，将每个元素合起来形成一个新的值 collect()：对流的汇总操作，比如输出成List集合 anyMatch()：匹配流中的元素，类似的操作还有allMatch()和noneMatch()方法 findFirst()：查找第一个元素，类似的还有findAny()方法 max()：求最大值 min()：求最小值 count()：求总数 下面逐一介绍这些方法的用法。 过滤和排序Stream.of(1, 8, 5, 2, 1, 0, 9, 2, 0, 4, 8) .filter(n -> n > 2) // 对元素过滤，保留大于2的元素 .distinct() // 去重，类似于SQL语句中的DISTINCT .skip(1) // 跳过前面1个元素 .limit(2) // 返回开头2个元素，类似于SQL语句中的SELECT TOP .sorted() // 对结果排序 .forEach(System.out::println); 查找和匹配Stream中提供的查找方法有anyMatch()、allMatch()、noneMatch()、findFirst()、findAny()，这些方法被用来查找或匹配某些元素是否符合给定的条件： // 检查流中的任意元素是否包含字符串\"Java\" boolean hasMatch = Stream.of(\"Java\", \"C#\", \"PHP\", \"C++\", \"Python\") .anyMatch(s -> s.equals(\"Java\")); // 检查流中的所有元素是否都包含字符串\"#\" boolean hasAllMatch = Stream.of(\"Java\", \"C#\", \"PHP\", \"C++\", \"Python\") .allMatch(s -> s.contains(\"#\")); // 检查流中的任意元素是否没有以\"C\"开头的字符串 boolean hasNoneMatch = Stream.of(\"Java\", \"C#\", \"PHP\", \"C++\", \"Python\") .noneMatch(s -> s.startsWith(\"C\")); // 查找元素 Optional&lt;String> element = Stream.of(\"Java\", \"C#\", \"PHP\", \"C++\", \"Python\") .filter(s -> s.contains(\"C\")) // .findFirst() // 查找第一个元素 .findAny(); // 查找任意元素 注意最后一行代码的返回类型，是一个Optional&lt;T&gt;类（java.util.Optional），它一个容器类，代表一个值存在或不存在。上面的代码中，findAny()可能什么元素都没找到。Java 8的库设计人员引入了Optional&lt;T&gt;，这样就不用返回众所周知容易出问题的null了。有关Optional&lt;T&gt;类的详细用法，将在下一篇文章中介绍。 实际上测试结果发现，findFirst()和findAny()返回的都是第一个元素，那么两者之间到底有什么区别？通过查看javadoc描述，大致意思是findAny()是为了提高并行操作时的性能，如果没有特别需要，还是建议使用findAny()方法。 归约归约操作就是将流中的元素进行合并，形成一个新的值，常见的归约操作包括求和，求最大值或最小值。归约操作一般使用reduce()方法，与map()方法搭配使用，可以处理一些很复杂的归约操作。 // 获取流 List&lt;Book> books = Arrays.asList( new Book(\"Java编程思想\", \"Bruce Eckel\", \"机械工业出版社\", 108.00D), new Book(\"Java 8实战\", \"Mario Fusco\", \"人民邮电出版社\", 79.00D), new Book(\"MongoDB权威指南（第2版）\", \"Kristina Chodorow\", \"人民邮电出版社\", 69.00D) ); // 计算所有图书的总价 Optional&lt;Double> totalPrice = books.stream() .map(Book::getPrice) .reduce((n, m) -> n + m); // 价格最高的图书 Optional&lt;Book> expensive = books.stream().max(Comparator.comparing(Book::getPrice)); // 价格最低的图书 Optional&lt;Book> cheapest = books.stream().min(Comparator.comparing(Book::getPrice)); // 计算总数 long count = books.stream().count() 在计算图书总价的时候首先使用map()方法得到所有图书价格的流，然后再使用reduce()方法进行归约计算。与map()方法类似的还有一个flatMap()，flatMap()方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个新的流。看看下面的代码： List&lt;String[]> result = Stream.of(\"Hello Man\") .map(s -> s.split(\"\")) .collect(Collectors.toList()); 上面代码返回的结果是一个List&lt;String[]&gt;类型，也就是[[&quot;H&quot;, &quot;e&quot;, &quot;l&quot;, &quot;l&quot;, &quot;o&quot;], [&quot;M&quot;, &quot;a&quot;, &quot;n&quot;]]这种结构，而我们想要的到[&quot;H&quot;, &quot;e&quot;, &quot;l&quot;, &quot;l&quot;, &quot;o&quot;, &quot;M&quot;, &quot;a&quot;, &quot;n&quot;]这种结构，这时候就需要使用flatMap()方法了： List&lt;String> result = Stream.of(\"Hello Man\") .map(s -> s.split(\"\")) .flatMap(Arrays::stream) .collect(Collectors.toList()); 使用flatMap()方法的效果是，各个数组并不是分别映射成一个流，而是映射成流的内容。所有使用map(Arrays::stream)时生成的单个流都被合并起来，也就是对流扁平化操作。 数据收集前面两部分内容分别为流式数据处理的前两个步骤：从数据源创建流、使用流进行中间处理。下面我们介绍流式数据处理的最后一个步骤——数据收集。 数据收集是流式数据处理的终端处理，与中间处理不同的是，终端处理会消耗流，也就是说，终端处理之后，这个流就会被关闭，如果再进行中间处理，就会抛出异常。数据收集主要使用collect方法，该方法也属于归约操作，像reduce()方法那样可以接收各种做法作为参数，将流中的元素累积成一个汇总结果，具体的做法是通过定义新的Collector接口来定义的。 在前面部分的例子中使用收集器（Collector）是由java.util.stream.Collectors工具类中的toList()方法提供，Collectors类提供了许多常用的方法用于处理数据收集，常见的有归约、汇总、分组等。 归约和汇总我们使用前面归约操作中计算图书总价，最大值，最小值，输入总数那个例子来看看收集器如何进行上述归约操作： // 求和 long count = books.stream().collect(counting()); // 价格最高的图书 Optional&lt;Book> expensive = books.stream().collect(maxBy(comparing(Book::getPrice))); // 价格最低的图书 Optional&lt;Book> cheapest = books.stream().collect(minBy(comparing(Book::getPrice))); 上面的代码假设你已经使用静态导入了Collectors和Comparator两个类，这样你就不用再去写Collectors.counting()和Comparator.comparing()这样的代码了： import static java.util.stream.Collectors.*; import static java.util.Comparator.*; Collectors工具类为我们提供了用于汇总的方法，包括summarizingInt()，summarizingLong()和summarizingDouble()，由于图书的价格为Double类型，所以我们使用summarizingDouble()方法进行汇总。该方法会返回一个DoubleSummaryStatistics对象，包含一系列归约操作的方法，如：汇总、计算平均数、最大值、最小值、计算总数： DoubleSummaryStatistics dss = books.stream().collect(summarizingDouble(Book::getPrice)); double sum = dss.getSum(); // 汇总 double average = dss.getAverage(); // 求平均数 long count = dss.getCount(); // 计算总数 double max = dss.getMax(); // 最大值 double min = dss.getMin(); // 最小值 Collectors类还包含一个joining()方法，该方法用于连接字符串： String str = Stream.of(\"A\", \"B\", \"C\", \"D\").collect(joining(\",\")); 上面的代码用于将流中的字符串通过逗号连接成一个新的字符串。 分组和关系数据库一样，流也提供了类似于数据库中GROUP BY分组的特性，由Collectors.groupingBy()方法提供： Map&lt;String, List&lt;Book>> booksGroup = books.stream().collect(groupingBy(Book::getPublisher)); 上面的代码按照出版社对图书进行分组，分组的结果是一个Map对象，Map的key值是出版社的名称，value值是每个出版社分组对应的集合。分组方法groupingBy()接收一个Function接口作为参数，上面的例子中我们使用了方法引用传递了出版社作为分组的依据，但实际情况可能比这复杂，比如将价格在0-50之间的书籍分成一组，50-100之间的分成一组，超过100的分成一组，这时候，我们可以直接使用Lambda表达式来表示这个分组逻辑： Map&lt;String, List&lt;Book>> booksGroup = books .stream() .collect(groupingBy(book -> { if (book.getPrice() > 0 &amp;&amp; book.getPrice() &lt;= 50) { return \"A\"; } else if (book.getPrice() > 50 &amp;&amp; book.getPrice() &lt;=100) { return \"B\"; } else { return \"C\"; } })); groupingBy()方法还支持多级分组，他有一个重载方法，除了接收一个Function类型的参数外，还接收一个Collector类型的参数： Map&lt;String, Map&lt;String, List&lt;Book>>> booksGroup = books.stream().collect( groupingBy(Book::getPublisher, groupingBy(book -> { if (book.getPrice() > 0 &amp;&amp; book.getPrice() &lt;= 50) { return \"A\"; } else if (book.getPrice() > 50 &amp;&amp; book.getPrice() &lt;=100) { return \"B\"; } else { return \"C\"; } })) ); 上面的代码将之前两个分组合并成一个，实现了多级分组，首先按照出版社进行分组，然后按照价格进行分组，返回类型是一个Map&lt;String, Map&lt;String, List&lt;Book&gt;&gt;&gt;。groupingBy()的第二个参数可以是任意类型，只要是Collector接口的实例就可以，比如先分组，再统计数量： Map&lt;String, Long> countGroup = books.stream() .collect(groupingBy(Book::getPublisher, counting())); 还可以在进行分组后获取每组中价格最高的图书： Map&lt;String, Book> expensiveGroup = books.stream() .collect(groupingBy(Book::getPublisher, collectingAndThen( maxBy(comparingDouble(Book::getPrice)), Optional::get ))); 并行数据处理在Java 7之前，处理并行数据集合非常麻烦，首先需要将一个庞大数据集合分成几个子集合；然后需要为每一个子集合编写多线程处理程序，还需要对他们做线程同步来避免访问共享变量导致处理结果不准确；最后，等待所有线程处理完毕后将处理结果合并。在Java 7之后新添加了一个fork/join的框架，让这一切变得更加简单。 并行流并行流使用集合的parallelStream()方法可以获取一个并行流。Java内部会将流的内容分割成若干个子部分，然后将它们交给多个线程并行处理，这样就将工作的负担交给多核CPU的其他内核处理。 我们通过一个简单粗暴的例子演示并行流的处理性能。假设有一个方法，接受一个数字n作为参数，返回从1到n的所有自然数之和： public static long sequentialSum(long n) { return Stream.iterate(1L, i -> i + 1) .limit(n) .reduce(0L, Long::sum); } 上面的方法也可以通过传统的for循环方式实现： public static long iterativeSum(long n) { long result = 0; for (long i = 1L; i &lt;= n; i++) { result += i; } return result; } 编写测试代码： public static void main(String[] args) { long number = 10000000L; System.out.println(\"Sequential Sum: \" + sumPerformanceTest(StreamTest::sequentialSum, number) + \" 毫秒\"); System.out.println(\"Iterative Sum: \" + sumPerformanceTest(StreamTest::iterativeSum, number) + \" 毫秒\"); } public static long sumPerformanceTest(Function&lt;Long, Long> function, long number) { long maxValue = Long.MAX_VALUE; for (int i=0; i&lt;10; i++) { long start = System.nanoTime(); long sum = function.apply(n); long end = System.nanoTime(); System.out.println(\"Result: \" + sum); long time = ( end - start ) / 1000000; if (time &lt; maxValue) { maxValue = time; } } return maxValue; } 为了方便测试，我们编写一个sumPerformanceTest()方法，参数number表示给定的一个数，用于计算从1到这个数的所有自然数之和。该方法内部执行10次运算，返回时间最短的一次运算结果。 运行上面的代码，可以在控制台看到如下结果： Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Sequential Sum: 159 毫秒 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Iterative Sum: 5 毫秒 可以看出，采用传统的for循环更快，因为它不用做任何自动拆箱/装箱操作，操作的都是基本类型。这个测试结果并不客观，提升的性能取决于机器的配置，以上是我在公司的台式机（机器配置为Intel(R) Core i7-6700 CPU 3.40HZ; 8GB RAM）上运行的结果。 现在我们使用并行流测试一下： public static long parallelSum(long n) { return Stream.iterate(1L, i -> i + 1) .limit(n) .parallel() .reduce(0L, Long::sum); } public static void main(String[] args) { System.out.println(\"Parallel Sum: \" + sumPerformanceTest(StreamTest::parallelSum, number) + \" 毫秒\"); } 并行流执行结果为： Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Parallel Sum: 570 毫秒 并行的执行效率比顺序执行还要慢，这个结果让人大跌眼镜。主要有两个原因： iterate()方法生成的对象是基本类型的包装类（也就是java.lang.Long类型），必须进行拆箱操作才能运算。 iterate()方法不适合用并行流处理。 第一个原因容易理解，自动拆箱操作确实需要花费一定的时间，这从前一个例子可以看出来。第二个原因中iterate()方法不适合用并行流处理，主要原因是iterate()方法内部机制的问题。iterate()方法每次执行都需要依赖前一次的结果，比如本次执行的输入值为10，这个输入值必须是前一次运算结果的输出，因此iterate()方法很难使用并行流分割成不同小块处理。实际上，上面的并行流程序还增加了顺序处理的额外开销，因为需要把每次操作执行的结果分别分配到不同的线程中。 一个有效的处理方式是使用LongStream.rangeClosed()方法，该方法弥补了上述例子的两个缺点，它生成的是基本类型而非包装类，不用拆箱操作就可以运算，并且，它生成的是由范围的数字，很容易拆分。如：生成1-20范围的数字可以拆分成1-10, 11-20。 public static long rangedSum(long n) { return LongStream.rangeClosed(1, n) .reduce(0L, Long::sum); } public static void main(String[] args) { System.out.println(\"Ranged Sum: \" + sumPerformanceTest(StreamTest::rangedSum, number) + \" 毫秒\"); } 执行结果为： Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Ranged Sum: 8 毫秒 这个结果比起sequentialSum()方法执行的结果还要快，所以选择合适的数据结构有时候比并行化处理更重要。我们再将rangeClosed()方法生成的流转化为并行流： public static long parallelRangedSum(long n) { return LongStream.rangeClosed(1, n) .parallel() .reduce(0L, Long::sum); } public static void main(String[] args) { System.out.println(\"Parallel Ranged Sum: \" + sumPerformanceTest(StreamTest::parallelRangedSum, number) + \" 毫秒\"); } 执行结果为： Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Result: 200000010000000 Parallel Ranged Sum: 2 毫秒 我们终于得到了想要的结果，所以并行操作需要选择合适的数据结构，建议多做测试，找到合适的并行方式再执行，否则很容易跳到坑里。 获取一个合适的IP地址/** * 合适的ip地址前缀 */ private static final List&lt;String> PREFIX_IP = Stream.of(\"192.168\", \"172.16\").collect(toList()); public static String getPreferIp() { try { Enumeration&lt;NetworkInterface> enumeration = NetworkInterface.getNetworkInterfaces(); List&lt;List&lt;String>> lists = Collections.list(enumeration) .stream() .map(x -> Collections.list(x.getInetAddresses()) .stream() .filter(InetAddress::isSiteLocalAddress) .map(InetAddress::getHostAddress) .filter(Objects::nonNull) .collect(Collectors.toList()) ).filter(x -> !x.isEmpty()) .collect(toList()); AtomicReference&lt;String> prefer = new AtomicReference&lt;>(); PREFIX_IP.forEach(x -> lists.forEach(i -> i.forEach(a -> { if (a.startsWith(x)) { prefer.set(a); } }))); String ip = prefer.get(); log.info(\"获取可用ip为： {}\", ip); return ip; } catch ( SocketException e) { e.printStackTrace(); return null; } }","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Java8 新特性-日期api","slug":"java8-localdatetime","date":"2019-02-13T02:32:01.000Z","updated":"2024-07-01T12:30:37.373Z","comments":true,"path":"2019/02/13/java8-localdatetime/","link":"","permalink":"http://iogogogo.github.io/2019/02/13/java8-localdatetime/","excerpt":"","text":"Java 8的一个新增的重要特性就是引入了新的时间和日期API，它们被包含在java.time包中。借助新的时间和日期API可以以更简洁的方法处理时间和日期。 在介绍本篇文章内容之前，我们先来讨论Java 8为什么要引入新的日期API，与之前的时间和日期处理方式有什么不同？ 在Java 8之前，所有关于时间和日期的API都存在各种使用方面的缺陷，主要有： Java的java.util.Date和java.util.Calendar类易用性差，不支持时区，而且他们都不是线程安全的； 用于格式化日期的类DateFormat被放在java.text包中，它是一个抽象类，所以我们需要实例化一个SimpleDateFormat对象来处理日期格式化，并且DateFormat也是非线程安全，这意味着如果你在多线程程序中调用同一个DateFormat对象，会得到意想不到的结果。 对日期的计算方式繁琐，而且容易出错，因为月份是从0开始的，从Calendar中获取的月份需要加一才能表示当前月份。 由于以上这些问题，出现了一些三方的日期处理框架，例如Joda-Time，date4j等开源项目。但是，Java需要一套标准的用于处理时间和日期的框架，于是Java 8中引入了新的日期API。新的日期API是JSR-310规范的实现，Joda-Time框架的作者正是JSR-310的规范的倡导者，所以能从Java 8的日期API中看到很多Joda-Time的特性。 Java 8日期/时间类Java 8的日期和时间类包含LocalDate、LocalTime、Instant、Duration以及Period，这些类都包含在java.time包中，下面我们看看这些类的用法。 LocalDate和LocalTimeLocalDate类表示一个具体的日期，但不包含具体时间，也不包含时区信息。可以通过LocalDate的静态方法of()创建一个实例，LocalDate也包含一些方法用来获取年份，月份，天，星期几等： LocalDate localDate = LocalDate.of(2017, 1, 4); // 初始化一个日期：2017-01-04 int year = localDate.getYear(); // 年份：2017 Month month = localDate.getMonth(); // 月份：JANUARY int dayOfMonth = localDate.getDayOfMonth(); // 月份中的第几天：4 DayOfWeek dayOfWeek = localDate.getDayOfWeek(); // 一周的第几天：WEDNESDAY int length = localDate.lengthOfMonth(); // 月份的天数：31 boolean leapYear = localDate.isLeapYear(); // 是否为闰年：false 也可以调用静态方法now()来获取当前日期： LocalDate now = LocalDate.now(); LocalTime和LocalDate类似，他们之间的区别在于LocalDate不包含具体时间，而LocalTime包含具体时间，例如： LocalTime localTime = LocalTime.of(17, 23, 52); // 初始化一个时间：17:23:52 int hour = localTime.getHour(); // 时：17 int minute = localTime.getMinute(); // 分：23 int second = localTime.getSecond(); // 秒：52 LocalDateTimeLocalDateTime类是LocalDate和LocalTime的结合体，可以通过of()方法直接创建，也可以调用LocalDate的atTime()方法或LocalTime的atDate()方法将LocalDate或LocalTime合并成一个LocalDateTime： LocalDateTime ldt1 = LocalDateTime.of(2017, Month.JANUARY, 4, 17, 23, 52); LocalDate localDate = LocalDate.of(2017, Month.JANUARY, 4); LocalTime localTime = LocalTime.of(17, 23, 52); LocalDateTime ldt2 = localDate.atTime(localTime); LocalDateTime也提供用于向LocalDate和LocalTime的转化： LocalDate date = ldt1.toLocalDate(); LocalTime time = ldt1.toLocalTime(); InstantInstant用于表示一个时间戳，它与我们常使用的System.currentTimeMillis()有些类似，不过Instant可以精确到纳秒（Nano-Second），System.currentTimeMillis()方法只精确到毫秒（Milli-Second）。如果查看Instant源码，发现它的内部使用了两个常量，seconds表示从1970-01-01 00:00:00开始到现在的秒数，nanos表示纳秒部分（nanos的值不会超过999,999,999）。Instant除了使用now()方法创建外，还可以通过ofEpochSecond方法创建： Instant instant = Instant.ofEpochSecond(120, 100000); ofEpochSecond()方法的第一个参数为秒，第二个参数为纳秒，上面的代码表示从1970-01-01 00:00:00开始后两分钟的10万纳秒的时刻，控制台上的输出为： 1970-01-01T00:02:00.000100Z DurationDuration的内部实现与Instant类似，也是包含两部分：seconds表示秒，nanos表示纳秒。两者的区别是Instant用于表示一个时间戳（或者说是一个时间点），而Duration表示一个时间段，所以Duration类中不包含now()静态方法。可以通过Duration.between()方法创建Duration对象： LocalDateTime from = LocalDateTime.of(2017, Month.JANUARY, 5, 10, 7, 0); // 2017-01-05 10:07:00 LocalDateTime to = LocalDateTime.of(2017, Month.FEBRUARY, 5, 10, 7, 0); // 2017-02-05 10:07:00 Duration duration = Duration.between(from, to); // 表示从 2017-01-05 10:07:00 到 2017-02-05 10:07:00 这段时间 long days = duration.toDays(); // 这段时间的总天数 long hours = duration.toHours(); // 这段时间的小时数 long minutes = duration.toMinutes(); // 这段时间的分钟数 long seconds = duration.getSeconds(); // 这段时间的秒数 long milliSeconds = duration.toMillis(); // 这段时间的毫秒数 long nanoSeconds = duration.toNanos(); // 这段时间的纳秒数 Duration对象还可以通过of()方法创建，该方法接受一个时间段长度，和一个时间单位作为参数： Duration duration1 = Duration.of(5, ChronoUnit.DAYS); // 5天 Duration duration2 = Duration.of(1000, ChronoUnit.MILLIS); // 1000毫秒 PeriodPeriod在概念上和Duration类似，区别在于Period是以年月日来衡量一个时间段，比如2年3个月6天： Period period = Period.of(2, 3, 6); Period对象也可以通过between()方法创建，值得注意的是，由于Period是以年月日衡量时间段，所以between()方法只能接收LocalDate类型的参数： // 2017-01-05 到 2017-02-05 这段时间 Period period = Period.between( LocalDate.of(2017, 1, 5), LocalDate.of(2017, 2, 5)); 日期的操作和格式化增加和减少日期Java 8中的日期/时间类都是不可变的，这是为了保证线程安全。当然，新的日期/时间类也提供了方法用于创建对象的可变版本，比如增加一天或者减少一天： LocalDate date = LocalDate.of(2017, 1, 5); // 2017-01-05 LocalDate date1 = date.withYear(2016); // 修改为 2016-01-05 LocalDate date2 = date.withMonth(2); // 修改为 2017-02-05 LocalDate date3 = date.withDayOfMonth(1); // 修改为 2017-01-01 LocalDate date4 = date.plusYears(1); // 增加一年 2018-01-05 LocalDate date5 = date.minusMonths(2); // 减少两个月 2016-11-05 LocalDate date6 = date.plus(5, ChronoUnit.DAYS); // 增加5天 2017-01-10 上面例子中对于日期的操作比较简单，但是有些时候我们要面临更复杂的时间操作，比如将时间调到下一个工作日，或者是下个月的最后一天，这时候我们可以使用with()方法的另一个重载方法，它接收一个TemporalAdjuster参数，可以使我们更加灵活的调整日期： LocalDate date7 = date.with(nextOrSame(DayOfWeek.SUNDAY)); // 返回下一个距离当前时间最近的星期日 LocalDate date9 = date.with(lastInMonth(DayOfWeek.SATURDAY)); // 返回本月最后一个星期六 要使上面的代码正确编译，你需要使用静态导入TemporalAdjusters对象： import static java.time.temporal.TemporalAdjusters.*; TemporalAdjusters类中包含了很多静态方法可以直接使用，下面的表格列出了一些方法： 方法名 描述 dayOfWeekInMonth 返回同一个月中每周的第几天 firstDayOfMonth 返回当月的第一天 firstDayOfNextMonth 返回下月的第一天 firstDayOfNextYear 返回下一年的第一天 firstDayOfYear 返回本年的第一天 firstInMonth 返回同一个月中第一个星期几 lastDayOfMonth 返回当月的最后一天 lastDayOfNextMonth 返回下月的最后一天 lastDayOfNextYear 返回下一年的最后一天 lastDayOfYear 返回本年的最后一天 lastInMonth 返回同一个月中最后一个星期几 next / previous 返回后一个/前一个给定的星期几 nextOrSame / previousOrSame 返回后一个/前一个给定的星期几，如果这个值满足条件，直接返回 如果上面表格中列出的方法不能满足你的需求，你还可以创建自定义的TemporalAdjuster接口的实现，TemporalAdjuster也是一个函数式接口，所以我们可以使用Lambda表达式： @FunctionalInterface public interface TemporalAdjuster { Temporal adjustInto(Temporal temporal); } 比如给定一个日期，计算该日期的下一个工作日（不包括星期六和星期天）： LocalDate date = LocalDate.of(2017, 1, 5); date.with(temporal -> { // 当前日期 DayOfWeek dayOfWeek = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); // 正常情况下，每次增加一天 int dayToAdd = 1; // 如果是星期五，增加三天 if (dayOfWeek == DayOfWeek.FRIDAY) { dayToAdd = 3; } // 如果是星期六，增加两天 if (dayOfWeek == DayOfWeek.SATURDAY) { dayToAdd = 2; } return temporal.plus(dayToAdd, ChronoUnit.DAYS); }); 格式化日期新的日期API中提供了一个DateTimeFormatter类用于处理日期格式化操作，它被包含在java.time.format包中，Java 8的日期类有一个format()方法用于将日期格式化为字符串，该方法接收一个DateTimeFormatter类型参数： LocalDateTime dateTime = LocalDateTime.now(); String strDate1 = dateTime.format(DateTimeFormatter.BASIC_ISO_DATE); // 20170105 String strDate2 = dateTime.format(DateTimeFormatter.ISO_LOCAL_DATE); // 2017-01-05 String strDate3 = dateTime.format(DateTimeFormatter.ISO_LOCAL_TIME); // 14:20:16.998 String strDate4 = dateTime.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); // 2017-01-05 String strDate5 = dateTime.format(DateTimeFormatter.ofPattern(\"今天是：YYYY年 MMMM DD日 E\", Locale.CHINESE)); // 今天是：2017年 一月 05日 星期四 同样，日期类也支持将一个字符串解析成一个日期对象，例如： String strDate6 = \"2017-01-05\"; String strDate7 = \"2017-01-05 12:30:05\"; LocalDate date = LocalDate.parse(strDate6, DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); LocalDateTime dateTime1 = LocalDateTime.parse(strDate7, DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")); 时区Java 8中的时区操作被很大程度上简化了，新的时区类java.time.ZoneId是原有的java.util.TimeZone类的替代品。ZoneId对象可以通过ZoneId.of()方法创建，也可以通过ZoneId.systemDefault()获取系统默认时区： ZoneId shanghaiZoneId = ZoneId.of(\"Asia/Shanghai\"); ZoneId systemZoneId = ZoneId.systemDefault(); of()方法接收一个“区域/城市”的字符串作为参数，你可以通过getAvailableZoneIds()方法获取所有合法的“区域/城市”字符串： Set&lt;String> zoneIds = ZoneId.getAvailableZoneIds(); 对于老的时区类TimeZone，Java 8也提供了转化方法： ZoneId oldToNewZoneId = TimeZone.getDefault().toZoneId(); 有了ZoneId，我们就可以将一个LocalDate、LocalTime或LocalDateTime对象转化为ZonedDateTime对象： LocalDateTime localDateTime = LocalDateTime.now(); ZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, shanghaiZoneId); 将zonedDateTime打印到控制台为： 2017-01-05T15:26:56.147+08:00[Asia/Shanghai] ZonedDateTime对象由两部分构成，LocalDateTime和ZoneId，其中2017-01-05T15:26:56.147部分为LocalDateTime，+08:00[Asia/Shanghai]部分为ZoneId。 另一种表示时区的方式是使用ZoneOffset，它是以当前时间和世界标准时间（UTC）/格林威治时间（GMT）的偏差来计算，例如： ZoneOffset zoneOffset = ZoneOffset.of(\"+09:00\"); LocalDateTime localDateTime = LocalDateTime.now(); OffsetDateTime offsetDateTime = OffsetDateTime.of(localDateTime, zoneOffset); 其他历法Java中使用的历法是ISO 8601日历系统，它是世界民用历法，也就是我们所说的公历。平年有365天，闰年是366天。闰年的定义是：非世纪年，能被4整除；世纪年能被400整除。为了计算的一致性，公元1年的前一年被当做公元0年，以此类推。 此外Java 8还提供了4套其他历法（很奇怪为什么没有汉族人使用的农历），每套历法都包含一个日期类，分别是： ThaiBuddhistDate：泰国佛教历 MinguoDate：中华民国历 JapaneseDate：日本历 HijrahDate：伊斯兰历 每个日期类都继承ChronoLocalDate类，所以可以在不知道具体历法的情况下也可以操作。不过这些历法一般不常用，除非是有某些特殊需求情况下才会使用。 这些不同的历法也可以用于向公历转换： LocalDate date = LocalDate.now(); JapaneseDate jpDate = JapaneseDate.from(date); 由于它们都继承ChronoLocalDate类，所以在不知道具体历法情况下，可以通过ChronoLocalDate类操作日期： Chronology jpChronology = Chronology.ofLocale(Locale.JAPANESE); ChronoLocalDate jpChronoLocalDate = jpChronology.dateNow(); 我们在开发过程中应该尽量避免使用ChronoLocalDate，尽量用与历法无关的方式操作时间，因为不同的历法计算日期的方式不一样，比如开发者会在程序中做一些假设，假设一年中有12个月，如果是中国农历中包含了闰月，一年有可能是13个月，但开发者认为是12个月，多出来的一个月属于明年的。再比如假设年份是累加的，过了一年就在原来的年份上加一，但日本天皇在换代之后需要重新纪年，所以过了一年年份可能会从1开始计算。 在实际开发过程中建议使用LocalDate，包括存储、操作、业务规则的解读；除非需要将程序的输入或者输出本地化，这时可以使用ChronoLocalDate类。 Date与LocalDateTime相互转换 在Java 8中将Date转换为LocalDateTime 1.从日期获取ZonedDateTime并使用其方法toLocalDateTime（）获取LocalDateTime2.使用LocalDateTime的Instant（）工厂方法 /** * Date convert LocalDateTime */ @Test public void test() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); log.info(\"localDateTime:{}\", localDateTime); } /** * Date convert LocalDate */ @Test public void test1() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); LocalDate localDate = localDateTime.toLocalDate(); log.info(\"localDate:{}\", localDate); } /** * Date convert LocalTime */ @Test public void test2() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); LocalTime localTime = localDateTime.toLocalTime(); log.info(\"localTime:{}\", localTime); } // 我们也可以使用LocalDateTime的FactoryInput（）方法使用系统的默认时区。 LocalDateTime localDateTime = LocalDateTime.ofInstant(date.toInstant(), zoneId); 在Java 8中将LocalDateTime转换为Date 1.使用atZone（）方法将LocalDateTime转换为ZonedDateTime2.将ZonedDateTime转换为Instant，并从中获取Date /** * LocalDateTime to Date */ @Test public void test3() { LocalDateTime localDateTime = LocalDateTime.now(); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDateTime.atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } /** * LocalDate to Date */ @Test public void test4() { LocalDate localDate = LocalDate.now(); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDate.atStartOfDay().atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } /** * LocalTime to Date */ @Test public void test5() { LocalTime localTime = LocalTime.now(); LocalDate localDate = LocalDate.now(); LocalDateTime localDateTime = LocalDateTime.of(localDate, localTime); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDateTime.atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } 常用操作apipackage com.iogogogo; import lombok.extern.slf4j.Slf4j; import org.junit.Test; import java.time.*; import java.time.format.DateTimeFormatter; import java.util.Date; /** * Created by tao.zeng on 2019/2/12. */ @Slf4j public class Java8DatetimeTest { /** * Date convert LocalDateTime */ @Test public void test() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); log.info(\"localDateTime:{}\", localDateTime); } /** * Date convert LocalDate */ @Test public void test1() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); LocalDate localDate = localDateTime.toLocalDate(); log.info(\"localDate:{}\", localDate); } /** * Date convert LocalTime */ @Test public void test2() { java.util.Date date = new java.util.Date(); Instant instant = date.toInstant(); ZoneId zone = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zone); LocalTime localTime = localDateTime.toLocalTime(); log.info(\"localTime:{}\", localTime); } /** * LocalDateTime to Date */ @Test public void test3() { LocalDateTime localDateTime = LocalDateTime.now(); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDateTime.atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } /** * LocalDate to Date */ @Test public void test4() { LocalDate localDate = LocalDate.now(); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDate.atStartOfDay().atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } /** * LocalTime to Date */ @Test public void test5() { LocalTime localTime = LocalTime.now(); LocalDate localDate = LocalDate.now(); LocalDateTime localDateTime = LocalDateTime.of(localDate, localTime); ZoneId zone = ZoneId.systemDefault(); Instant instant = localDateTime.atZone(zone).toInstant(); java.util.Date date = Date.from(instant); log.info(\"date:{}\", date); } @Test public void test6() { String s1 = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"YYYY-mm-dd HH:mm:ss.SSS\")); LocalDate s2 = LocalDate.now(); LocalTime s3 = LocalTime.now(); log.info(\"s1:{}\", s1); log.info(\"s2:{}\", s2); log.info(\"s3:{}\", s3); } @Test public void test7() { long l1 = System.currentTimeMillis(); long l2 = LocalDateTime.now().atZone(ZoneId.systemDefault()).toInstant().toEpochMilli(); log.info(\"l1:{}\", l1); log.info(\"l2:{}\", l2); } }","categories":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"}]},{"title":"Jenkins 后台进程","slug":"jenkins-background-process","date":"2019-02-13T01:58:53.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2019/02/13/jenkins-background-process/","link":"","permalink":"http://iogogogo.github.io/2019/02/13/jenkins-background-process/","excerpt":"","text":"配置 Jenkins Job 的时候，after mvn package 用命令行 nohup java -jar project-1.0-SNAPSHOT.jar &gt; /dev/null 2&gt;&amp;1 &amp;起一个 spring-boot 项目，死活不生效。 ssh 到服务器上查不到对应的进程，而直接在服务器上执行是完全 OK 的。 Google 一番后得知，这是 Jenkins 的特性。 To reliably kill processes spawned by a job during a build, Jenkins contains a bit of native code to list up such processes and kill them. This is tested on several platforms and architectures, but if you find a show-stopper problem because of this, you can disable this feature by setting a Java property named “hudson.util.ProcessTree.disable” to the value “true”. This can be done as a parameter to the “java” binary when starting Jenkins: `java -Dhudson.util.ProcessTree.disable=true -jar jenkins.war` The ProcessTreeKiller takes advantage of the fact that by default a new process gets a copy of the environment variables of its spawning/creating process. It sets a specific environment variable in the process executing the build job. Later, when the user requests to stop the build job’s process it gets a list of all processes running on the computer and their environment variables, and looks for the environment variable that it initially set for the build job’s process. 具体链接请点击 ProcessTreeKiller。 大概意思是 Jenkins 是在启动 Job 的时候会给子进程设置环境变量，在结束 Job 的时候会检查进程的环境变量，如果包含 Jenkins 生成的，kill 掉。 解决方案： 启动 Jenkins 的时候加上 -Dhudson.util.ProcessTree.disable=true，也就是 java -Dhudson.util.ProcessTree.disable=true -jar jenkins.war 在后台进程前加上 BUILD_ID=dontKillMe, 也就是 BUILD_ID=dontKillMe nohup java -jar project-1.0-SNAPSHOT.jar &gt; /dev/null 2&gt;&amp;1 &amp; 除了上面两种方式，网上也有说讲nohup换成 setsid的方式，如有需要，可自行测试验证","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://iogogogo.github.io/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://iogogogo.github.io/tags/Jenkins/"}]},{"title":"Java拆分shell命令成数组","slug":"java-spilt-command","date":"2019-01-29T02:39:33.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2019/01/29/java-spilt-command/","link":"","permalink":"http://iogogogo.github.io/2019/01/29/java-spilt-command/","excerpt":"","text":"命令行拆分成string数组 原始命令如下 -p /path -d \"here's my description\" --verbose other args 需要的拆分结果如下 Array[0] = -p Array[1] = /path Array[2] = -d Array[3] = here&#39;s my description Array[4] = --verbose Array[5] = other Array[6] = args stackoverflow上的问题以及解决方案 依赖的ant jar scala 可以直接使用scala.tools.cmd提供的api 解决方案 /** * [code borrowed from ant.jar] * Crack a command line. * @param toProcess the command line to process. * @return the command line broken into strings. * An empty or null toProcess parameter results in a zero sized array. */ public static String[] translateCommandline(String toProcess) { if (toProcess == null || toProcess.length() == 0) { //no command? no string return new String[0]; } // parse with a simple finite state machine final int normal = 0; final int inQuote = 1; final int inDoubleQuote = 2; int state = normal; final StringTokenizer tok = new StringTokenizer(toProcess, \"\\\"\\' \", true); final ArrayList&lt;String> result = new ArrayList&lt;String>(); final StringBuilder current = new StringBuilder(); boolean lastTokenHasBeenQuoted = false; while (tok.hasMoreTokens()) { String nextTok = tok.nextToken(); switch (state) { case inQuote: if (\"\\'\".equals(nextTok)) { lastTokenHasBeenQuoted = true; state = normal; } else { current.append(nextTok); } break; case inDoubleQuote: if (\"\\\"\".equals(nextTok)) { lastTokenHasBeenQuoted = true; state = normal; } else { current.append(nextTok); } break; default: if (\"\\'\".equals(nextTok)) { state = inQuote; } else if (\"\\\"\".equals(nextTok)) { state = inDoubleQuote; } else if (\" \".equals(nextTok)) { if (lastTokenHasBeenQuoted || current.length() != 0) { result.add(current.toString()); current.setLength(0); } } else { current.append(nextTok); } lastTokenHasBeenQuoted = false; break; } } if (lastTokenHasBeenQuoted || current.length() != 0) { result.add(current.toString()); } if (state == inQuote || state == inDoubleQuote) { throw new RuntimeException(\"unbalanced quotes in \" + toProcess); } return result.toArray(new String[result.size()]); }","categories":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"Spring mvc文件上传下载","slug":"spring-file-upload-download","date":"2019-01-29T02:38:07.000Z","updated":"2024-07-01T12:30:37.379Z","comments":true,"path":"2019/01/29/spring-file-upload-download/","link":"","permalink":"http://iogogogo.github.io/2019/01/29/spring-file-upload-download/","excerpt":"","text":"简介文件上传是项目开发中最常见的功能。为了能上传文件，必须将表单的method设置为POST，并将enctype设置为multipart/form-data。只有在这样的情况下，浏览器才会把用户选择的文件以二进制数据发送给服务器。一旦设置了enctype为multipart/form-data，浏览器即会采用二进制流的方式来处理表单数据，而对于文件上传的处理则涉及在服务器端解析原始的HTTP响应。在2003年，Apache Software Foundation发布了开源的Commons FileUpload组件，其很快成为Servlet/JSP程序员上传文件的最佳选择。Servlet3.0规范已经提供方法来处理文件上传，但这种上传需要在Servlet中完成。而Spring MVC则提供了更简单的封装。Spring MVC为文件上传提供了直接的支持，这种支持是用即插即用的MultipartResolver实现的。Spring MVC使用Apache Commons FileUpload技术实现了一个MultipartResolver实现类：CommonsMultipartResolver。因此，SpringMVC的文件上传还需要依赖Apache Commons FileUpload的组件。 核心代码package com.iogogogo.api; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.boot.web.servlet.MultipartConfigFactory; import org.springframework.context.annotation.Bean; import org.springframework.core.io.InputStreamResource; import org.springframework.core.io.Resource; import org.springframework.http.HttpHeaders; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.util.Base64Utils; import org.springframework.util.FileCopyUtils; import org.springframework.util.unit.DataSize; import org.springframework.web.bind.annotation.*; import org.springframework.web.multipart.MultipartFile; import javax.servlet.MultipartConfigElement; import javax.servlet.ServletOutputStream; import javax.servlet.http.HttpServletResponse; import java.io.*; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.*; /** * # 禁用 thymeleaf 缓存 * spring.thymeleaf.cache=false * &lt;p> * # 是否支持批量上传 (默认值 true) * spring.servlet.multipart.enabled=true * &lt;p> * # 上传文件的临时目录 （一般情况下不用特意修改） * spring.servlet.multipart.location= * &lt;p> * # 上传文件最大为 1M （默认值 1M 根据自身业务自行控制即可） * spring.servlet.multipart.max-file-size=1048576 * &lt;p> * # 上传请求最大为 10M（默认值10M 根据自身业务自行控制即可） * spring.servlet.multipart.max-request-size=10485760 * &lt;p> * # 文件大小阈值，当大于这个阈值时将写入到磁盘，否则存在内存中，（默认值0 一般情况下不用特意修改） * spring.servlet.multipart.file-size-threshold=0 * &lt;p> * # 判断是否要延迟解析文件（相当于懒加载，一般情况下不用特意修改） * spring.servlet.multipart.resolve-lazily=false * &lt;p> * Created by tao.zeng on 2018/12/6. * http://localhost:8080/api/file/download2stream * http://localhost:8080/api/file/download */ @RestController @RequestMapping(\"/api/file\") public class FileApi { private Logger logger = LoggerFactory.getLogger(FileApi.class); private final static String FILE_NAME = \"main.csv\"; private final static String FILE_CONTENT = \"key,value\"; private final static String FILE_PATH = System.getProperty(\"user.dir\") + File.separator + \"tmp\"; static { File file = new File(FILE_PATH); if (!file.exists()) { file.mkdirs(); } } /** * 通过 OutputStream 每次往客户端写 buffer * * @param response */ @GetMapping(\"/download\") public void download(HttpServletResponse response) { InputStream inStream = new ByteArrayInputStream(FILE_CONTENT.getBytes()); // 设置强制下载不打开 response.setContentType(\"application/force-download\"); // 设置content-type response.setHeader(HttpHeaders.CONTENT_TYPE, \"application/octet-stream\"); // 设置文件名 response.addHeader(HttpHeaders.CONTENT_DISPOSITION, \"attachment;fileName=\" + FILE_NAME); byte[] buffer = new byte[1024]; ServletOutputStream outStream = null; BufferedInputStream bufferStream = null; try { outStream = response.getOutputStream(); bufferStream = new BufferedInputStream(inStream); int len; while ((len = bufferStream.read(buffer)) != -1) { outStream.write(buffer, 0, len); } outStream.flush(); } catch (IOException e) { e.printStackTrace(); } finally { close(outStream, bufferStream); } } /** * 流式下载 * * @return */ @GetMapping(\"/download2stream\") public ResponseEntity&lt;Resource> download2stream() { InputStream inStream = null; try { inStream = new ByteArrayInputStream(FILE_CONTENT.getBytes()); Resource resource = new InputStreamResource(inStream); return ResponseEntity.ok() .contentType(MediaType.parseMediaType(\"application/octet-stream;charset=UTF-8\")) .header(HttpHeaders.CONTENT_DISPOSITION, \"attachment;fileName=\" + FILE_NAME) .body(resource); } catch (Exception e) { e.printStackTrace(); throw new RuntimeException(\"下载异常:\" + e); } finally { close(inStream); } } /** * multipart/form-data * * @param file * @return */ @PostMapping(\"/upload\") public Map&lt;String, Object> upload(@RequestParam(\"file\") MultipartFile file) { // 获取 resources 目录 // String realPath = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest().getServletContext().getRealPath(\"\"); Map&lt;String, Object> result = new HashMap&lt;>(16); try { logger.info(\"[文件类型] - [{}]\", file.getContentType()); logger.info(\"[文件名称] - [{}]\", file.getOriginalFilename()); logger.info(\"[文件大小] - [{}]\", file.getSize()); byte[] bytes = file.getBytes(); String fileName = FILE_PATH + File.separator + file.getOriginalFilename(); Path path = Paths.get(fileName); Files.write(path, bytes); result.put(\"contentType\", file.getContentType()); result.put(\"fileName\", file.getOriginalFilename()); result.put(\"fileSize\", file.getSize()); } catch (IOException e) { e.printStackTrace(); } return result; } /** * 多文件上传 * * @param files * @return */ @PostMapping(\"/multi-file-upload\") public List&lt;Map&lt;String, Object>> multiFileUpload(@RequestParam(\"file\") MultipartFile[] files) { if (files == null || files.length == 0) { return null; } List&lt;Map&lt;String, Object>> results = new ArrayList&lt;>(); Map&lt;String, Object> map; try { for (MultipartFile file : files) { map = new HashMap&lt;>(16); String fileName = FILE_PATH + File.separator + file.getOriginalFilename(); file.transferTo(new File(fileName)); map.put(\"contentType\", file.getContentType()); map.put(\"fileName\", file.getOriginalFilename()); map.put(\"fileSize\", file.getSize()); results.add(map); } } catch (IOException e) { e.printStackTrace(); } return results; } /** * Base64文件上传 * &lt;p> * base64编码： http://base64.xpcha.com/pic.html * * @param base64 * @return */ @PostMapping(\"/base64-upload\") public Map&lt;String, Object> uploadBase64(String base64) { Map&lt;String, Object> map = new HashMap&lt;>(16); // 防止有的传了 data:image/png;base64, 有的没传的情况 String[] d = base64.split(\"base64,\"); final byte[] bytes = Base64Utils.decodeFromString(d.length > 1 ? d[1] : d[0]); // BASE64 方式的 格式和名字需要自己控制（如 png 图片编码后前缀就会是 data:image/png;base64,） File tempFile = new File(FILE_PATH + File.separator + UUID.randomUUID() + \".jpg\"); try { FileCopyUtils.copy(bytes, tempFile); map.put(\"fileSize\", tempFile.length()); map.put(\"fileName\", tempFile.getName()); map.put(\"parent\", tempFile.getParent()); } catch (IOException e) { e.printStackTrace(); } return map; } private void close(Closeable... closeables) { try { if (closeables != null) { for (Closeable io : closeables) { if (io != null) { io.close(); } } } } catch (IOException e) { logger.warn(\"io close exception {}\", e); } } @Bean public MultipartConfigElement multipartConfigElement() { MultipartConfigFactory factory = new MultipartConfigFactory(); // 最大支持文件大小 factory.setMaxFileSize(DataSize.ofMegabytes(10)); // 最大支持请求大小 factory.setMaxRequestSize(DataSize.ofMegabytes(100)); // 支持文件写入磁盘. // factory.setFileSizeThreshold(); // Sets the directory location where files will be stored. // factory.setLocation(\"上传文件的临时目录\"); return factory.createMultipartConfig(); } }","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Git常用命令","slug":"git-command","date":"2019-01-29T02:35:03.000Z","updated":"2024-07-01T12:30:37.371Z","comments":true,"path":"2019/01/29/git-command/","link":"","permalink":"http://iogogogo.github.io/2019/01/29/git-command/","excerpt":"","text":"Git常用命令使用Git生成ssh密钥:ssh-keygen -t rsa -C \"email@example.com\" 设置全局用户名和邮箱:git config --global user.name \"YourName\" git config --global user.email \"email@example.com\" 初始化仓库git init 添加文件到暂存区git add #添加指定文件到暂存区 git add . #添加工作区所有文件到暂存区 git add -i #交互方式添加文件到暂存区 git add -u #将工作区中已经变动的文件添加到暂存区，当新增加的文件不会被添加 提交文件到仓库git commit -m \"描述信息\" #提交更新 git commit -am \"描述信息\" #如果工作目录中仅是已跟踪的文件被修改或被删除，使用此提交命令 分支的创建、删除、和平、切换、查看git branch #查看Git仓库中已有的分支 git branch 新分支名 [分支起点] #创建分支，如果没有分支起点的话，则默认在当前分支的最新提交上创建分支 git checkout 分支名 #切换分支 git checkout -b 新分支名 #创建同时切换到新分支 git merge 要被合并的分支名 #合并分支 git branch -d 要删除的分支名 #删除指定分支（如果分支没有被合并过，该命令会执行失败） git branch -D 要删除的分支名 #删除指定分支，不管有没有被合并过 gitk #用图形界面查看分支提交历史 合并分支过程中如果发生冲突则需要自己手动解决冲突，然后再提交。有冲突时，Git会显示哪个文件有冲突，并在冲突的文件中加上特殊的标识符号，解决完冲突后，要手动去掉这些被添加的标识符号。如果冲突比较复杂的话，最好使用其他工具来协助，通过git mergetool来启动。冲突一般是在不同的分支上对同一文件的同一位置内容进行了改动，并已提交到仓库中，这样在合并的时候就会发生冲突。 标签的添加、删除、查看git tag #查看标签 git tag 标签名 #创建简单的标签 git tag -a 标签名 -m '附加信息' #创建附加信息的标签 git show 标签名 #通过标签查看信息 git tag -d 标签名 #删除标签 标签可以在需要的地方，为某个提交对象创建别名，这样以后我们就可以通过标签来查看一些信息，创建分支等。 查看工作目录状态git status 在git命令执行后，要养成通过git status查看git状态的习惯，以便及时了解文件变化的情况。通过git status可以知道文件的状态（已修改未暂存、已删除、已修改并已暂存等待提交、未跟踪）。 查看提交历史git log git log -p #显示每次提交文件变化 通过git log可以查看当前分支的所有提交历史，知道每次提交的commit对象的ID以及提交时附加的描述信息等。要显示更多的信息，需要使用其支持的选项，如git log -p可以将每次提交的文件变化也显示出来。 查看指定的提交对象git show commit_id #查看指定的某次提交内容 git show --all #显示所有的提交历史内容 git shortlog -s -n #显示总的提交次数 通过git log可以显示整个提交历史，而通过git show commit-id则可以查看指定的某次提交内容，当然git show -all也可以显示出提交历史，另外还可以格式化显示内容。 Note : commit-id可以是commit对象对应的ID，也可以是HEAD，分支名，tag等。 查看工作区、暂存区、仓库之间的差异git diff #比较工作区与暂存区的差异 git diff HEAD #比较工作区与仓库中最近一次的提交间的差异 git diff --cached #比较暂存区与仓库中最近一次提交的差异 git blame filename #可以列出该文件每次被修改的时间和内容。 版本回退、撤销操作git reflog #显示提交历史的简介 git checkout -- filename #丢弃工作区的修改 git reset --hard HEAD^ #回退到上一个版本 git reset --hard commit_id #回退到指定版本 git checkout -- filename #恢复工作区被删除的指定文件（文件之前被提交到仓库中） git checkout -f #恢复工作区中所有被删除的文件(文件之前被提交到仓库中) git ls-files -d #列出工作区被删除的文件（文件之前被提交到仓库中） 有时候，由于我们的误操作，产生了一些错误，我们发现后希望能够及时纠正这些因为误操作而产生的结果，将工作目录恢复到某个正常状态。 撤销修改，但还没有添加到暂存区： git checkout -- filename 修改的文件会被恢复到上次提交时的状态，修改的内容会丢失。 版本回退：先通过git reflog找到某个版本的commit_id，然后用git reset --hard commit_id将工作目录的文件恢复到指定的版本。 恢复工作区中被删除的文件（文件之前被提交到仓库中）：git checkout -- filename 或 git checkout -f 备份工作区git stash #将工作区文件保存在Git内部栈中 git stash list #列出Git内部栈中保存的工作区文件列表 git stash apply stash_id #恢复工作区到指定的内部栈状态 git stash pop #恢复工作区到上一个内部栈状态 git stash clear #清空Git内部栈 如果正在一个develop分支上正在开发新功能，但这时master分支(稳定版本)突然发现了bug，并需要及时修复，而develop分支此时的工作还没有完成，且不希望将之前的工作就这样提交到仓库中时，这时就可以用git stash来暂时保存这些状态到Git内部栈中，并用当前分支上一次的提交内容来恢复工作目录，然后切换到master分支进行bug修复工作，等修复完毕并提交到仓库上后，再使用git stash apply [stash@{0}]或者git stash pop将工作目录恢复到之前的状态，继续之前的工作。 同时也可以多次使用git stash将未提交的代码压入到Git栈中，但当多次使用git stash命令后，Git栈里将充满了未提交的代码，这时候到底要用哪个版本来恢复工作目录呢？git stash list命令可以将当前的Git栈信息打印出来，我们只需要将找到对应的版本号，例如使用git stash apply stash@{1}就可以用版本号为stash@{1}的内容来恢复工作目录。 当Git栈中所有的内容都被恢复后，可以使用git stash clear来将栈清空。 将当前工作区目录文件压缩归档git archive --format=zip -o arch.zip HEAD git arch --format zip head>arch.zip 远程操作 Git相比其他版本控制软件的一个优点就是大多数的操作都可以在本地进行，而不用管远程的仓库，因为操作是在本地，且操作的数据也是在本地，加上指针等原因，所以执行的速度就会比较快。 在多人协作的项目中，就需要涉及与远程仓库交互的问题，主要是如何从远程仓库抓取最新数据合并到自己的本地分支上，将自己的最新成果分享给其他人或让别人审查等 。 远程仓库的克隆、添加、查看git remote #显示已添加的远程仓库名 git remote -v #显示已添加的远程仓库名和地址 git remote add 远程仓库名 远程仓库地址 #在本地添加远程仓库 git remote rm 远程仓库名 #删除本地添加的远程仓库名 git remote rename 原名 新名 #重命名远程仓库名 git clone 远程仓库地址 [克隆到指定的文件夹] #克隆远程仓库到本地 git clone -b [branch-name] 远程仓库地址 [克隆到指定的文件夹] #克隆远程仓库到本地 -b git fetch 远程仓库名 #从远程仓库抓取最新数据到本地但不与本地分支进行合并 git pull 远程仓库名 本地要合并的分支名 #从远程仓库抓取最新数据并自动与本地分支进行合并 git push 远程仓库名 本地分支名 #将本地仓库推送到远程仓库中 git remote show 远程仓库名 #查看远程仓库信息 git remote show #查看所有远程仓库 git push 远程仓库名 标签名 #将标签推送到远程仓库（Git默认不推送标签） 协同流程 Fork远程项目 把Fork的项目clone到本地 执行以下命令，将别人的库添加为远端库 git remote add 远端仓库名 远端的分支 运行以下命令，拉去合并到本地 git pull 远端仓库名 远端分支名 编辑内容 commit之后push到自己的库 登录Github，在你的首页可以看到一个pull request按钮，点击它，填写一些说明信息，提交即可。 在本地编辑内容前必须执行pull操作同步别人的远端库（这样避免冲突） 实用技巧 当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再使用git stash pop，回到工作现场. 多人协作技巧 查看远程库信息，使用git remote -v；本地新建的分支如果不推送到远程，对其他人就是不可见的；从本地推送分支，使用git push 远程仓库名 分支名，如果推送失败，先用git pull抓取远程的新提交；在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致；建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name；从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。","categories":[{"name":"工具使用","slug":"工具使用","permalink":"http://iogogogo.github.io/categories/工具使用/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/tags/Git/"}]},{"title":"Spring Boot 结合 Quartz 设置定时任务","slug":"spring-quartz-scheduled","date":"2019-01-29T02:29:13.000Z","updated":"2024-07-01T12:30:37.380Z","comments":true,"path":"2019/01/29/spring-quartz-scheduled/","link":"","permalink":"http://iogogogo.github.io/2019/01/29/spring-quartz-scheduled/","excerpt":"","text":"Spring Boot 原生 @Scheduled任务配置@Slf4j @Component public class ScheduledTask { @Scheduled(fixedRate = 5000) // 表示每隔5000ms，Spring scheduling会调用一次该方法，不论该方法的执行时间是多少 public void reportCurrentTime() throws InterruptedException { log.info(new Date()); } @Scheduled(fixedDelay = 5000) // 表示当方法执行完毕5000ms后，Spring scheduling会再次调用该方法 public void reportCurrentTimeAfterSleep() throws InterruptedException { log.info(new Date()); } @Scheduled(cron = \"0 0 1 * * *\") // 提供了一种通用的定时任务表达式，这里表示每隔5秒执行一次，更加详细的信息可以参考cron表达式。 public void reportCurrentTimeCron() throws InterruptedException { log.info(new Date()); } } 启动@SpringBootApplication @EnableScheduling // 告诉Spring创建一个task executor，如果我们没有这个标注，所有@Scheduled标注都不会执行 public class App { public static void main(String[] args) { SpringApplication.run(App.class, args); } } Spring Boot 结合 Quartz 实现动态设置定时任务 需要spring boot版本大于2.x http://www.quartz-scheduler.org/ 添加依赖配置// implementation 'org.quartz-scheduler:quartz:2.3.0' // implementation 'org.quartz-scheduler:quartz-jobs:2.3.0' implementation 'org.springframework.boot:spring-boot-starter-quartz' 配置 quartzJobFactory 和 scheduler 对象package com.iogogogo.quartz.configure; import org.quartz.Scheduler; import org.quartz.spi.TriggerFiredBundle; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.config.AutowireCapableBeanFactory; import org.springframework.context.ApplicationContextAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.SchedulerFactoryBean; import org.springframework.scheduling.quartz.SpringBeanJobFactory; import org.springframework.stereotype.Component; /** * Created by tao.zeng on 2019/1/29. */ @Configuration public class QuartzConfiguration { /** * 解决Job中注入Spring Bean为null的问题 */ @Component(\"quartzJobFactory\") class QuartzJobFactory extends SpringBeanJobFactory implements ApplicationContextAware { // 这个对象Spring会帮我们自动注入进来,也属于Spring技术范畴. @Autowired private AutowireCapableBeanFactory capableBeanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception { // 调用父类的方法 final Object jobInstance = super.createJobInstance(bundle); // 进行注入,这属于Spring的技术,不清楚的可以查看Spring的API. capableBeanFactory.autowireBean(jobInstance); return jobInstance; } } /** * 注入scheduler到spring，在下面quartzManege会用到 * * @return * @throws Exception */ @Bean(name = \"scheduler\") public Scheduler scheduler(SchedulerFactoryBean schedulerFactoryBean) throws Exception { // schedulerFactoryBean.setJobFactory(quartzJobFactory); // 该方法会再次初始化 quartz 这里的初始化任务交给spring容器即可 // schedulerFactoryBean.afterPropertiesSet(); Scheduler scheduler = schedulerFactoryBean.getScheduler(); scheduler.start(); return scheduler; } } 新建一个bean对象，用来保存基本的job信息package com.iogogogo.quartz.bean; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; /** * Created by tao.zeng on 2019/1/18. */ @Data @NoArgsConstructor @AllArgsConstructor public class QuartzJob { public static final Integer STATUS_RUNNING = 1; public static final Integer STATUS_NOT_RUNNING = 0; public static final Integer CONCURRENT_IS = 1; public static final Integer CONCURRENT_NOT = 0; private String jobId; /** * cron 表达式 */ private String cronExpression; /** * 任务调用的方法名 */ private String methodName; /** * 任务是否有状态 */ private Integer isConcurrent; /** * 描述 */ private String description; /** * 任务执行时调用哪个类的方法 包名+类名，完全限定名 */ private String beanName; /** * 触发器名称 */ private String triggerName; /** * 任务状态 */ private Integer jobStatus; /** * 任务名 */ private String jobName; } 新建一个统一的QuartzManager，用来统一管理jobpackage com.iogogogo.quartz.configure; import com.iogogogo.quartz.bean.QuartzJob; import lombok.extern.slf4j.Slf4j; import org.quartz.*; import org.springframework.stereotype.Component; import javax.annotation.Resource; import static org.quartz.JobBuilder.newJob; import static org.quartz.TriggerBuilder.newTrigger; /** * Created by tao.zeng on 2019/1/18. */ @Slf4j @Component public class QuartzManager { @Resource(name = \"scheduler\") private Scheduler scheduler; public void addJob(QuartzJob job) throws SchedulerException, ClassNotFoundException, IllegalAccessException, InstantiationException { // 通过类名获取实体类，即要执行的定时任务的类 Class&lt;?> clazz = Class.forName(job.getBeanName()); Job jobEntity = (Job) clazz.newInstance(); // 通过实体类和任务名创建 JobDetail JobDetail jobDetail = newJob(jobEntity.getClass()) .withIdentity(job.getJobName()).build(); // 通过触发器名和cron 表达式创建 Trigger Trigger cronTrigger = newTrigger() .withIdentity(job.getTriggerName()) .startNow() .withSchedule(CronScheduleBuilder.cronSchedule(job.getCronExpression())) .build(); // 执行定时任务 scheduler.scheduleJob(jobDetail, cronTrigger); } /** * 更新job cron表达式 * * @param quartzJob * @throws SchedulerException */ public void updateJobCron(QuartzJob quartzJob) throws SchedulerException { TriggerKey triggerKey = TriggerKey.triggerKey(quartzJob.getJobName()); CronTrigger trigger = (CronTrigger) scheduler.getTrigger(triggerKey); CronScheduleBuilder scheduleBuilder = CronScheduleBuilder.cronSchedule(quartzJob.getCronExpression()); trigger = trigger.getTriggerBuilder().withIdentity(triggerKey).withSchedule(scheduleBuilder).build(); scheduler.rescheduleJob(triggerKey, trigger); } /** * 删除一个job * * @param quartzJob * @throws SchedulerException */ public void deleteJob(QuartzJob quartzJob) throws SchedulerException { JobKey jobKey = JobKey.jobKey(quartzJob.getJobName()); scheduler.deleteJob(jobKey); } /** * 恢复一个job * * @param quartzJob * @throws SchedulerException */ public void resumeJob(QuartzJob quartzJob) throws SchedulerException { JobKey jobKey = JobKey.jobKey(quartzJob.getJobName()); scheduler.resumeJob(jobKey); } /** * 立即执行job * * @param quartzJob * @throws SchedulerException */ public void runAJobNow(QuartzJob quartzJob) throws SchedulerException { JobKey jobKey = JobKey.jobKey(quartzJob.getJobName()); scheduler.triggerJob(jobKey); } /** * 暂停一个job * * @param quartzJob * @throws SchedulerException */ public void pauseJob(QuartzJob quartzJob) throws SchedulerException { JobKey jobKey = JobKey.jobKey(quartzJob.getJobName()); scheduler.pauseJob(jobKey); } } 新建job任务，实现org.quartz.Job接口package com.iogogogo.quartz.schedule; import lombok.extern.slf4j.Slf4j; import org.quartz.JobExecutionContext; import org.springframework.scheduling.quartz.QuartzJobBean; import org.springframework.stereotype.Component; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.Locale; /** * Created by tao.zeng on 2019/1/29. */ @Slf4j @Component public class ScheduleTask extends QuartzJobBean { @Override protected void executeInternal(JobExecutionContext context) { log.info(\"execute task:{}\", LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\", Locale.CHINA))); } } 启动类配置package com.iogogogo.quartz; import com.iogogogo.quartz.bean.QuartzJob; import com.iogogogo.quartz.configure.QuartzManager; import org.quartz.SchedulerException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * Created by tao.zeng on 2019/1/18. */ @SpringBootApplication public class QuartzSchedulerApplication implements CommandLineRunner { @Autowired private QuartzManager quartzManager; public static void main(String... args) { SpringApplication.run(QuartzSchedulerApplication.class, args); } @Override public void run(String... args) { try { String scheduleTask = \"com.iogogogo.quartz.schedule.ScheduleTask\"; QuartzJob job = new QuartzJob(scheduleTask, \"*/1 * * * * ?\", scheduleTask, 1, scheduleTask, scheduleTask, scheduleTask, QuartzJob.STATUS_NOT_RUNNING, scheduleTask); quartzManager.addJob(job); } catch (SchedulerException | ClassNotFoundException | IllegalAccessException | InstantiationException e) { e.printStackTrace(); } } }","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"}]},{"title":"Windows下安装MySQL-5.7.17解压版","slug":"windows-install-mysql-5-7-17","date":"2018-08-10T09:59:42.000Z","updated":"2024-07-01T12:30:37.381Z","comments":true,"path":"2018/08/10/windows-install-mysql-5-7-17/","link":"","permalink":"http://iogogogo.github.io/2018/08/10/windows-install-mysql-5-7-17/","excerpt":"","text":"下载MySQL Community Server地址：http://dev.mysql.com/downloads/mysql/ 选择Windows (x86, 64-bit), ZIP Archive进行下载。 现在最新版本是5.7.19，笔者这里是5.7.17 配置mysql 环境变量我这里将下载好的mysql-5.7.17 解压到 C:\\Program Files\\mysql-5.7.17-winx64 配置 MYSQL_HOME —&gt; C:\\Program Files\\mysql-5.7.17-winx64 Path 环境变量中加入 %MYSQL_HOME%/bin; 注意如果path最后一个没有; 记得自己手动添加; 修改mysql 配置文件复制解压目录下的 my-default.ini 文件将名称修改为 my.ini 修改文件内容 打开 my.ini 修改文件内容 basedir = C:\\Program Files\\mysql-5.7.17-winx64 datadir = C:\\Program Files\\mysql-5.7.17-winx64\\data port = 3306 注意：去掉源文件上述三行前面的# 注册windows系统服务以管理员权限打开cmd 执行 mysqld install MySQL –defaults-file=”C:\\Program Files\\mysql-5.7.17-winx64\\my.ini” 注册表中查看ImagePath的值 我的为 “C:\\Program Files\\mysql-5.7.17-winx64\\bin\\mysqld” –defaults-file=”C:\\Program Files\\mysql-5.7.17-winx64\\my.ini” MySQL 其中包含了mysqld，就不修改了。 注册表位置为： \\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MySQL 执行mysqld –initialize进行初始化（生成data目录执行 mysqld –initialize 启动 MySQL 服务执行 net start mysql 登录mysql 修改 root 账户默认密码默认密码保存在生成data目录下面的 .err 文件中 记事本打开以后查找初始化密码 A temporary password is generated for root@localhost: [密码] 我的为 执行 mysql –uroot –p 复制刚刚上面的初始化密码完成登录 修改默认密码 执行 SET PASSWORD = PASSWORD(‘’); 我这里将密码设置为空 执行完成以后退出mysql 就可以使用新密码进行登录了 修改mysql 默认编码执行 show variables like ‘character_set_%’; 查看 mysql 编码 查看mysql默认编码字符 修改 my.ini 文件 修改配置mysql编码 重启mysql 重启mysql并且重新登录 执行 show variables like ‘character_set_%’; 查看 mysql 编码 查看修改以后的编码字符 utf8 注意： 网上很多资源都是在[mysqld]下添加 default-character-set=utf8 如果这样改会导致5.7版本mysql无法打开 所以要改为 character-set-server=utf8 改完后，要删除数据库中所有数据，才能使用。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"}]},{"title":"mac使用parallels安装配置centos7","slug":"mac-install-parallel-centos7","date":"2018-08-10T09:54:40.000Z","updated":"2024-07-01T12:30:37.375Z","comments":true,"path":"2018/08/10/mac-install-parallel-centos7/","link":"","permalink":"http://iogogogo.github.io/2018/08/10/mac-install-parallel-centos7/","excerpt":"","text":"安装parallelshttps://www.jianshu.com/p/76f38e6c0792 配置 ssh 登录 查看宿主机ip和网关 修改网卡配置文件 配置外网dns 保存重启网络 ssh 连接 配置 查看宿主机IP和网关ifconfig 修改网卡配置文件和NDS vi /etc/sysconfig/network-scripts/ifcfg-eth0 BOOTPROTO=static # 网卡获取IP的方式(默认为dchp,设置为静态获取。 IPADDR=192.168.1.254 # 除最后部分其他与宿主机的网关一致 GATEWAY=192.168.1.1 # 与宿主机保持一致 NETMASK=255.255.255.0 ONBOOT=yes DNS1=192.168.1.1 DNS2=8.8.8.8 保存重启网络service network restart ssh 连接 配置ssh root@192.168.1.254 开放端口 永久的开放需要的端口 # 添加开放端口 sudo firewall-cmd --zone=public --add-port=3000/tcp --permanent # 关闭开放端口 sudo firewall-cmd --zone=public --remove-port=80/tcp --permanent # 重新加载 sudo firewall-cmd --reload 之后检查新的防火墙规则 firewall-cmd --list-all 关闭防火墙//临时关闭防火墙,重启后会重新自动打开 systemctl restart firewalld //检查防火墙状态 firewall-cmd --state firewall-cmd --list-all //Disable firewall systemctl disable firewalld systemctl stop firewalld systemctl status firewalld //Enable firewall systemctl enable firewalld systemctl start firewalld systemctl status firewalld","categories":[{"name":"MacBook","slug":"MacBook","permalink":"http://iogogogo.github.io/categories/MacBook/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://iogogogo.github.io/tags/Mac/"}]},{"title":"kafka常用操作笔记","slug":"kafka-note","date":"2018-07-30T03:36:44.000Z","updated":"2024-07-01T12:30:37.374Z","comments":true,"path":"2018/07/30/kafka-note/","link":"","permalink":"http://iogogogo.github.io/2018/07/30/kafka-note/","excerpt":"","text":"下载地址http://kafka.apache.org/downloads 安装步骤 解压下载文件到指定目录，比如 /usr/local tar -zxvf /usr/local/kafka_2.12-1.0.0.tgz 停止zookeeper与kafkacd /usr/local ./bin/zookeeper-server-stop.sh ./bin/kafka-server-stop.sh 启动 zookeepercd /usr/local ./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties -daemon 表示后台运行 启动kafkacd /usr/local ./bin/kafka-server-start.sh -daemon ./config/server.properties 查看kafka与zookeeper是否运行netstat -ntpul | grep 2181 netstat -ntpul | grep 9092 创建 topic./bin/kafka-topics.sh --create --zookeeper 192.168.1.200:2181 --replication-factor 1 --partitions 1 --topic TOPIC_001 删除topic http://blog.csdn.net/fengzheku/article/details/50585972 ./bin/kafka-topics.sh --delete --zookeeper 192.168.1.200:2181 --topic TOPIC_001 查看已经存在的topic./bin/kafka-topics.sh --list --zookeeper localhost:2181 查看topic的详细信息./bin/kafka-topics.sh --describe --zookeeper 192.168.1.200:2181 --topic TOPIC_001 生产消息./bin/kafka-console-producer.sh --broker-list 192.168.1.200:9092 --topic TOPIC_001 消费消息./bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.200:9092 --topic TOPIC_001 --from-beginning 解决kafka无法收发消息 org.apache.kafka.common.errors.TimeoutException https://www.jianshu.com/p/2db7abddb9e6 vim /usr/local/kafka/config/server.properties 加入以下配置然后重启zookeeper与kafka advertised.host.name=192.168.1.200 advertised.port=9092","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/categories/Kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://iogogogo.github.io/tags/kafka/"}]},{"title":"使用docker-compose构建kafka集群","slug":"docker-compose-zk-kafka","date":"2018-07-28T04:41:40.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2018/07/28/docker-compose-zk-kafka/","link":"","permalink":"http://iogogogo.github.io/2018/07/28/docker-compose-zk-kafka/","excerpt":"","text":"&emsp;&emsp;上篇说到了docker-compose的一些基本命令，这次使用docker-compose构建kafka集群。在说kafka之前，先简单了解一下kafka是什么东西。 Kafka创建背景Kafka是一个消息系统，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司作为多种类型的数据管道和消息系统使用。 活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。 近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。 Kafka简介Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下： 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 Scale out：支持在线水平扩展。 为何使用消息系统 解耦 在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 冗余 有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。 扩展性 因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。 灵活性 &amp; 峰值处理能力 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。 可恢复性 系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 顺序保证 在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。 缓冲 在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。 异步通信 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 常用Message Queue对比 RabbitMQ RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。 Redis Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。 ZeroMQ ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。 ActiveMQ ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。 Kafka/Jafka Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。 构建zookeeper、kakfa集群&emsp;&emsp;首先kafka依赖于zookeeper，所以在构建kafka集群之前我们先来构建zookeeper集群，zookeeper的集群构建方式很简单，docker官网都有给出docker-compose文件。zookeeper有官方镜像，kakfa暂时还没有，所以我们选择了一个github上目前star最高的镜像kafka-docker。 编写zookeeper的docker-compose文件version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 volumes: - \"~/share/docker/compose-data/zookeeper/zoo1/data:/data\" - \"~/share/docker/compose-data/zookeeper/zoo1/datalog:/datalog\" - \"~/share/docker/compose-data/zookeeper/zoo1/conf:/conf\" environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 volumes: - \"~/share/docker/compose-data/zookeeper/zoo2/data:/data\" - \"~/share/docker/compose-data/zookeeper/zoo2/datalog:/datalog\" - \"~/share/docker/compose-data/zookeeper/zoo2/conf:/conf\" environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 volumes: - \"~/share/docker/compose-data/zookeeper/zoo3/data:/data\" - \"~/share/docker/compose-data/zookeeper/zoo3/datalog:/datalog\" - \"~/share/docker/compose-data/zookeeper/zoo3/conf:/conf\" environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 &emsp;&emsp;保存文件名为【docker-compose.yml】,我们可以看到整个compose文件中一共运行了三个zookeeper实例，为什么是三个？因为zookeeper内部的选举机制，在集群中有其他节点挂掉的话，至少保证n+1个节点用来选举leader，所以集群至少三个节点。 &emsp;&emsp;现在来说说compose文件中的参数含义： version: ‘3.1’ 表示使用第三代compose语法 services 表示一个实例服务 zoo1、zoo2、zoo3是我自己给实例服务起的名字 image 表示需要使用的docker镜像，这里使用的官方镜像，并且没有指定target restart: always 表示挂掉会一直重启 ports 导出的端口号，因为我这是在一台机器，所以分别使用了2181，2182，2183三个端口 volumes 数据卷目录 environment 环境参数，这里面ZOO_MY_ID表示集群中的zk编号，不可重复，ZOO_SERVERS表示集群中所有的zk服务实例 编写kakfa的docker-compose文件kakfa的compose文件和zookeeper有些小区别，主要体现在运行方式上面并且我们现在需要创建三个docker-compose文件，唯一的区别就是port不一样。需要注意的是environment参数中的IP地址不要使用localhost或者127.0.0.1，这里需要使用IP地址 docker-compose-9092.yml version: '3.1' services: kafka: image: wurstmeister/kafka restart: always hostname: kafka ports: - 9092:9092 volumes: - \"~/share/docker/compose-data/kafka/kafka-9092/docker.sock:/var/run/docker.sock\" - \"~/share/docker/compose-data/kafka/kafka-9092:/kafka\" environment: KAFKA_VERSION: 1.1.0 KAFKA_ADVERTISED_HOST_NAME: 192.168.1.6 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: 192.168.1.6:2181,192.168.1.6:2182,192.168.1.6:2183 docker-compose-9093.yml version: '3.1' services: kafka: image: wurstmeister/kafka restart: always hostname: kafka ports: - 9093:9092 volumes: - \"~/share/docker/compose-data/kafka/kafka-9093/docker.sock:/var/run/docker.sock\" - \"~/share/docker/compose-data/kafka/kafka-9093:/kafka\" environment: KAFKA_VERSION: 1.1.0 KAFKA_ADVERTISED_HOST_NAME: 192.168.1.6 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: 192.168.1.6:2181,192.168.1.6:2182,192.168.1.6:2183 docker-compose-9094.yml version: '3.1' services: kafka: image: wurstmeister/kafka restart: always hostname: kafka ports: - 9094:9092 volumes: - \"~/share/docker/compose-data/kafka/kafka-9094/docker.sock:/var/run/docker.sock\" - \"~/share/docker/compose-data/kafka/kafka-9094:/kafka\" environment: KAFKA_VERSION: 1.1.0 KAFKA_ADVERTISED_HOST_NAME: 192.168.1.6 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: 192.168.1.6:2181,192.168.1.6:2182,192.168.1.6:2183 运行zk与kakfa集群&emsp;&emsp;到这里，我们已经把两个组件的docker-compose文件写好了，现在我们来运行集群。 运行zookeeper集群在zookeeper的docker-compose文件夹下面打开终端，运行docker-compose up，这里也可以使用docker-compose up -d 后台运行 ➜ zk-kafka docker-compose up Creating network \"zk-kafka_default\" with the default driver Pulling zoo1 (zookeeper:)... latest: Pulling from library/zookeeper Digest: sha256:a043534003831de15268779b582d407d37291bf7d22292ec7dce242c57a5a2be Status: Downloaded newer image for zookeeper:latest Creating zk-kafka_zoo3_1 ... done Creating zk-kafka_zoo2_1 ... done Creating zk-kafka_zoo1_1 ... done Attaching to zk-kafka_zoo1_1, zk-kafka_zoo3_1, zk-kafka_zoo2_1 zoo1_1 | ZooKeeper JMX enabled by default zoo3_1 | ZooKeeper JMX enabled by default zoo1_1 | Using config: /conf/zoo.cfg zoo3_1 | Using config: /conf/zoo.cfg zoo2_1 | ZooKeeper JMX enabled by default zoo2_1 | Using config: /conf/zoo.cfg zoo1_1 | log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig). zoo1_1 | log4j:WARN Please initialize the log4j system properly. zoo1_1 | log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. zoo3_1 | log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig). zoo3_1 | log4j:WARN Please initialize the log4j system properly. zoo3_1 | log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. zoo2_1 | log4j:WARN No appenders could be found for logger (org.apache.zookeeper.server.quorum.QuorumPeerConfig). zoo2_1 | log4j:WARN Please initialize the log4j system properly. zoo2_1 | log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. 查看zookeeper的运行情况新开终端，执行docker ps，可以看到，我们已经有三个zookeeper实例已经运行起来了 ➜ ~ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7278fca16a38 zookeeper \"/docker-entrypoint.…\" 24 seconds ago Up 27 seconds 2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp zk-kafka_zoo1_1 bc396f78a9d4 zookeeper \"/docker-entrypoint.…\" 24 seconds ago Up 27 seconds 2888/tcp, 3888/tcp, 0.0.0.0:2183->2181/tcp zk-kafka_zoo3_1 dd9b8be8eebe zookeeper \"/docker-entrypoint.…\" 24 seconds ago Up 26 seconds 2888/tcp, 3888/tcp, 0.0.0.0:2182->2181/tcp zk-kafka_zoo2_1 运行kakfa在kakfa的docker-compose-909*.yml文件夹下面分布执行下面三个命令 # 集群启动方式 docker-compose -f docker-compose-9092.yml up -d docker-compose -f docker-compose-9093.yml scale kafka=2 docker-compose -f docker-compose-9094.yml scale kafka=3 查看kafka的运行情况docker ps 可以看到现在已经有三个zookeeper实例和三个kafka实例 ➜ ~ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 31e7e8ad1fc5 wurstmeister/kafka \"start-kafka.sh\" 29 seconds ago Up 37 seconds 0.0.0.0:9094->9092/tcp zk-kafka_kafka_3 d9c1fa25f46e wurstmeister/kafka \"start-kafka.sh\" 35 seconds ago Up 43 seconds 0.0.0.0:9093->9092/tcp zk-kafka_kafka_2 caf6b21ba709 wurstmeister/kafka \"start-kafka.sh\" 44 seconds ago Up 52 seconds 0.0.0.0:9092->9092/tcp zk-kafka_kafka_1 7278fca16a38 zookeeper \"/docker-entrypoint.…\" 37 minutes ago Up About a minute 2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp zk-kafka_zoo1_1 bc396f78a9d4 zookeeper \"/docker-entrypoint.…\" 37 minutes ago Up About a minute 2888/tcp, 3888/tcp, 0.0.0.0:2183->2181/tcp zk-kafka_zoo3_1 dd9b8be8eebe zookeeper \"/docker-entrypoint.…\" 37 minutes ago Up About a minute 2888/tcp, 3888/tcp, 0.0.0.0:2182->2181/tcp zk-kafka_zoo2_1 使用kafka集群进行消息生产与消费进入kafka容器docker exec -it [container-name] /bin/bash，这里使用的是容器的名称，因为有三个kafka集群，通过docker ps可以看到分别是（zk-kafka_kafka_1，zk-kafka_kafka_2，zk-kafka_kafka_3）所以随便一个都可以 # 进入kafka容器 docker exec -it zk-kafka_kafka_1 /bin/bash # 进入安装目录 cd /opt/kafka/ # 查看topic列表 ./bin/kafka-topics.sh --list --zookeeper 192.168.1.6:2181 # 创建 topic ./bin/kafka-topics.sh --create --zookeeper 192.168.1.6:2181 --replication-factor 1 --partitions 1 --topic test # 生产消息 ./bin/kafka-console-producer.sh --broker-list 192.168.1.6:9092 --topic test # 消费消息 ./bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.6:9092 --topic test --from-beginning 查看topic列表➜ ~ docker exec -it zk-kafka_kafka_1 /bin/bash bash-4.4# cd /opt/kafka bash-4.4# pwd /opt/kafka bash-4.4# ./bin/kafka-topics.sh --list --zookeeper 192.168.1.6:2181 bash-4.4# 创建topic➜ ~ docker exec -it zk-kafka_kafka_1 /bin/bash bash-4.4# cd /opt/kafka bash-4.4# pwd /opt/kafka bash-4.4# ./bin/kafka-topics.sh --list --zookeeper 192.168.1.6:2181 ion-factor 1 --partitions 1 --topic test --zookeeper 192.168.1.6:2181 --replicati Created topic \"test\". bash-4.4# 消息的生产与消费打开两个终端进入容器，一个作为生产者生产消息，一个作为消费者消费消息 生产者使用zk-kafka_kafka_1容器，zk使用9092端口 ➜ zk-kafka docker exec -it zk-kafka_kafka_1 /bin/bash bash-4.4# cd /opt/kafka bash-4.4# ./bin/kafka-console-producer.sh --broker-list 192.168.1.6:9092 --topic test >123 >测试数据 >test data >阿牛 > 消费者zk-kafka_kafka_2，zk使用9093端口 ➜ ~ docker exec -it zk-kafka_kafka_2 /bin/bash bash-4.4# cd /opt/kafka bash-4.4# ./bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.6:9093 --topic test --from-beginning 123 测试数据 test data 阿牛 消费者zk-kafka_kafka_3，zk使用9094端口 ➜ ~ docker exec -it zk-kafka_kafka_3 /bin/bash bash-4.4# cd /opt/kafka bash-4.4# ./bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.6:9094 --topic test --from-beginning 123 测试数据 test data 阿牛 至此，zookeeper和kakfa集群搭建到此结束 小结中间踩了很多坑，网上参考了很多教程，重点还是需要自己动手折腾 参考docker从入门到实践 kakfa-docker Docker部署Kafka集群 zookeeper-docker","categories":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/tags/docker/"}]},{"title":"docker-compose-基础","slug":"docker-compose-start","date":"2018-07-11T13:32:06.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2018/07/11/docker-compose-start/","link":"","permalink":"http://iogogogo.github.io/2018/07/11/docker-compose-start/","excerpt":"","text":"docker-compose介绍Docker-Compose 是 Docker 的一种编排服务，是一个用于在 Docker 上定义并运行复杂应用的工具，可以让用户在集群中部署分布式应用。 Compose 中有两个重要的概念： 服务 (service) ：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project) ：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 docker-compose安装docker-compose 是 Docker 的独立产品，因此需要安装 Docker 之后在单独安装 Docker Compose 。 要安装其他版本的 Compose，请替换 v2.2.2。 #下载 sudo curl -L \"https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose #赋予二进制文件执行权限 chmod +x /usr/local/bin/docker-compose # 创建软链 sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose # 显示docker-compose版本 docker-compose version docker-compose补全工具安装 #安装 yum install bash-completion #下载docker-compose脚本 curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose docker-compose常用命令 #查看帮助 docker-compose -h # -f 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 docker-compose -f docker-compose.yml up -d #启动所有容器，-d 将会在后台启动并运行所有的容器 docker-compose up -d #停用移除所有容器以及网络相关 docker-compose down #查看服务容器的输出 docker-compose logs #列出项目中目前的所有容器 docker-compose ps #构建（重新构建）项目中的服务容器。服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。可以随时在项目目录下运行 docker-compose build 来重新构建服务 docker-compose build #拉取服务依赖的镜像 docker-compose pull #重启项目中的服务 docker-compose restart #删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 docker-compose rm #在指定服务上执行一个命令。 docker-compose run ubuntu ping docker.com #设置指定服务运行的容器个数。通过 service=num 的参数来设置数量 docker-compose scale web=3 db=2 #启动已经存在的服务容器。 docker-compose start #停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 docker-compose stop 本篇全是基本的安装和命令，下篇通过docker和docker-compose构建一些常用的软件运行环境 参考Docker(四)：Docker 三剑客之 Docker Compose","categories":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/tags/docker/"}]},{"title":"docke-安装","slug":"docker-start","date":"2018-07-10T14:31:39.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2018/07/10/docker-start/","link":"","permalink":"http://iogogogo.github.io/2018/07/10/docker-start/","excerpt":"","text":"docker安装建议在linux环境下安装Docker，window环境搭建比较复杂且容易出错，使用Centos7+yum来安装Docker环境很方便。 # 卸载旧版本docker sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine # 安装yum-utils sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 # 配置docker-ce.repo sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 安装docker-ce sudo yum install docker-ce # 启动docker sudo systemctl start docker # Docker守护进程自启动 sudo systemctl enable docker.service # 显示docker版本 docker --version 设置中国镜像加速器# 编辑daemon.json文件 vim /etc/docker/daemon.json # 添加加速内容 { \"registry-mirrors\": [\"https://registry.docker-cn.com\"], \"live-restore\": true } docker常用命令 拉取镜像 docker pull [image_name] # 获取redis镜像 docker pull redis Using default tag: latest latest: Pulling from library/redis 683abbb4ea60: Pull complete 259238e792d8: Pull complete 78399601c709: Pull complete f397da474601: Pull complete c57de4edc390: Pull complete b2ea05c9d9a1: Pull complete Digest: sha256:5534b92530acc653f0721ebfa14f31bc718f68bf9070cbba25bb00bc7aacfabb Status: Downloaded newer image for redis:latest 查看所有镜像docker images # 查看所有镜像 docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins latest e2541428ed0d 7 days ago 696MB redis latest 71a81cb279e3 13 days ago 83.4MB zookeeper latest 397be0d8fa45 3 weeks ago 146MB 删除镜像 docker rmi redis 或者 docker rmi 71a81cb279e3 查看所有运行的容器docker ps docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES eb5abaa4710a mysql:5.7.20 \"docker-entrypoint.s…\" 6 weeks ago Up 6 minutes 0.0.0.0:10100->3306/tcp mysql # 这里可以添加 -a 参数，查看所有容器，包括没有运行的 查看容器运行日志 docker logs -f –tail 20 [container_name] # -f 表示跟踪日志输出 --tail 表示持续输出 20表示第一次查看的行数 最后是容器名称 docker logs -f --tail 20 [container_name] 2018-07-10T14:49:21.476230Z 0 [Warning] CA certificate ca.pem is self signed. 2018-07-10T14:49:21.481000Z 0 [Note] InnoDB: Buffer pool(s) load completed at 180710 进入运行的容器docker exec -it [container_name] bash 当然进入容器的方式很多，但是官方推荐此方式，其他方式感兴趣可以参考此文章： nsenter进入后台运行的Docker容器 # 进入容器 docker exec -it redis bash # 退出容器 exit 删除所有停止的容器 docker rm $(docker ps -a -q) 删除容器 docker rm container_name/container_id 启动、停止、重启容器 docker start container_name/container_id docker stop container_name/container_id docker restart container_name/container_id docker安装常见问题启动报错 Job for docker.service failed. See &#39;systemctl status docker.service&#39; and &#39;journalctl -xn&#39; for details. 解决方案1: # 查看SELinux状态： /usr/sbin/sestatus -v ##如果SELinux status参数为enabled即为开启状态 SELinux status: enabled getenforce ##也可以用这个命令检查 # 关闭SELinux： 1、临时关闭（不用重启机器）： setenforce 0 ##设置SELinux 成为permissive模式 ##setenforce 1 设置SELinux 成为enforcing模式 2、修改配置文件需要重启机器： 修改/etc/selinux/config 文件 将SELINUX=enforcing改为SELINUX=disabled 重启机器即可 解决方案2: # 升级yum，重新安装docker yum update # 卸载docker sudo yum -y remove docker-ce sudo rm -rf /var/lib/docker # 重新安装 参考链接docker官网 关闭SELinux","categories":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/tags/docker/"}]},{"title":"eclipse 使用 maven 构建web项目","slug":"eclipse-mvn-build-web-project","date":"2017-09-28T15:13:53.000Z","updated":"2024-07-01T12:30:37.370Z","comments":true,"path":"2017/09/28/eclipse-mvn-build-web-project/","link":"","permalink":"http://iogogogo.github.io/2017/09/28/eclipse-mvn-build-web-project/","excerpt":"","text":"环境准备 apache-maven-3.3.9 apache-tomcat-8.5.20 eclipse-jee-neon-3 jdk1.8.0_131 Maven基本配置 修改 setting.xml 文件apache-tomcat-8.5.20/conf/settings.xml 1.仓库本地存储位置 2.配置阿里云国内的中央仓库，提升下载速度 mirrors 节点内` alimaven central aliyun maven http://maven.aliyun.com/nexus/content/repositories/central/ &lt;mirror&gt; &lt;id&gt;repo1&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;repo2&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; ![阿里云maven镜像](http://upload-images.jianshu.io/upload_images/7779890-fdbaf1e3853ed100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) &gt; 3.配置编译时的jdk版本，可以在这里配置全局，也可以根据项目配置 profiles 节点内 jdk1.8 true 1.8 &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; ` eclipse 集成maven插件 新建maven项目 将项目转换成maven web 项目右键打开项目设置 但是现在这个不是一个标准的web项目，继续修改项目结构，将WebContent目录下的文件拷贝到main/webapp目录下面，删除WebContent目录，结构如下 配置运行该项目 在webapp右键新建一个html 文件 2.配置 tomcat 3.运行 eclipse 集成 maven 构建 web 项目完成 最后推荐一篇文章：在 idea 中如何使用 maven 构建项目https://yq.aliyun.com/articles/111053","categories":[{"name":"工具使用","slug":"工具使用","permalink":"http://iogogogo.github.io/categories/工具使用/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"}]},{"title":"阿牛","slug":"index","date":"2017-09-05T13:26:39.000Z","updated":"2024-07-01T12:30:37.372Z","comments":true,"path":"2017/09/05/index/","link":"","permalink":"http://iogogogo.github.io/2017/09/05/index/","excerpt":"","text":"记录工作中的一些问题和笔记。","categories":[],"tags":[{"name":"有心怎么会做不到","slug":"有心怎么会做不到","permalink":"http://iogogogo.github.io/tags/有心怎么会做不到/"}]}],"categories":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/categories/Git/"},{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/categories/博客选型/"},{"name":"zsh","slug":"zsh","permalink":"http://iogogogo.github.io/categories/zsh/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/categories/Spring-Boot/"},{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/categories/MySQL/"},{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/categories/Java/"},{"name":"Maven","slug":"Maven","permalink":"http://iogogogo.github.io/categories/Maven/"},{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/categories/Kafka/"},{"name":"Spring","slug":"Kafka/Spring","permalink":"http://iogogogo.github.io/categories/Kafka/Spring/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://iogogogo.github.io/categories/Hadoop/"},{"name":"Redis","slug":"Redis","permalink":"http://iogogogo.github.io/categories/Redis/"},{"name":"Guava","slug":"Guava","permalink":"http://iogogogo.github.io/categories/Guava/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://iogogogo.github.io/categories/MyBatis/"},{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/categories/Gson/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://iogogogo.github.io/categories/正则表达式/"},{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/categories/Vertica/"},{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/categories/maven/"},{"name":"工具使用","slug":"工具使用","permalink":"http://iogogogo.github.io/categories/工具使用/"},{"name":"Spring","slug":"Spring","permalink":"http://iogogogo.github.io/categories/Spring/"},{"name":"tools","slug":"tools","permalink":"http://iogogogo.github.io/categories/tools/"},{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/categories/Java8/"},{"name":"Swagger","slug":"Swagger","permalink":"http://iogogogo.github.io/categories/Swagger/"},{"name":"PMP实战","slug":"PMP实战","permalink":"http://iogogogo.github.io/categories/PMP实战/"},{"name":"Web开发","slug":"Web开发","permalink":"http://iogogogo.github.io/categories/Web开发/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/categories/Spring-Cloud/"},{"name":"MacBook","slug":"MacBook","permalink":"http://iogogogo.github.io/categories/MacBook/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://iogogogo.github.io/categories/elasticsearch/"},{"name":"Jenkins","slug":"Jenkins","permalink":"http://iogogogo.github.io/categories/Jenkins/"},{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/categories/docker/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://iogogogo.github.io/tags/Git/"},{"name":"博客选型","slug":"博客选型","permalink":"http://iogogogo.github.io/tags/博客选型/"},{"name":"zsh","slug":"zsh","permalink":"http://iogogogo.github.io/tags/zsh/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://iogogogo.github.io/tags/Spring-Boot/"},{"name":"MySQL","slug":"MySQL","permalink":"http://iogogogo.github.io/tags/MySQL/"},{"name":"Java","slug":"Java","permalink":"http://iogogogo.github.io/tags/Java/"},{"name":"hexo","slug":"hexo","permalink":"http://iogogogo.github.io/tags/hexo/"},{"name":"cron","slug":"cron","permalink":"http://iogogogo.github.io/tags/cron/"},{"name":"logstash","slug":"logstash","permalink":"http://iogogogo.github.io/tags/logstash/"},{"name":"Logstash","slug":"Logstash","permalink":"http://iogogogo.github.io/tags/Logstash/"},{"name":"Maven","slug":"Maven","permalink":"http://iogogogo.github.io/tags/Maven/"},{"name":"Kafka","slug":"Kafka","permalink":"http://iogogogo.github.io/tags/Kafka/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://iogogogo.github.io/tags/Hadoop/"},{"name":"Redis","slug":"Redis","permalink":"http://iogogogo.github.io/tags/Redis/"},{"name":"Guava","slug":"Guava","permalink":"http://iogogogo.github.io/tags/Guava/"},{"name":"map","slug":"map","permalink":"http://iogogogo.github.io/tags/map/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://iogogogo.github.io/tags/MyBatis/"},{"name":"Gson","slug":"Gson","permalink":"http://iogogogo.github.io/tags/Gson/"},{"name":"Java8","slug":"Java8","permalink":"http://iogogogo.github.io/tags/Java8/"},{"name":"Nginx","slug":"Nginx","permalink":"http://iogogogo.github.io/tags/Nginx/"},{"name":"Vertica","slug":"Vertica","permalink":"http://iogogogo.github.io/tags/Vertica/"},{"name":"maven","slug":"maven","permalink":"http://iogogogo.github.io/tags/maven/"},{"name":"IDEA","slug":"IDEA","permalink":"http://iogogogo.github.io/tags/IDEA/"},{"name":"spring","slug":"spring","permalink":"http://iogogogo.github.io/tags/spring/"},{"name":"transaction","slug":"transaction","permalink":"http://iogogogo.github.io/tags/transaction/"},{"name":"AspectJ","slug":"AspectJ","permalink":"http://iogogogo.github.io/tags/AspectJ/"},{"name":"Aop","slug":"Aop","permalink":"http://iogogogo.github.io/tags/Aop/"},{"name":"linux","slug":"linux","permalink":"http://iogogogo.github.io/tags/linux/"},{"name":"Swagger","slug":"Swagger","permalink":"http://iogogogo.github.io/tags/Swagger/"},{"name":"PMP","slug":"PMP","permalink":"http://iogogogo.github.io/tags/PMP/"},{"name":"FTP","slug":"FTP","permalink":"http://iogogogo.github.io/tags/FTP/"},{"name":"Vue","slug":"Vue","permalink":"http://iogogogo.github.io/tags/Vue/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://iogogogo.github.io/tags/Spring-Cloud/"},{"name":"Mac","slug":"Mac","permalink":"http://iogogogo.github.io/tags/Mac/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://iogogogo.github.io/tags/elasticsearch/"},{"name":"Jenkins","slug":"Jenkins","permalink":"http://iogogogo.github.io/tags/Jenkins/"},{"name":"kafka","slug":"kafka","permalink":"http://iogogogo.github.io/tags/kafka/"},{"name":"docker","slug":"docker","permalink":"http://iogogogo.github.io/tags/docker/"},{"name":"有心怎么会做不到","slug":"有心怎么会做不到","permalink":"http://iogogogo.github.io/tags/有心怎么会做不到/"}]}